{"meta":{"title":"自在技术博客","subtitle":"专心一点","description":null,"author":"自在","url":"https://hxqxiaoqi.gitee.io"},"pages":[{"title":"关于我","date":"2018-03-11T08:18:54.000Z","updated":"2020-07-24T01:39:32.308Z","comments":false,"path":"about/index.html","permalink":"https://hxqxiaoqi.gitee.io/about/index.html","excerpt":"","text":"本博客所有教程都是以文字形式说明，因为图片太麻烦了，请仔细查看教程每一个说明。重点说两边，认真点。"},{"title":"categories","date":"2020-07-23T12:19:40.543Z","updated":"2020-07-23T12:19:40.543Z","comments":true,"path":"categories/index.html","permalink":"https://hxqxiaoqi.gitee.io/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2020-07-24T01:24:07.625Z","updated":"2020-07-24T01:24:07.625Z","comments":true,"path":"tags/index.html","permalink":"https://hxqxiaoqi.gitee.io/tags/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2020-07-24T01:43:01.952Z","updated":"2020-07-24T01:43:01.952Z","comments":false,"path":"tags/友情链接/index.html","permalink":"https://hxqxiaoqi.gitee.io/tags/友情链接/index.html","excerpt":"","text":"我的博客园: https://www.cnblogs.com/hxqxiaoqi outsrkem: https://www.cnblogs.com/outsrkem/ github地址: https://hxqxiaoqi1990.github.io/blog/"}],"posts":[{"title":"nginx之添加模块","slug":"nginx之添加模块","date":"2020-07-20T09:40:43.000Z","updated":"2020-07-24T04:07:55.328Z","comments":true,"path":"2020/07/20/nginx之添加模块/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2020/07/20/nginx之添加模块/","excerpt":"","text":"查看模块 123456# 查看可用模块及已安装模块cd nginx-1.14.2cat auto/options | grep YES# 查看已安装模块./nginx -V 添加模块 1234567891011121314151617# 到安装包cd nginx-1.14.2# 编译，别make install，会覆盖原配置./configure --prefix=/opt/nginx --user=nginx --group=nginx --with-http_ssl_module --with-http_stub_status_module --with-http_gzip_static_module --with-http_realip_module# 编译make# 备份nginx文件cp /opt/nginx/sbin/nginx /mnt# 复制新的nginx文件到nginx安装目录下cp objs/nginx /opt/nginx/sbin/# 查看安装模块/opt/nginx/sbin/nginx -V 添加第三方模块 (nginx_upstream_check_module-master) 123456789101112131415161718192021222324# 下载、解压wget https://codeload.github.com/yaoweibin/nginx_upstream_check_module/zip/mastertar xf nginx_upstream_check_module-master.zip# 到nginx安装包下cd nginx-1.14.2# 导入模块patch -p1 &lt; ../nginx_upstream_check_module-master/check_1.14.0+.patch# 试编译./configure --prefix=/opt/nginx --user=nginx --group=nginx --with-http_ssl_module --with-http_stub_status_module --with-http_gzip_static_module --with-http_realip_module --add-module=../nginx_upstream_check_module-master/# 编译，千万别执行：make installmake# 备份nginx文件cp /opt/nginx/sbin/nginx /mnt# 复制新的nginx文件到nginx安装目录下cp objs/nginx /opt/nginx/sbin/# 查看安装模块/opt/nginx/sbin/nginx -V","categories":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://hxqxiaoqi.gitee.io/tags/nginx/"}],"keywords":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}]},{"title":"nginx之健康检查","slug":"nginx之健康检查","date":"2020-07-20T08:40:43.000Z","updated":"2020-07-24T04:07:58.988Z","comments":true,"path":"2020/07/20/nginx之健康检查/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2020/07/20/nginx之健康检查/","excerpt":"","text":"介绍nginx健康检查分为： 被动：ngx_http_proxy_module 模块和ngx_http_upstream_module模块，会有失败的连接。（自带） 主动：nginx 模块 nginx_upstream_check_module，通过它可以用来检测后端 realserver 的健康状态。（淘宝第三方） 配置被动检查 1234567upstream name &#123; server 10.1.1.110:8080 max_fails=1 fail_timeout=10s; server 10.1.1.122:8080 max_fails=1 fail_timeout=10s;&#125;max_fails=number # 设定Nginx与服务器通信的尝试失败的次数。在fail_timeout参数定义的时间段内，如果失败的次数达到此值，Nginx就认为服务器不可用。在下一个fail_timeout时间段，服务器不会再被尝试。 失败的尝试次数默认是1。设为0就会停止统计尝试次数，认为服务器是一直可用的。 你可以通过指令proxy_next_upstream、fastcgi_next_upstream和 memcached_next_upstream来配置什么是失败的尝试。 默认配置时，http_404状态不被认为是失败的尝试。fail_timeout=time # 设定服务器被认为不可用的时间段以及统计失败尝试次数的时间段。在这段时间中，服务器失败次数达到指定的尝试次数，服务器就被认为不可用。默认情况下，该超时时间是10秒。 主动检查 123456789101112# interval检测间隔时间，单位为毫秒，rsie请求2次正常的话，标记此realserver的状态为up，fall表示请求5次都失败的情况下，标记此realserver的状态为down，timeout为超时时间，单位为毫秒。upstream linuxyan &#123; server 192.168.10.21:80; server 192.168.10.22:80; check interval=3000 rise=2 fall=5 timeout=1000;&#125;# web查看realserver状态的页面location /nstatus &#123;check_status;access_log off;&#125;","categories":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://hxqxiaoqi.gitee.io/tags/nginx/"}],"keywords":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}]},{"title":"seata分布式事务","slug":"seata分布式事务","date":"2020-07-13T07:00:00.000Z","updated":"2020-07-24T03:43:54.045Z","comments":true,"path":"2020/07/13/seata分布式事务/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2020/07/13/seata分布式事务/","excerpt":"","text":"介绍角色介绍： XID：一个全局事务的唯一标识，由ip:port:sequence组成 Transaction Coordinator (TC)： 事务协调器，维护全局事务的运行状态，负责协调并驱动全局事务的提交或回滚。 Transaction Manager （TM）： 控制全局事务的边界，负责开启一个全局事务，并最终发起全局提交或全局回滚的决议。 Resource Manager (RM)： 控制分支事务，负责分支注册、状态汇报，并接收事务协调器的指令，驱动分支（本地）事务的提交和回滚。 k8s高可用部署123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119apiVersion: v1kind: Servicemetadata: name: seata-ha-server namespace: default labels: app.kubernetes.io/name: seata-ha-serverspec: type: ClusterIP ports: - port: 8091 protocol: TCP name: http selector: app.kubernetes.io/name: seata-ha-server---apiVersion: apps/v1kind: Deploymentmetadata: name: seata-ha-server namespace: default labels: app.kubernetes.io/name: seata-ha-serverspec: replicas: 3 selector: matchLabels: app.kubernetes.io/name: seata-ha-server template: metadata: labels: app.kubernetes.io/name: seata-ha-server spec: containers: - name: seata-ha-server image: docker.io/seataio/seata-server:latest imagePullPolicy: IfNotPresent env: - name: SEATA_CONFIG_NAME value: file:/root/seata-config/registry ports: - name: http containerPort: 8091 protocol: TCP volumeMounts: - name: seata-config mountPath: /root/seata-config - name: file-conf mountPath: /root/seata-config1 volumes: - name: seata-config configMap: name: seata-ha-server-config - name: file-conf configMap: name: file-config---apiVersion: v1kind: ConfigMapmetadata: name: file-configdata: file.conf: | ## transaction log store, only used in seata-server store &#123; ## store mode: file、db、redis mode = \"db\" ## 填写数据库连接信息 db &#123; ## the implement of javax.sql.DataSource, such as DruidDataSource(druid)/BasicDataSource(dbcp)/HikariDataSource(hikari) etc. datasource = \"druid\" ## mysql/oracle/postgresql/h2/oceanbase etc. dbType = \"mysql\" driverClassName = \"com.mysql.jdbc.Driver\" url = \"jdbc:mysql://192.168.10.70:3306/seata\" user = \"root\" password = \"mamahao\" minConn = 5 maxConn = 30 globalTable = \"global_table\" branchTable = \"branch_table\" lockTable = \"lock_table\" queryLimit = 100 maxWait = 5000 &#125; &#125;---apiVersion: v1kind: ConfigMapmetadata: name: seata-ha-server-configdata: registry.conf: | registry &#123; # eureka配置信息 # file 、nacos 、eureka、redis、zk、consul、etcd3、sofa type = \"eureka\" eureka &#123; serviceUrl = \"http://10.107.152.214:9901/eureka\" application = \"default\" weight = \"1\" &#125; &#125; config &#123; # file、nacos 、apollo、zk、consul、etcd3 type = \"file\" file &#123; # 指定file.conf的文件位置 name = \"file:/root/seata-config1/file.conf\" &#125; &#125;","categories":[{"name":"中间件","slug":"中间件","permalink":"https://hxqxiaoqi.gitee.io/categories/中间件/"}],"tags":[{"name":"seata","slug":"seata","permalink":"https://hxqxiaoqi.gitee.io/tags/seata/"}],"keywords":[{"name":"中间件","slug":"中间件","permalink":"https://hxqxiaoqi.gitee.io/categories/中间件/"}]},{"title":"k8s之ingress-nginx","slug":"k8s之ingress-nginx","date":"2020-07-09T07:06:00.000Z","updated":"2020-07-24T03:50:03.184Z","comments":true,"path":"2020/07/09/k8s之ingress-nginx/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2020/07/09/k8s之ingress-nginx/","excerpt":"","text":"介绍Ingress是什么？ ingress 是除了 hostport nodeport clusterIP以及云环境专有的负载均衡器外的访问方式,官方提供了Nginx ingress controller。ingress-nginx本身就是nodeport模式 Ingress能做什么？ k8s中，不管是哪种类型的svc，不管是用iptables还是ipvs实现端口转发实现负载均衡，也只是实现了四层的负载均衡，但是，如果有需求要进行七层负载均衡呢？比如你想将你的网站设置为https呢？Ingress就是来帮你解决此问题的。 Ingress工作原理及主要组成部分？ 工作原理： 类似于Nginx，可以理解为在Ingress建立一个个映射规则，Ingress Controller通过监听Ingress这个api对象里的规则并转化为Nginx/HAporxy等的配置，然后对外部提供服务。 组成部分： ingress controller： 核心是一个deployment，实现方式有很多种，比如Nignx、HAproxy、trafik、lstio，需要编写的yaml有：Deployment、Service、ConfigMap、ServiceAccount(Auth)，其中Service类型可以是NodePort或者LoadBalance ingress resources：这个是类型为ingress的k8s api对象，主要面向开发人员。 nginx-ingress-controller yaml部署123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276apiVersion: v1kind: Namespacemetadata: name: ingress-nginx labels: app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx---kind: ConfigMapapiVersion: v1metadata: name: nginx-configuration namespace: ingress-nginx labels: app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx---kind: ConfigMapapiVersion: v1metadata: name: tcp-services namespace: ingress-nginx labels: app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx---kind: ConfigMapapiVersion: v1metadata: name: udp-services namespace: ingress-nginx labels: app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx---apiVersion: v1kind: ServiceAccountmetadata: name: nginx-ingress-serviceaccount namespace: ingress-nginx labels: app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx---apiVersion: rbac.authorization.k8s.io/v1beta1kind: ClusterRolemetadata: name: nginx-ingress-clusterrole labels: app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginxrules: - apiGroups: - \"\" resources: - configmaps - endpoints - nodes - pods - secrets verbs: - list - watch - apiGroups: - \"\" resources: - nodes verbs: - get - apiGroups: - \"\" resources: - services verbs: - get - list - watch - apiGroups: - \"\" resources: - events verbs: - create - patch - apiGroups: - \"extensions\" - \"networking.k8s.io\" resources: - ingresses verbs: - get - list - watch - apiGroups: - \"extensions\" - \"networking.k8s.io\" resources: - ingresses/status verbs: - update---apiVersion: rbac.authorization.k8s.io/v1beta1kind: Rolemetadata: name: nginx-ingress-role namespace: ingress-nginx labels: app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginxrules: - apiGroups: - \"\" resources: - configmaps - pods - secrets - namespaces verbs: - get - apiGroups: - \"\" resources: - configmaps resourceNames: # Defaults to \"&lt;election-id&gt;-&lt;ingress-class&gt;\" # Here: \"&lt;ingress-controller-leader&gt;-&lt;nginx&gt;\" # This has to be adapted if you change either parameter # when launching the nginx-ingress-controller. - \"ingress-controller-leader-nginx\" verbs: - get - update - apiGroups: - \"\" resources: - configmaps verbs: - create - apiGroups: - \"\" resources: - endpoints verbs: - get---apiVersion: rbac.authorization.k8s.io/v1beta1kind: RoleBindingmetadata: name: nginx-ingress-role-nisa-binding namespace: ingress-nginx labels: app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginxroleRef: apiGroup: rbac.authorization.k8s.io kind: Role name: nginx-ingress-rolesubjects: - kind: ServiceAccount name: nginx-ingress-serviceaccount namespace: ingress-nginx---apiVersion: rbac.authorization.k8s.io/v1beta1kind: ClusterRoleBindingmetadata: name: nginx-ingress-clusterrole-nisa-binding labels: app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginxroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: nginx-ingress-clusterrolesubjects: - kind: ServiceAccount name: nginx-ingress-serviceaccount namespace: ingress-nginx---apiVersion: apps/v1kind: Deploymentmetadata: name: nginx-ingress-controller namespace: ingress-nginx labels: app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginxspec: replicas: 3 selector: matchLabels: app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx template: metadata: labels: app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx annotations: prometheus.io/port: \"10254\" prometheus.io/scrape: \"true\" spec: # wait up to five minutes for the drain of connections hostNetwork: true terminationGracePeriodSeconds: 300 serviceAccountName: nginx-ingress-serviceaccount nodeSelector: kubernetes.io/os: linux containers: - name: nginx-ingress-controller image: bitnami/nginx-ingress-controller:0.26.2 args: - /nginx-ingress-controller - --configmap=$(POD_NAMESPACE)/nginx-configuration - --tcp-services-configmap=$(POD_NAMESPACE)/tcp-services - --udp-services-configmap=$(POD_NAMESPACE)/udp-services - --publish-service=$(POD_NAMESPACE)/ingress-nginx - --annotations-prefix=nginx.ingress.kubernetes.io securityContext: allowPrivilegeEscalation: true capabilities: drop: - ALL add: - NET_BIND_SERVICE # www-data -&gt; 33 runAsUser: 33 env: - name: POD_NAME valueFrom: fieldRef: fieldPath: metadata.name - name: POD_NAMESPACE valueFrom: fieldRef: fieldPath: metadata.namespace ports: - name: http containerPort: 80 protocol: TCP - name: https containerPort: 443 protocol: TCP livenessProbe: failureThreshold: 3 httpGet: path: /healthz port: 10254 scheme: HTTP initialDelaySeconds: 10 periodSeconds: 10 successThreshold: 1 timeoutSeconds: 10 readinessProbe: failureThreshold: 3 httpGet: path: /healthz port: 10254 scheme: HTTP periodSeconds: 10 successThreshold: 1 timeoutSeconds: 10 lifecycle: preStop: exec: command: - /wait-shutdown ingress 配置示例一：暴露域名12345678910111213apiVersion: extensions/v1beta1kind: Ingressmetadata: name: ingress1spec: rules: - host: www1.wuzi.com http: paths: - path: / backend: serviceName: ingress-svc1 servicePort: 80 示例二：暴露ip12345678910111213141516171819202122apiVersion: extensions/v1beta1kind: Ingressmetadata: name: gw namespace: b2b-test annotations: kubernetes.io/ingress.class: \"nginx\" # 地址重写 nginx.ingress.kubernetes.io/rewrite-target: /$2spec: rules: - http: paths: # 绑定的svc内容。可以配置多个 - backend: serviceName: mmhsy-gateway servicePort: 9900 path: /b2b-gw(/|$)(.*) - backend: serviceName: nginx servicePort: 80 path: / 示例三：https配置1234567891011## 创建私钥keyopenssl genrsa -des3 -out server.key 2048## 创建csr请求openssl req -new -key server.key -out server.csr## 去除私钥的连接密码cp server.key&#123;,.org&#125;openssl rsa -in server.key.org -out server.key## 生成证书文件openssl x509 -req -days 3650 -in server.csr -signkey server.key -out server.crt## 生成tls格式kubectl create secret tls tls-secret --key server.key --cert server.crt ingress引用tls证书 1234567891011121314151617apiVersion: extensions/v1beta1kind: Ingressmetadata: name: ingress-httpsspec: tls: - hosts: - www3.wuzi.com secretName: tls-secret rules: - host: www3.wuzi.com http: paths: - path: / backend: serviceName: ingress-https servicePort: 80 示例四：重写12345678910111213141516apiVersion: networking.k8s.io/v1beta1kind: Ingressmetadata: annotations: nginx.ingress.kubernetes.io/rewrite-target: https://www3.wuzi.com:31087 name: rewrite namespace: defaultspec: rules: - host: www5.wuzi.com http: paths: - backend: serviceName: ingress-svc1 servicePort: 80 path: /","categories":[{"name":"kubernetes","slug":"kubernetes","permalink":"https://hxqxiaoqi.gitee.io/categories/kubernetes/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://hxqxiaoqi.gitee.io/tags/k8s/"}],"keywords":[{"name":"kubernetes","slug":"kubernetes","permalink":"https://hxqxiaoqi.gitee.io/categories/kubernetes/"}]},{"title":"记一次磁盘空间不足问题","slug":"记一次磁盘空间不足问题","date":"2020-07-07T08:27:43.000Z","updated":"2020-07-24T04:01:52.865Z","comments":true,"path":"2020/07/07/记一次磁盘空间不足问题/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2020/07/07/记一次磁盘空间不足问题/","excerpt":"","text":"问题 使用df -ha查看/分区容量占满 但使用du -sh /*却没有占用大的目录 lsof |grep delete也没有占用deleted状态的大容量进程 find / -type f -size +100M -exec ls -lh {} ;查找大文件，也没有找到 find / -name “.*” -exec ls -lh {} ;查找隐藏文件，也没有太大的 重启服务器没有效果，依然显示磁盘空间不足 思路去谷歌和百度查了大量相关的资料，没有效果，最后仔细区分了下du和df的区别，得到灵感。 df 从文件系统上获得磁盘信息。 du 计算文件数容量总和的到磁盘信息。 du基本确定是实际的磁盘容量占用，既然du显示磁盘比较空余，那肯定是df这边出问题。 df从文件系统获取磁盘信息，大概率文件系统信息错误，查看linux的文件系统，是xfs，查找xfs文件系统异常相关文档。 解决方案12345678# 安装xfs检查工具yum -y install xfsdump xfsprogs-devel xfsprogs# 检测/分区的碎片，显示的数据是50%左右，xfs_db -c frag -r /dev/sda3# 尝试使用修复整理碎片xfs_fsr /dev/sda3 ps：如果是SSD或者PCIE的SSD盘，一般不需要碎片整理，整理多了反而影响寿命。","categories":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}],"tags":[{"name":"disk","slug":"disk","permalink":"https://hxqxiaoqi.gitee.io/tags/disk/"}],"keywords":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}]},{"title":"k8s监控脚本","slug":"k8s监控脚本","date":"2020-07-04T01:06:00.000Z","updated":"2020-07-24T06:59:39.038Z","comments":true,"path":"2020/07/04/k8s监控脚本/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2020/07/04/k8s监控脚本/","excerpt":"","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133#!/usr/bin/python3# -*- coding: UTF-8 -*-# 获取k8s集群基本信息，根据kubernets模块提供的接口from kubernetes import client, configfrom collections import Counterimport requestsimport datetimeconfig.kube_config.load_kube_config(config_file=\"/var/www/html/cgi-bin/b2b-kubeconfig.yaml\")# 选择名称空间clusername = \"b2b\"#获取API的CoreV1Api版本对象v1 = client.CoreV1Api()k8snamespaces = v1.list_pod_for_all_namespaces(watch=False)k8snamespacessvc = v1.list_namespaced_service(namespace=clusername)nodename = &#123;\"192.168.1.10\":\"(外网IP1#k1)\",\"192.168.1.10\":\"(外网IP2#k2)\",\"192.168.1.10\":\"(外网IP3#k3)\"&#125;def k8sinfo(podname): #集群接口信息 k8spodinfo = v1.read_namespaced_pod(namespace=clusername,name=podname) # 获取pod信息 print(\"&lt;tr&gt;\") if k8spodinfo.status.pod_ip != None: global podip podip = k8spodinfo.status.pod_ip print(\"&lt;td bgcolor='e8e8e8'&gt;&amp;nbsp;%s&lt;font size='1' color='#575757'&gt;%s&lt;/font&lt;/td&gt;\" % (podip,nodename[k8spodinfo.status.host_ip])) else: print(\"&lt;td bgcolor='e8e8e8' align='center'&gt;None&lt;/td&gt;\") print(\"&lt;td bgcolor='e8e8e8'&gt;&amp;nbsp;%s&lt;/td&gt;\" % (podname)) print(\"&lt;td bgcolor='e8e8e8'&gt;&amp;nbsp;%s &lt;/td&gt;\" % (k8spodinfo.status.host_ip)) if k8spodinfo.spec.containers[0].ports[0].container_port != None: k8spodport = k8spodinfo.spec.containers[0].ports[0].container_port print(\"&lt;td bgcolor='e8e8e8' align='center'&gt;%s&lt;/td&gt;\" % (k8spodport)) else: print(\"&lt;td bgcolor='e8e8e8' align='center'&gt;None&lt;/td&gt;\") # 获取pod运行状态 k8sstatus = k8spodinfo.status.container_statuses[0].ready if k8sstatus == True: print(\"&lt;td bgcolor='e8e8e8' align='center'&gt;&lt;font color='green'&gt;&amp;nbsp;True&lt;/font&gt;&lt;/td&gt;\") elif k8sstatus == False: print(\"&lt;td bgcolor='e8e8e8' align='center'&gt;&lt;font color='red'&gt;&amp;nbsp;False&lt;/font&gt;&lt;/td&gt;\") else: print(\"&lt;td bgcolor='e8e8e8' align='center'&gt;&lt;font color='red'&gt;&amp;nbsp;Error&lt;/font&gt;&lt;/td&gt;\") # 健康检查 if k8spodinfo.spec.containers[0].readiness_probe != None: if k8spodinfo.spec.containers[0].readiness_probe.http_get != None: checkurl = k8spodinfo.spec.containers[0].readiness_probe.http_get url=\"http://\"+podip+\":\"+str(k8spodport)+checkurl.path try: request = requests.get(url,timeout=2.2) httpStatusCode = request.status_code except requests.exceptions.ConnectTimeout: httpStatusCode = 502 except requests.exceptions.Timeout: httpStatusCode = 503 except requests.exceptions.ConnectionError: httpStatusCode=504 if httpStatusCode == 200: print(\"&lt;td bgcolor='e8e8e8' align='center'&gt;&lt;font color='green'&gt;\"+str(httpStatusCode)+\"&lt;/font&gt;&lt;/td&gt;\") else: print(\"&lt;td bgcolor='e8e8e8' align='center'&gt;&lt;font color='red'&gt;\"+str(httpStatusCode)+\"&lt;/font&gt;&lt;/td&gt;\") else: print(\"&lt;td bgcolor='e8e8e8' align='center'&gt;none&lt;/td&gt;\") else: print(\"&lt;td bgcolor='e8e8e8' align='center'&gt;none&lt;/td&gt;\") #版本 if k8spodinfo.metadata.annotations['aliyun.kubernetes.io/deploy-timestamp'] != None: k8spodversion = k8spodinfo.metadata.annotations['aliyun.kubernetes.io/deploy-timestamp'] k8spodversion1 = k8spodversion.split(\"T\")[0]+\" \"+k8spodversion.split(\"T\")[1].split(\"Z\")[0] k8spodversion2 = datetime.datetime.strptime(k8spodversion1,\"%Y-%m-%d %H:%M:%S\") add = datetime.timedelta(hours=8) k8spodversion = (k8spodversion2+add).strftime(\"%Y-%m-%d %H:%M:%S\") print(\"&lt;td bgcolor='e8e8e8' align='center'&gt;%s&lt;/td&gt;\" % (k8spodversion)) else: print(\"&lt;td bgcolor='e8e8e8' align='center'&gt;None&lt;/td&gt;\") # 重启次数 k8srestart = k8spodinfo.status.container_statuses[0].restart_count print(\"&lt;td bgcolor='e8e8e8' align='center'&gt;%s&lt;/td&gt;\" % (k8srestart)) #最后重启时间 if k8spodinfo.status.container_statuses[0].state.running != None: restarttime = k8spodinfo.status.container_statuses[0].state.running.started_at restarttime1 = str(restarttime).split(\"+\")[0] restarttime2 = datetime.datetime.strptime(restarttime1,\"%Y-%m-%d %H:%M:%S\") addtime = datetime.timedelta(hours=8) restarttime = (restarttime2+addtime).strftime(\"%Y-%m-%d %H:%M:%S\") print(\"&lt;td bgcolor='e8e8e8' align='center'&gt;%s&lt;/td&gt;\" % (restarttime)) else: print(\"&lt;td bgcolor='e8e8e8' align='center'&gt;None&lt;/td&gt;\") print(\"&lt;/tr&gt;\") # 获取pod名，去重，相同pod打印同一表格内def podinfo(): podapp = [] podlist = [] for i in k8snamespaces.items: if i.metadata.namespace == clusername: podapp.append(i.metadata.labels['app']) podlist.append(i.metadata.name) b = dict(Counter(podapp)) c = [key for key, value in b.items() if value &gt; 0] for y in c: for cluster in k8snamespacessvc.items: if cluster.spec.selector['app'] == y: cluster_ip = cluster.spec.cluster_ip cluster_port = cluster.spec.ports[0].port #num = 0 print(\"&lt;b&gt;&lt;font size=4&gt;%s&lt;/font&gt;&lt;/b&gt;\" % (y)) print('&lt;table border=1 cellspacing=0&gt;&lt;tr style=\"color: #ffffff\" bgcolor=\"#444444\" align=\"center\"&gt;&lt;td width=220px&gt;&lt;b&gt;Container IP&lt;/b&gt;&lt;/td&gt;&lt;td width=360px&gt;&lt;b&gt;&amp;nbsp;Name&lt;/b&gt;&lt;/td&gt;&lt;td width=150px&gt;&lt;b&gt;node IP&lt;/b&gt;&lt;/td&gt;&lt;td width=62px&gt;&lt;b&gt;&amp;nbsp;Port&lt;/b&gt;&lt;/td&gt;&lt;td width=80px&gt;&lt;b&gt;Status&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;&lt;font size=1&gt;UrlCheck(2.2s)&lt;/font&gt;&lt;/b&gt;&lt;/td&gt;&lt;td width=130px&gt;&lt;b&gt;Version&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;&lt;font size=1&gt;Refresh_Conf&lt;/font&gt;&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Log&lt;/b&gt;&lt;/td&gt;&lt;td&gt;restart&lt;/td&gt;&lt;td&gt;restarttime&lt;/td&gt;&lt;/tr&gt;') for x in podlist: if x.startswith(y): #num = num+1 k8sinfo(x) print ('&lt;/table&gt;') print(\"&lt;br&gt;&lt;br&gt;\") podinfo()","categories":[{"name":"脚本","slug":"脚本","permalink":"https://hxqxiaoqi.gitee.io/categories/脚本/"}],"tags":[{"name":"python脚本","slug":"python脚本","permalink":"https://hxqxiaoqi.gitee.io/tags/python脚本/"}],"keywords":[{"name":"脚本","slug":"脚本","permalink":"https://hxqxiaoqi.gitee.io/categories/脚本/"}]},{"title":"openvpn搭建配置","slug":"openvpn搭建配置","date":"2020-06-06T06:00:00.000Z","updated":"2020-07-24T06:29:12.228Z","comments":true,"path":"2020/06/06/openvpn搭建配置/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2020/06/06/openvpn搭建配置/","excerpt":"","text":"https://www.cnblogs.com/lemon-le/p/6266921.html","categories":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}],"tags":[{"name":"vpn","slug":"vpn","permalink":"https://hxqxiaoqi.gitee.io/tags/vpn/"}],"keywords":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}]},{"title":"flink之REST API调用","slug":"flink之REST API调用","date":"2020-06-05T05:00:00.000Z","updated":"2020-07-24T04:04:05.097Z","comments":true,"path":"2020/06/05/flink之REST API调用/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2020/06/05/flink之REST API调用/","excerpt":"","text":"介绍监视API由作为Dispatcher一部分运行的Web服务器支持。默认情况下，此服务器在post侦听8081，可以flink-conf.yaml通过via 进行配置rest.port。请注意，监视API Web服务器和Web仪表板Web服务器当前是相同的，因此可以在同一端口一起运行。但是，它们会响应不同的HTTP URL。 如果有多个Dispatcher（用于高可用性），则每个Dispatcher将运行自己的监视API实例，该实例提供有关在Dispatcher被选为集群负责人时已完成和正在运行的作业的信息。 官网地址：https://ci.apache.org/projects/flink/flink-docs-stable/monitoring/rest_api.html 示例123456789101112131415161718192021# 提交任务# programArgsList: jar包启动的参数，指定允许环境# entryClass：jar定义的类，可以根据类指定允许不同任务curl -XPOST -H \"Content-Type:application/java-archive\" http://192.168.10.111:8081/jars/692d1b44-8f99-4f42-abe0-21579238b57d_mmhsy-dw-flink-1.0-SNAPSHOT.jar/run -d '&#123;\"programArgsList\":[ \"--profiles\",\"test\"],\"entryClass\":\"com.mmhsy.flink.member.job.MemberStarMemberInviteJob\"&#125;'# 查看jobcurl -XGET http://192.168.10.111:8081/v1/jobs# 停止job# a50773a0af8feb5d57a16b6b7191d6b2：是jobidcurl -XPATCH http://192.168.10.111:8081/jobs/a50773a0af8feb5d57a16b6b7191d6b2# 查看包curl -XGET http://192.168.10.111:8081/jars# 上传包curl -X POST -F \"jarfile=@/root/.jenkins/workspace/mmhsy-dw-flink/target/mmhsy-dw-flink-1.0-SNAPSHOT.jar\" http://192.168.10.111:8081/jars/upload# 删除包# be820cde-b111-4641-9542-abaef4ca239f_Flink-Demo-1.0-SNAPSHOT.jar：是上传jar时生成的idcurl -X DELETE -H \"Content-Type:application/x-java-archive\" http://192.168.10.111:8081/jars/be820cde-b111-4641-9542-abaef4ca239f_Flink-Demo-1.0-SNAPSHOT.jar","categories":[{"name":"大数据","slug":"大数据","permalink":"https://hxqxiaoqi.gitee.io/categories/大数据/"}],"tags":[{"name":"flink","slug":"flink","permalink":"https://hxqxiaoqi.gitee.io/tags/flink/"}],"keywords":[{"name":"大数据","slug":"大数据","permalink":"https://hxqxiaoqi.gitee.io/categories/大数据/"}]},{"title":"nginx之php-fpm","slug":"nginx之php-fpm","date":"2020-06-04T09:40:43.000Z","updated":"2020-07-24T04:07:50.916Z","comments":true,"path":"2020/06/04/nginx之php-fpm/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2020/06/04/nginx之php-fpm/","excerpt":"","text":"介绍nginx 是一个高性能的http服务器和反向代理服务器。即nginx可以作为一个HTTP服务器进行网站的发布处理，也可以作为一个反向代理服务器进行负载均衡。但需要注意的是：nginx本身并不会对php文件进行解析。对PHP页面的请求将会被nginx交给FastCGI进程监听的IP地址及端口，由php-fpm(第三方的fastcgi进程管理器)作为动态解析服务器处理，最后将处理结果再返回给nginx。即nginx通过反向代理功能将动态请求转向后端php-fpm，从而实现对PHP的解析支持，这就是Nginx实现PHP动态解析的基本原理。 Nginx 是非阻塞IO &amp; IO复用模型，通过操作系统提供的类似 epoll 的功能，可以在一个线程里处理多个客户端的请求。Nginx 的进程就是线程，即每个进程里只有一个线程，但这一个线程可以服务多个客户端。 PHP-FPM 是阻塞的单线程模型，pm.max_children 指定的是最大的进程数量，pm.max_requests 指定的是每个进程处理多少个请求后重启(因为 PHP 偶尔会有内存泄漏，所以需要重启)。PHP-FPM 的每个进程也只有一个线程，但是一个进程同时只能服务一个客户端。 fastCGI ：为了解决不同的语言解释器(如php、python解释器)与webserver的通信，于是出现了cgi协议。只要你按照cgi协议去编写程序，就能实现语言解释器与webwerver的通信。如php-cgi程序。但是webserver每收到一个请求，都会去fork一个cgi进程，请求结束再kill掉这个进程。这样有10000个请求，就需要fork、kill php-cgi进程10000次。 fastcgi是cgi的改良版本。fast-cgi每次处理完请求后，不会kill掉这个进程，而是保留这个进程，使这个进程可以一次处理多个请求。大大提高了效率。 php-fpm安装12345678910111213# 安装yum -y remove php*yum install epel-release -yrpm -Uvh https://mirror.webtatic.com/yum/el7/webtatic-release.rpmyum -y install php72w php72w-cli php72w-fpm php72w-common php72w-devel php72w-embedded php72w-gd php72w-mbstring php72w-mysqlnd php72w-opcache php72w-pdo php72w-xml# 修改/etc/php-fpm.d/www.conf，解决访问403问题security.limit_extensions = .php .php3 .php4 .php5 .php7 .html .js .css .jpg .jpeg .gif .png .htm# 启动systemctl enable php-fpm.servicesystemctl start php-fpm.service nginx配置php1234567891011121314151617 server &#123; listen 86; server_name localhost; root /data/winbb; location / &#123; index index.php index.html index.htm; try_files $uri $uri/ /index.php?$args; &#125; #php 的单独写一个匹配location,这样让静态文件走location /&#123;&#125; location ~* \\.php &#123; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; &#125;&#125; 如上配置，当一个http请求到来时，被处理的过程如下： http请求到来后，通过server全局块里监听的端口号，匹配到相应server。然后接下来进行location路径的匹配。 首先匹配到location / ，在这个匹配规则中，通过try_files 先在root目录(/home/leimengyao/api/app/htdocs)下查找是否有$uri文件；没有匹配到，然后再查找root目录下是否有$uri/目录；同样没有匹配到，则匹配最后一项/index.php?$args，即发出一个”内部子请求”，也就相当于nginx发起了一个http请求到http://10.94.120.124:8000/index.php?c=1&amp;d=4 这个子请求会被location ~ .php${ … }catch住，也就是进入 FastCGI 的处理程序（nginx需要通过FastCGI模块配置，将相关php参数传递给php-fpm处理。在该项中设置了fastcgi_pass相关参数，将用户请求的资源发给php-fpm进行解析，这里涉及到nginx FastCGI模块的相关配置语法下文会介绍）。而具体的 URI 及参数是在 REQUEST_URI 中传递给 FastCGI 和 WordPress 程序的，因此不受 URI 变化的影响！！！！。","categories":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://hxqxiaoqi.gitee.io/tags/nginx/"}],"keywords":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}]},{"title":"k8s之存储","slug":"k8s之存储","date":"2020-06-04T01:06:00.000Z","updated":"2020-07-24T03:50:19.746Z","comments":true,"path":"2020/06/04/k8s之存储/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2020/06/04/k8s之存储/","excerpt":"","text":"介绍为了保证数据的持久性，必须保证数据在外部存储在docker容器中，为了实现数据的持久性存储，在宿主机和容器内做映射，可以保证在容器的生命周期结束，数据依旧可以实现持久性存储。但是在k8s中，由于*pod分布在各个不同的节点之上，并不能实现不同节点之间持久性数据的共享，并且，在节点故障时，可能会导致数据的永久性丢失。为此，k8s就引入了外部存储卷的功能。 k8s的存储卷类型： emptyDir（临时目录）:Pod删除，数据也会被清除，这种存储成为emptyDir，用于数据的临时存储。 hostPath (宿主机目录映射): 本地的SAN (iSCSI,FC)、NAS(nfs,cifs,http)存储 分布式存储（glusterfs，rbd，cephfs） 云存储（EBS，Azure Disk） k8s整体存储概念为：实际存储空间（nfs，hostpath…）—&gt; pv（抽象的存储卷，从实际的存储空间划分）—&gt; pvc（存储卷创建申请，从pv中划分定义）—&gt; pod（在创建pod中引用pvc进行挂在） 参考链接：https://www.cnblogs.com/linuxk/p/9760363.html emptyDir存储卷演示一个emptyDir 第一次创建是在一个pod被指定到具体node的时候，并且会一直存在在pod的生命周期当中，正如它的名字一样，它初始化是一个空的目录，pod中的容器都可以读写这个目录，这个目录可以被挂在到各个容器相同或者不相同的的路径下。当一个pod因为任何原因被移除的时候，这些数据会被永久删除。注意：一个容器崩溃了不会导致数据的丢失，因为容器的崩溃并不移除pod。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566[root@k8s-master ~]# kubectl explain pods.spec.volumes.emptyDir #查看emptyDir存储定义[root@k8s-master ~]# kubectl explain pods.spec.containers.volumeMounts #查看容器挂载方式[root@k8s-master ~]# cd mainfests &amp;&amp; mkdir volumes &amp;&amp; cd volumes[root@k8s-master volumes]# cp ../pod-demo.yaml ./[root@k8s-master volumes]# mv pod-demo.yaml pod-vol-demo.yaml[root@k8s-master volumes]# vim pod-vol-demo.yaml #创建emptyDir的清单apiVersion: v1kind: Podmetadata: name: pod-demo namespace: default labels: app: myapp tier: frontend annotations: magedu.com/create-by:\"cluster admin\"spec: containers: - name: myapp image: ikubernetes/myapp:v1 imagePullPolicy: IfNotPresent ports: - name: http containerPort: 80 volumeMounts: #在容器内定义挂载存储名称和挂载路径 - name: html mountPath: /usr/share/nginx/html/ - name: busybox image: busybox:latest imagePullPolicy: IfNotPresent volumeMounts: - name: html mountPath: /data/ #在容器内定义挂载存储名称和挂载路径 command: ['/bin/sh','-c','while true;do echo $(date) &gt;&gt; /data/index.html;sleep 2;done'] volumes: #定义存储卷 - name: html #定义存储卷名称 emptyDir: &#123;&#125; #定义存储卷类型 [root@k8s-master volumes]# kubectl apply -f pod-vol-demo.yaml pod/pod-vol-demo created [root@k8s-master volumes]# kubectl get podsNAME READY STATUS RESTARTS AGEpod-vol-demo 2/2 Running 0 27s[root@k8s-master volumes]# kubectl get pods -o wideNAME READY STATUS RESTARTS AGE IP NODE......pod-vol-demo 2/2 Running 0 16s 10.244.2.34 k8s-node02......# 在上面，我们定义了2个容器，其中一个容器是输入日期到index.html中，然后验证访问nginx的html是否可以获取日期。以验证两个容器之间挂载的emptyDir实现共享。如下访问验证:[root@k8s-master volumes]# curl 10.244.2.34 #访问验证Tue Oct 9 03:56:53 UTC 2018Tue Oct 9 03:56:55 UTC 2018Tue Oct 9 03:56:57 UTC 2018Tue Oct 9 03:56:59 UTC 2018Tue Oct 9 03:57:01 UTC 2018Tue Oct 9 03:57:03 UTC 2018Tue Oct 9 03:57:05 UTC 2018Tue Oct 9 03:57:07 UTC 2018Tue Oct 9 03:57:09 UTC 2018Tue Oct 9 03:57:11 UTC 2018Tue Oct 9 03:57:13 UTC 2018Tue Oct 9 03:57:15 UTC 2018 hostPath存储卷演示hostPath宿主机路径，就是把pod所在的宿主机之上的脱离pod中的容器名称空间的之外的宿主机的文件系统的某一目录和pod建立关联关系，在pod删除时，存储数据不会丢失。 1234567891011121314151617181920212223242526272829303132333435363738394041424344[root@k8s-master volumes]# vim pod-hostpath-vol.yamlapiVersion: v1kind: Podmetadata: name: pod-vol-hostpath namespace: defaultspec: containers: - name: myapp image: ikubernetes/myapp:v1 volumeMounts: - name: html mountPath: /usr/share/nginx/html volumes: - name: html hostPath: path: /data/pod/volume1 type: DirectoryOrCreate# DirectoryOrCreate 宿主机上不存在创建此目录 # Directory 必须存在挂载目录 # FileOrCreate 宿主机上不存在挂载文件就创建 # File 必须存在文件 [root@k8s-node01 ~]# mkdir -p /data/pod/volume1[root@k8s-node01 ~]# vim /data/pod/volume1/index.htmlnode01.magedu.com[root@k8s-node02 ~]# mkdir -p /data/pod/volume1[root@k8s-node02 ~]# vim /data/pod/volume1/index.htmlnode02.magedu.com[root@k8s-master volumes]# kubectl apply -f pod-hostpath-vol.yaml pod/pod-vol-hostpath created[root@k8s-master volumes]# kubectl get pods -o wideNAME READY STATUS RESTARTS AGE IP NODE......pod-vol-hostpath 1/1 Running 0 37s 10.244.2.35 k8s-node02......[root@k8s-master volumes]# curl 10.244.2.35node02.magedu.com[root@k8s-master volumes]# kubectl delete -f pod-hostpath-vol.yaml #删除pod，再重建，验证是否依旧可以访问原来的内容[root@k8s-master volumes]# kubectl apply -f pod-hostpath-vol.yaml pod/pod-vol-hostpath created[root@k8s-master volumes]# curl 10.244.2.37 node02.magedu.com nfs共享存储卷演示nfs使的我们可以挂在已经存在的共享到的我们的Pod中，和emptyDir不同的是，emptyDir会被删除当我们的Pod被删除的时候，但是nfs不会被删除，仅仅是解除挂在状态而已，这就意味着NFS能够允许我们提前对数据进行处理，而且这些数据可以在Pod之间相互传递.并且，nfs可以同时被多个pod挂在并进行读写。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354（1）在stor01节点上安装nfs，并配置nfs服务[root@stor01 ~]# yum install -y nfs-utils ==》192.168.56.14[root@stor01 ~]# mkdir /data/volumes -pv[root@stor01 ~]# vim /etc/exports/data/volumes 192.168.56.0/24(rw,no_root_squash)[root@stor01 ~]# systemctl start nfs[root@stor01 ~]# showmount -eExport list for stor01:/data/volumes 192.168.56.0/24（2）在node01和node02节点上安装nfs-utils，并测试挂载[root@k8s-node01 ~]# yum install -y nfs-utils[root@k8s-node02 ~]# yum install -y nfs-utils[root@k8s-node02 ~]# mount -t nfs stor01:/data/volumes /mnt[root@k8s-node02 ~]# mount......stor01:/data/volumes on /mnt type nfs4 (rw,relatime,vers=4.1,rsize=131072,wsize=131072,namlen=255,hard,proto=tcp,port=0,timeo=600,retrans=2,sec=sys,clientaddr=192.168.56.13,local_lock=none,addr=192.168.56.14)[root@k8s-node02 ~]# umount /mnt/（3）创建nfs存储卷的使用清单[root@k8s-master volumes]# cp pod-hostpath-vol.yaml pod-nfs-vol.yaml[root@k8s-master volumes]# vim pod-nfs-vol.yamlapiVersion: v1kind: Podmetadata: name: pod-vol-nfs namespace: defaultspec: containers: - name: myapp image: ikubernetes/myapp:v1 volumeMounts: - name: html mountPath: /usr/share/nginx/html volumes: - name: html nfs: path: /data/volumes server: stor01[root@k8s-master volumes]# kubectl apply -f pod-nfs-vol.yaml pod/pod-vol-nfs created[root@k8s-master volumes]# kubectl get pods -o wideNAME READY STATUS RESTARTS AGE IP NODEpod-vol-nfs 1/1 Running 0 21s 10.244.2.38 k8s-node02（3）在nfs服务器上创建index.html[root@stor01 ~]# cd /data/volumes[root@stor01 volumes ~]# vim index.html&lt;h1&gt; nfs stor01&lt;/h1&gt;[root@k8s-master volumes]# curl 10.244.2.38&lt;h1&gt; nfs stor01&lt;/h1&gt;[root@k8s-master volumes]# kubectl delete -f pod-nfs-vol.yaml #删除nfs相关pod，再重新创建，可以得到数据的持久化存储pod \"pod-vol-nfs\" deleted[root@k8s-master volumes]# kubectl apply -f pod-nfs-vol.yaml NFS使用PV和PVC1、配置nfs存储1234567891011121314151617181920[root@stor01 volumes]# mkdir v&#123;1,2,3,4,5&#125;[root@stor01 volumes]# vim /etc/exports/data/volumes/v1 192.168.56.0/24(rw,no_root_squash)/data/volumes/v2 192.168.56.0/24(rw,no_root_squash)/data/volumes/v3 192.168.56.0/24(rw,no_root_squash)/data/volumes/v4 192.168.56.0/24(rw,no_root_squash)/data/volumes/v5 192.168.56.0/24(rw,no_root_squash)[root@stor01 volumes]# exportfs -arvexporting 192.168.56.0/24:/data/volumes/v5exporting 192.168.56.0/24:/data/volumes/v4exporting 192.168.56.0/24:/data/volumes/v3exporting 192.168.56.0/24:/data/volumes/v2exporting 192.168.56.0/24:/data/volumes/v1[root@stor01 volumes]# showmount -eExport list for stor01:/data/volumes/v5 192.168.56.0/24/data/volumes/v4 192.168.56.0/24/data/volumes/v3 192.168.56.0/24/data/volumes/v2 192.168.56.0/24/data/volumes/v1 192.168.56.0/24 2、定义PV这里定义了pvc的访问模式为多路读写，该访问模式必须在前面pv定义的访问模式之中。定义PVC申请的大小为2Gi，此时PVC会自动去匹配多路读写且大小为2Gi的PV，匹配成功获取PVC的状态即为Bound 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889[root@k8s-master volumes]# kubectl explain pv[root@k8s-master volumes]# kubectl explain pv.spec.nfs[root@k8s-master volumes]# vim pv-demo.yamlapiVersion: v1kind: PersistentVolumemetadata: name: pv001 labels: name: pv001spec: nfs: path: /data/volumes/v1 server: stor01 accessModes: [\"ReadWriteMany\",\"ReadWriteOnce\"] #accessModes（定义访问模型，有以下三种访问模型，以列表的方式存在，也就是说可以定义多个访问模式） #ReadWriteOnce（RWO） 单节点读写 #ReadOnlyMany（ROX） 多节点只读 #ReadWriteMany（RWX） 多节点读写 capacity: storage: 1Gi---apiVersion: v1kind: PersistentVolumemetadata: name: pv002 labels: name: pv002spec: nfs: path: /data/volumes/v2 server: stor01 accessModes: [\"ReadWriteOnce\"] capacity: storage: 2Gi---apiVersion: v1kind: PersistentVolumemetadata: name: pv003 labels: name: pv003spec: nfs: path: /data/volumes/v3 server: stor01 accessModes: [\"ReadWriteMany\",\"ReadWriteOnce\"] capacity: storage: 2Gi---apiVersion: v1kind: PersistentVolumemetadata: name: pv004 labels: name: pv004spec: nfs: path: /data/volumes/v4 server: stor01 accessModes: [\"ReadWriteMany\",\"ReadWriteOnce\"] capacity: storage: 4Gi---apiVersion: v1kind: PersistentVolumemetadata: name: pv005 labels: name: pv005spec: nfs: path: /data/volumes/v5 server: stor01 accessModes: [\"ReadWriteMany\",\"ReadWriteOnce\"] capacity: storage: 5Gi[root@k8s-master volumes]# kubectl apply -f pv-demo.yaml persistentvolume/pv001 createdpersistentvolume/pv002 createdpersistentvolume/pv003 createdpersistentvolume/pv004 createdpersistentvolume/pv005 created[root@k8s-master volumes]# kubectl get pvNAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGEpv001 1Gi RWO,RWX Retain Available 7spv002 2Gi RWO Retain Available 7spv003 2Gi RWO,RWX Retain Available 7spv004 4Gi RWO,RWX Retain Available 7spv005 5Gi RWO,RWX Retain Available 7s 3、定义PVC这里定义了pvc的访问模式为多路读写，该访问模式必须在前面pv定义的访问模式之中。定义PVC申请的大小为2Gi，此时PVC会自动去匹配多路读写且大小为2Gi的PV，匹配成功获取PVC的状态即为Bound 1234567891011121314151617181920212223242526272829303132333435363738394041[root@k8s-master volumes ~]# vim pod-vol-pvc.yamlapiVersion: v1kind: PersistentVolumeClaimmetadata: name: mypvc namespace: defaultspec: accessModes: [\"ReadWriteMany\"] resources: requests: storage: 2Gi---apiVersion: v1kind: Podmetadata: name: pod-vol-pvc namespace: defaultspec: containers: - name: myapp image: ikubernetes/myapp:v1 volumeMounts: - name: html mountPath: /usr/share/nginx/html volumes: - name: html persistentVolumeClaim: claimName: mypvc[root@k8s-master volumes]# kubectl apply -f pod-vol-pvc.yaml persistentvolumeclaim/mypvc createdpod/pod-vol-pvc created[root@k8s-master volumes]# kubectl get pvNAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGEpv001 1Gi RWO,RWX Retain Available 19mpv002 2Gi RWO Retain Available 19mpv003 2Gi RWO,RWX Retain Bound default/mypvc 19mpv004 4Gi RWO,RWX Retain Available 19mpv005 5Gi RWO,RWX Retain Available 19m[root@k8s-master volumes]# kubectl get pvcNAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGEmypvc Bound pv003 2Gi RWO,RWX 22s 4、测试访问在存储服务器上创建index.html，并写入数据，通过访问Pod进行查看，可以获取到相应的页面。 123456[root@stor01 volumes]# cd v3/[root@stor01 v3]# echo \"welcome to use pv3\" &gt; index.html[root@k8s-master volumes]# kubectl get pods -o widepod-vol-pvc 1/1 Running 0 3m 10.244.2.39 k8s-node02[root@k8s-master volumes]# curl 10.244.2.39welcome to use pv3 StorageClass在pv和pvc使用过程中存在的问题，在pvc申请存储空间时，未必就有现成的pv符合pvc申请的需求，上面nfs在做pvc可以成功的因素是因为我们做了指定的需求处理。那么当PVC申请的存储空间不一定有满足PVC要求的PV事，又该如何处理呢？？？为此，Kubernetes为管理员提供了描述存储”class（类）”的方法（StorageClass）。举个例子，在存储系统中划分一个1TB的存储空间提供给Kubernetes使用，当用户需要一个10G的PVC时，会立即通过restful发送请求，从而让存储空间创建一个10G的image，之后在我们的集群中定义成10G的PV供给给当前的PVC作为挂载使用。在此之前我们的存储系统必须支持restful接口，比如ceph分布式存储，而glusterfs则需要借助第三方接口完成这样的请求。 StorageClass 中包含 provisioner、parameters 和 reclaimPolicy 字段，当 class 需要动态分配 PersistentVolume 时会使用到。由于StorageClass需要一个独立的存储系统，此处就不再演示。 配置容器应用：Secret和configMap在日常单机甚至集群状态下，我们需要对一个应用进行配置，只需要修改其配置文件即可。那么在容器中又该如何提供配置 信息呢？？？例如，为Nginx配置一个指定的server_name或worker进程数，为Tomcat的JVM配置其堆内存大小。传统的实践过程中通常有以下几种方式： 启动容器时，通过命令传递参数 将定义好的配置文件通过镜像文件进行写入 通过环境变量的方式传递配置数据 挂载Docker卷传送配置文件 而在Kubernetes系统之中也存在这样的组件，就是特殊的存储卷类型。其并不是提供pod存储空间，而是给管理员或用户提供从集群外部向Pod内部的应用注入配置信息的方式。这两种特殊类型的存储卷分别是：configMap和secret Secret：用于向Pod传递敏感信息，比如密码，私钥，证书文件等，这些信息如果在容器中定义容易泄露，Secret资源可以让用户将这些信息存储在急群众，然后通过Pod进行挂载，实现敏感数据和系统解耦的效果。 ConfigMap：主要用于向Pod注入非敏感数据，使用时，用户将数据直接存储在ConfigMap对象当中，然后Pod通过使用ConfigMap卷进行引用，实现容器的配置文件集中定义和管理。 Secret解析Secret对象存储数据的方式是以键值方式存储数据，在Pod资源进行调用Secret的方式是通过环境变量或者存储卷的方式进行访问数据，解决了密码、token、密钥等敏感数据的配置问题，而不需要把这些敏感数据暴露到镜像或者Pod Spec中。另外，Secret对象的数据存储和打印格式为Base64编码的字符串，因此用户在创建Secret对象时，也需要提供该类型的编码格式的数据。在容器中以环境变量或存储卷的方式访问时，会自动解码为明文格式。需要注意的是，如果是在Master节点上，Secret对象以非加密的格式存储在etcd中，所以需要对etcd的管理和权限进行严格控制。 Secret有4种类型： Service Account ：用来访问Kubernetes API，由Kubernetes自动创建，并且会自动挂载到Pod的/run/secrets/kubernetes.io/serviceaccount目录中； Opaque ：base64编码格式的Secret，用来存储密码、密钥、信息、证书等，类型标识符为generic； kubernetes.io/dockerconfigjson ：用来存储私有docker registry的认证信息，类型标识为docker-registry。 kubernetes.io/tls：用于为SSL通信模式存储证书和私钥文件，命令式创建类型标识为tls。 命令式创建 1、通过 –from-literal： 1234567891011121314151617181920[root@k8s-master ~]# kubectl create secret -hCreate a secret using specified subcommand.Available Commands: docker-registry Create a secret for use with a Docker registry generic Create a secret from a local file, directory or literal value tls Create a TLS secretUsage: kubectl create secret [flags] [options]Use \"kubectl &lt;command&gt; --help\" for more information about a given command.Use \"kubectl options\" for a list of global command-line options (applies to all commands).每个 --from-literal 对应一个信息条目。[root@k8s-master ~]# kubectl create secret generic mysecret --from-literal=username=admin --from-literal=password=123456secret/mysecret created[root@k8s-master ~]# kubectl get secretNAME TYPE DATA AGEmysecret Opaque 2 6s 2、通过 –from-file： 1234567[root@k8s-master ~]# echo -n admin &gt; ./username[root@k8s-master ~]# echo -n 123456 &gt; ./password[root@k8s-master ~]# kubectl create secret generic mysecret --from-file=./username --from-file=./password secret/mysecret created[root@k8s-master ~]# kubectl get secretNAME TYPE DATA AGEmysecret Opaque 2 6s 3、通过 –from-env-file： 123456789[root@k8s-master ~]# cat &lt;&lt; EOF &gt; env.txt&gt; username=admin&gt; password=123456&gt; EOF[root@k8s-master ~]# kubectl create secret generic mysecret --from-env-file=env.txt secret/mysecret created[root@k8s-master ~]# kubectl get secretNAME TYPE DATA AGEmysecret Opaque 2 10s 清单式创建 通过 YAML 配置文件： 123456789101112131415161718192021222324252627282930313233343536373839404142#事先完成敏感数据的Base64编码[root@k8s-master ~]# echo -n admin |base64YWRtaW4=[root@k8s-master ~]# echo -n 123456 |base64MTIzNDU2[root@k8s-master ~]# vim secret.yamlapiVersion: v1kind: Secretmetadata: name: mysecretdata: username: YWRtaW4= password: MTIzNDU2[root@k8s-master ~]# kubectl apply -f secret.yaml secret/mysecret created[root@k8s-master ~]# kubectl get secret #查看存在的 secret，显示有2条数据NAME TYPE DATA AGEmysecret Opaque 2 8s[root@k8s-master ~]# kubectl describe secret mysecret #查看数据的 KeyName: mysecretNamespace: defaultLabels: &lt;none&gt;Annotations: Type: OpaqueData====username: 5 bytespassword: 6 bytes[root@k8s-master ~]# kubectl edit secret mysecret #查看具体的value，可以使用该命令apiVersion: v1data: password: MTIzNDU2 username: YWRtaW4=kind: Secretmetadata:......[root@k8s-master ~]# echo -n MTIzNDU2 |base64 --decode #通过 base64 将 Value 反编码：123456[root@k8s-master ~]# echo -n YWRtaW4= |base64 --decodeadmin 使用Secret Pod 可以通过 Volume 或者环境变量的方式使用 Secret 1234567891011121314151617181920212223242526272829303132[root@k8s-master volumes]# vim pod-secret-demo.yamlapiVersion: v1kind: Podmetadata: name: pod-secretspec: containers: - name: pod-secret image: busybox args: - /bin/sh - -c - sleep 10;touch /tmp/healthy;sleep 30000 volumeMounts: #将 foo mount 到容器路径 /etc/foo，可指定读写权限为 readOnly。 - name: foo mountPath: \"/etc/foo\" readOnly: true volumes: #定义 volume foo，来源为 secret mysecret。 - name: foo secret: secretName: mysecret[root@k8s-master volumes]# kubectl apply -f pod-secret-demo.yaml pod/pod-secret created[root@k8s-master volumes]# kubectl get podspod-secret 1/1 Running 0 1m[root@k8s-master volumes]# kubectl exec -it pod-secret sh/ # ls /etc/foo/password username/ # cat /etc/foo/username admin/ # / # cat /etc/foo/password 123456/ # 可以看到，Kubernetes 会在指定的路径 /etc/foo 下为每条敏感数据创建一个文件，文件名就是数据条目的 Key，这里是 /etc/foo/username 和 /etc/foo/password，Value 则以明文存放在文件中。也可以自定义存放数据的文件名，比如将配置文件改为： 1234567891011121314151617181920212223242526272829303132333435[root@k8s-master volumes]# cat pod-secret-demo.yaml apiVersion: v1kind: Podmetadata: name: pod-secretspec: containers: - name: pod-secret image: busybox args: - /bin/sh - -c - sleep 10;touch /tmp/healthy;sleep 30000 volumeMounts: - name: foo mountPath: \"/etc/foo\" readOnly: true volumes: - name: foo secret: secretName: mysecret items: #自定义存放数据的文件名 - key: username path: my-secret/my-username - key: password path: my-secret/my-password[root@k8s-master volumes]# kubectl delete pods pod-secretpod \"pod-secret\" deleted[root@k8s-master volumes]# kubectl apply -f pod-secret-demo.yaml pod/pod-secret created[root@k8s-master volumes]# kubectl exec -it pod-secret sh/ # cat /etc/foo/my-secret/my-username admin/ # cat /etc/foo/my-secret/my-password 123456 这时数据将分别存放在 /etc/foo/my-secret/my-username 和 /etc/foo/my-secret/my-password 中。 以 Volume 方式使用的 Secret 支持动态更新：Secret 更新后，容器中的数据也会更新。 将 password 更新为 abcdef，base64 编码为 YWJjZGVm 123456789101112[root@k8s-master ~]# vim secret.yaml apiVersion: v1kind: Secretmetadata: name: mysecretdata: username: YWRtaW4= password: YWJjZGVm[root@k8s-master ~]# kubectl apply -f secret.yaml secret/mysecret configured/ # cat /etc/foo/my-secret/my-password abcdef 通过 Volume 使用 Secret，容器必须从文件读取数据，会稍显麻烦，Kubernetes 还支持通过环境变量使用 Secret。 123456789101112131415161718192021222324252627282930313233[root@k8s-master volumes]# cp pod-secret-demo.yaml pod-secret-env-demo.yaml[root@k8s-master volumes]# vim pod-secret-env-demo.yaml apiVersion: v1kind: Podmetadata: name: pod-secret-envspec: containers: - name: pod-secret-env image: busybox args: - /bin/sh - -c - sleep 10;touch /tmp/healthy;sleep 30000 env: - name: SECRET_USERNAME valueFrom: secretKeyRef: name: mysecret key: username - name: SECRET_PASSWORD valueFrom: secretKeyRef: name: mysecret key: password[root@k8s-master volumes]# kubectl apply -f pod-secret-env-demo.yaml pod/pod-secret-env created[root@k8s-master volumes]# kubectl exec -it pod-secret-env sh/ # echo $SECRET_USERNAMEadmin/ # echo $SECRET_PASSWORDabcdef 通过环境变量 SECRET_USERNAME 和 SECRET_PASSWORD 成功读取到 Secret 的数据。需要注意的是，环境变量读取 Secret 很方便，但无法支撑 Secret 动态更新。Secret 可以为 Pod 提供密码、Token、私钥等敏感数据；对于一些非敏感数据，比如应用的配置信息，则可以用 ConfigMap。 ConifgMap解析configmap是让配置文件从镜像中解耦，让镜像的可移植性和可复制性。许多应用程序会从配置文件、命令行参数或环境变量中读取配置信息。这些配置信息需要与docker image解耦，你总不能每修改一个配置就重做一个image吧？ConfigMap API给我们提供了向容器中注入配置信息的机制，ConfigMap可以被用来保存单个属性，也可以用来保存整个配置文件或者JSON二进制大对象。 ConfigMap API资源用来保存key-value pair配置数据，这个数据可以在pods里使用，或者被用来为像controller一样的系统组件存储配置数据。虽然ConfigMap跟Secrets类似，但是ConfigMap更方便的处理不含敏感信息的字符串。 注意：ConfigMaps不是属性配置文件的替代品。ConfigMaps只是作为多个properties文件的引用。可以把它理解为Linux系统中的/etc目录，专门用来存储配置文件的目录。下面举个例子，使用ConfigMap配置来创建Kuberntes Volumes，ConfigMap中的每个data项都会成为一个新文件。 ConfigMap创建方式 与 Secret 一样，ConfigMap 也支持四种创建方式： 1、 通过 –from-literal：每个 –from-literal 对应一个信息条目。 1234567891011121314151617181920[root@k8s-master volumes]# kubectl create configmap nginx-config --from-literal=nginx_port=80 --from-literal=server_name=myapp.magedu.comconfigmap/nginx-config created[root@k8s-master volumes]# kubectl get cmNAME DATA AGEnginx-config 2 6s[root@k8s-master volumes]# kubectl describe cm nginx-configName: nginx-configNamespace: defaultLabels: &lt;none&gt;Annotations: &lt;none&gt;Data====server_name:----myapp.magedu.comnginx_port:----80Events: &lt;none&gt; 2、通过 –from-file：每个文件内容对应一个信息条目。 12345678910111213141516171819202122232425[root@k8s-master mainfests]# mkdir configmap &amp;&amp; cd configmap[root@k8s-master configmap]# vim www.confserver &#123; server_name myapp.magedu.com; listen 80; root /data/web/html;&#125;[root@k8s-master configmap]# kubectl create configmap nginx-www --from-file=./www.conf configmap/nginx-www created[root@k8s-master configmap]# kubectl get cmNAME DATA AGEnginx-config 2 3mnginx-www 1 4s[root@k8s-master configmap]# kubectl get cm nginx-www -o yamlapiVersion: v1data: www.conf: \"server &#123;\\n\\tserver_name myapp.magedu.com;\\n\\tlisten 80;\\n\\troot /data/web/html;\\n&#125;\\n\"kind: ConfigMapmetadata: creationTimestamp: 2018-10-10T08:50:06Z name: nginx-www namespace: default resourceVersion: \"389929\" selfLink: /api/v1/namespaces/default/configmaps/nginx-www uid: 7c3dfc35-cc69-11e8-801a-000c2972dc1f 使用configMap 1、环境变量方式注入到pod 123456789101112131415161718192021222324252627282930313233343536[root@k8s-master configmap]# vim pod-configmap.yamlapiVersion: v1kind: Podmetadata: name: pod-cm-1 namespace: default labels: app: myapp tier: frontend annotations: magedu.com/created-by: \"cluster admin\"spec: containers: - name: myapp image: ikubernetes/myapp:v1 ports: - name: http containerPort: 80 env: - name: NGINX_SERVER_PORT valueFrom: configMapKeyRef: name: nginx-config key: nginx_port - name: NGINX_SERVER_NAME valueFrom: configMapKeyRef: name: nginx-config key: server_name[root@k8s-master configmap]# kubectl apply -f pod-configmap.yaml pod/pod-cm-1 created[root@k8s-master configmap]# kubectl exec -it pod-cm-1 -- /bin/sh/ # echo $NGINX_SERVER_PORT80/ # echo $NGINX_SERVER_NAMEmyapp.magedu.com 修改端口，可以发现使用环境变化注入pod中的端口不会根据配置的更改而变化 1234[root@k8s-master volumes]# kubectl edit cm nginx-configconfigmap/nginx-config edited/ # echo $NGINX_SERVER_PORT80 2、存储卷方式挂载configmap：Volume 形式的 ConfigMap 也支持动态更新 123456789101112131415161718192021222324252627282930313233343536373839404142434445[root@k8s-master configmap ~]# vim pod-configmap-2.yamlapiVersion: v1kind: Podmetadata: name: pod-cm-2 namespace: default labels: app: myapp tier: frontend annotations: magedu.com/created-by: \"cluster admin\"spec: containers: - name: myapp image: ikubernetes/myapp:v1 ports: - name: http containerPort: 80 volumeMounts: - name: nginxconf mountPath: /etc/nginx/config.d/ readOnly: true volumes: - name: nginxconf configMap: name: nginx-config[root@k8s-master configmap ~]# kubectl apply -f pod-configmap-2.yamlpod/pod-cm-2 created[root@k8s-master configmap ~]# kubectl get pods[root@k8s-master configmap ~]# kubectl exec -it pod-cm-2 -- /bin/sh/ # cd /etc/nginx/config.d/ # cat nginx_port80/ # cat server_name myapp.magedu.com[root@k8s-master configmap ~]# kubectl edit cm nginx-config #修改端口，再在容器中查看端口是否变化。apiVersion: v1data: nginx_port: \"800\" ...... / # cat nginx_port800[root@k8s-master configmap ~]# kubectl delete -f pod-configmap2.yaml 3、以nginx-www配置nginx 123456789101112131415161718192021222324252627282930313233343536373839[root@k8s-master configmap ~]# vim pod-configmap3.yamlapiVersion: v1kind: Podmetadata: name: pod-cm-3 namespace: default labels: app: myapp tier: frontend annotations: magedu.com/created-by: \"cluster admin\"spec: containers: - name: myapp image: ikubernetes/myapp:v1 ports: - name: http containerPort: 80 volumeMounts: - name: nginxconf mountPath: /etc/nginx/conf.d/ readOnly: true volumes: - name: nginxconf configMap: name: nginx-www[root@k8s-master configmap ~]# kubectl apply -f pod-configmap3.yamlpod/pod-cm-3 created[root@k8s-master configmap ~]# kubectl get pods[root@k8s-master configmap]# kubectl exec -it pod-cm-3 -- /bin/sh/ # cd /etc/nginx/conf.d//etc/nginx/conf.d # lswww.conf/etc/nginx/conf.d # cat www.conf server &#123; server_name myapp.magedu.com; listen 80; root /data/web/html;&#125;","categories":[{"name":"kubernetes","slug":"kubernetes","permalink":"https://hxqxiaoqi.gitee.io/categories/kubernetes/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://hxqxiaoqi.gitee.io/tags/k8s/"}],"keywords":[{"name":"kubernetes","slug":"kubernetes","permalink":"https://hxqxiaoqi.gitee.io/categories/kubernetes/"}]},{"title":"k8s之pod控制器","slug":"k8s之pod控制器","date":"2020-05-26T07:06:00.000Z","updated":"2020-07-24T03:50:58.280Z","comments":true,"path":"2020/05/26/k8s之pod控制器/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2020/05/26/k8s之pod控制器/","excerpt":"","text":"介绍Pod控制器是用于实现管理pod的中间层，确保pod资源符合预期的状态，pod的资源出现故障时，会尝试 进行重启，当根据重启策略无效，则会重新新建pod的资源。 pod控制器有多种类型： ReplicaSet：代用户创建指定数量的pod副本数量，确保pod副本数量符合预期状态，并且支持滚动式自动扩容和缩容功能。主要用于配合Deployment控制器使用。 Deployment：工作在ReplicaSet之上，用于管理无状态应用，目前来说最好的控制器。支持滚动更新和回滚功能，还提供声明式配置。 DaemonSet：用于确保集群中的每一个节点只运行特定的pod副本，通常用于实现系统级后台任务。比如ELK服务 StatefulSet：管理有状态应用 Deployment功能： （1）使用Deployment来创建ReplicaSet。ReplicaSet在后台创建pod。检查启动状态，看它是成功还是失败。 （2）然后，通过更新Deployment的PodTemplateSpec字段来声明Pod的新状态。这会创建一个新的ReplicaSet，Deployment会按照控制的速率将pod从旧的ReplicaSet移动到新的ReplicaSet中。 （3）如果当前状态不稳定，回滚到之前的Deployment revision。每次回滚都会更新Deployment的revision。 （4）扩容Deployment以满足更高的负载。 （5）暂停Deployment来应用PodTemplateSpec的多个修复，然后恢复上线。 （6）根据Deployment 的状态判断上线是否hang住了。 （7）清除旧的不必要的 ReplicaSet。 123456789101112131415161718192021apiVersion: apps/v1 #api版本定义kind: Deployment #定义资源类型为Deploymentmetadata: #元数据定义 name: myapp #Deployment名称 namespace: default #应用的名称空间spec: #Deployment的规格定义 replicas: 2 #定义副本数量为2个 selector: #标签选择器，定义匹配pod的标签 matchLabels: app: myapp template: #pod的模板定义 metadata: #pod的元数据定义 labels: #定义pod的标签，需要和上面定义的标签一致，也可以多出其他标签 app: myapp spec: #pod的规格定义 containers: #容器定义 - name: myapp-container #容器名称 image: ikubernetes/myapp:v1 #容器镜像 ports: #暴露端口 - name: http containerPort: 80 DaemonSetDaemonSet 确保全部（或者一些）Node 上运行一个 Pod 的副本。当有 Node 加入集群时，也会为他们新增一个 Pod 。当有 Node 从集群移除时，这些 Pod 也会被回收。删除 DaemonSet 将会删除它创建的所有 Pod。 1234567891011121314151617181920212223242526kind: DaemonSetapiVersion: apps/v1metadata: labels: app: node-exporter name: node-exporter namespace: ns-monitorspec: revisionHistoryLimit: 10 selector: matchLabels: app: node-exporter template: metadata: labels: app: node-exporter spec: containers: - name: node-exporter image: prom/node-exporter:v0.16.0 ports: - containerPort: 9100 protocol: TCP name: http hostNetwork: true hostPID: true StatefulSet一个完整的StatefulSet控制器由一个Headless Service、一个StatefulSet和一个volumeClaimTemplate组成。如下资源清单中的定义： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748apiVersion: v1kind: Servicemetadata: name: nginx labels: app: nginxspec: ports: - port: 80 name: web clusterIP: None # 集群设置None就是headless service 无头服务 selector: app: nginx---apiVersion: apps/v1kind: StatefulSetmetadata: name: webspec: selector: matchLabels: app: nginx # 必须设置项 serviceName: \"nginx\" #声明它属于哪个Headless Service. replicas: 3 # 默认1 template: metadata: labels: app: nginx # 必须设置项 spec: terminationGracePeriodSeconds: 10 containers: - name: nginx image: nginx ports: - containerPort: 80 name: web volumeMounts: - name: www mountPath: /usr/share/nginx/html volumeClaimTemplates: #可看作pvc的模板 - metadata: name: www spec: accessModes: [ \"ReadWriteOnce\" ] storageClassName: \"gluster-heketi\" #存储类名，改为集群中已存在的 resources: requests: storage: 1Gi Headless Service：名为nginx，用来定义Pod网络标识( DNS domain)。 StatefulSet：定义具体应用，名为Nginx，有三个Pod副本，并为每个Pod定义了一个域名。 volumeClaimTemplates： 存储卷申请模板，创建PVC，指定pvc名称大小，将自动创建pvc，且pvc必须由存储类供应。 为什么需要 headless service 无头服务？在用Deployment时，每一个Pod名称是没有顺序的，是随机字符串，因此是Pod名称是无序的，但是在statefulset中要求必须是有序 ，每一个pod不能被随意取代，pod重建后pod名称还是一样的。而pod IP是变化的，所以是以Pod名称来识别。pod名称是pod唯一性的标识符，必须持久稳定有效。这时候要用到无头服务，它可以给每个Pod一个唯一的名称 。 为什么需要volumeClaimTemplate？对于有状态的副本集都会用到持久存储，对于分布式系统来讲，它的最大特点是数据是不一样的，所以各个节点不能使用同一存储卷，每个节点有自已的专用存储，但是如果在Deployment中的Pod template里定义的存储卷，是所有副本集共用一个存储卷，数据是相同的，因为是基于模板来的 ，而statefulset中每个Pod都要自已的专有存储卷，所以statefulset的存储卷就不能再用Pod模板来创建了，于是statefulSet使用volumeClaimTemplate，称为卷申请模板，它会为每个Pod生成不同的pvc，并绑定pv， 从而实现各pod有专用存储。这就是为什么要用volumeClaimTemplate的原因。","categories":[{"name":"kubernetes","slug":"kubernetes","permalink":"https://hxqxiaoqi.gitee.io/categories/kubernetes/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://hxqxiaoqi.gitee.io/tags/k8s/"}],"keywords":[{"name":"kubernetes","slug":"kubernetes","permalink":"https://hxqxiaoqi.gitee.io/categories/kubernetes/"}]},{"title":"k8s之yaml详解","slug":"k8s之yaml详解","date":"2020-05-25T07:06:00.000Z","updated":"2020-07-24T03:49:59.981Z","comments":true,"path":"2020/05/25/k8s之yaml详解/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2020/05/25/k8s之yaml详解/","excerpt":"","text":"配置介绍使用yaml格式创建服务，更容易管理 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103apiVersion: extensions/v1beta1 #接口版本kind: Deployment #接口类型metadata: name: cango-demo #Deployment名称 namespace: cango-prd #命名空间 labels: app: cango-demo #标签spec: replicas: 3 strategy: rollingUpdate: ##由于replicas为3,则整个升级,pod个数在2-4个之间 maxSurge: 1 #滚动升级时会先启动1个pod maxUnavailable: 1 #滚动升级时允许的最大Unavailable的pod个数 template: metadata: labels: app: cango-demo #模板名称必填 sepc: #定义容器模板，该模板可以包含多个容器 containers: - name: cango-demo #镜像名称 image: swr.cn-east-2.myhuaweicloud.com/cango-prd/cango-demo:0.0.1-SNAPSHOT #镜像地址 command: [ \"/bin/sh\",\"-c\",\"cat /etc/config/path/to/special-key\" ] #启动命令 args: #启动参数 - '-storage.local.retention=$(STORAGE_RETENTION)' - '-storage.local.memory-chunks=$(STORAGE_MEMORY_CHUNKS)' - '-config.file=/etc/prometheus/prometheus.yml' - '-alertmanager.url=http://alertmanager:9093/alertmanager' - '-web.external-url=$(EXTERNAL_URL)' #如果command和args均没有写，那么用Docker默认的配置。 #如果command写了，但args没有写，那么Docker默认的配置会被忽略而且仅仅执行.yaml文件的command（不带任何参数的）。 #如果command没写，但args写了，那么Docker默认配置的ENTRYPOINT的命令行会被执行，但是调用的参数是.yaml中的args。 #如果如果command和args都写了，那么Docker默认的配置被忽略，使用.yaml的配置。 imagePullPolicy: IfNotPresent #如果不存在则拉取 livenessProbe: #表示container是否处于live状态。如果LivenessProbe失败，LivenessProbe将会通知kubelet对应的container不健康了。随后kubelet将kill掉container，并根据RestarPolicy进行进一步的操作。默认情况下LivenessProbe在第一次检测之前初始化值为Success，如果container没有提供LivenessProbe，则也认为是Success； httpGet: path: /health #如果没有心跳检测接口就为/ port: 8080 scheme: HTTP initialDelaySeconds: 60 ##启动后延时多久开始运行检测 timeoutSeconds: 5 successThreshold: 1 failureThreshold: 5 readinessProbe: readinessProbe: httpGet: path: /health #如果没有心跳检测接口就为/ port: 8080 scheme: HTTP initialDelaySeconds: 30 ##启动后延时多久开始运行检测 timeoutSeconds: 5 successThreshold: 1 failureThreshold: 5 resources: ##CPU内存限制 requests: cpu: 2 memory: 2048Mi limits: cpu: 2 memory: 2048Mi env: ##通过环境变量的方式，直接传递pod=自定义Linux OS环境变量 - name: LOCAL_KEY #本地Key value: value - name: CONFIG_MAP_KEY #局策略可使用configMap的配置Key， valueFrom: configMapKeyRef: name: special-config #configmap中找到name为special-config key: special.type #找到name为special-config里data下的key ports: - name: http containerPort: 8080 #对service暴露端口 volumeMounts: #挂载volumes中定义的磁盘 - name: log-cache mount: /tmp/log - name: sdb #普通用法，该卷跟随容器销毁，挂载一个目录 mountPath: /data/media - name: nfs-client-root #直接挂载硬盘方法，如挂载下面的nfs目录到/mnt/nfs mountPath: /mnt/nfs - name: example-volume-config #高级用法第1种，将ConfigMap的log-script,backup-script分别挂载到/etc/config目录下的一个相对路径path/to/...下，如果存在同名文件，直接覆盖。 mountPath: /etc/config - name: rbd-pvc #高级用法第2中，挂载PVC(PresistentVolumeClaim)#使用volume将ConfigMap作为文件或目录直接挂载，其中每一个key-value键值对都会生成一个文件，key为文件名，value为内容， volumes: # 定义磁盘给上面volumeMounts挂载 - name: log-cache emptyDir: &#123;&#125; - name: sdb #挂载宿主机上面的目录 hostPath: path: /any/path/it/will/be/replaced - name: example-volume-config # 供ConfigMap文件内容到指定路径使用 configMap: name: example-volume-config #ConfigMap中名称 items: - key: log-script #ConfigMap中的Key path: path/to/log-script #指定目录下的一个相对路径path/to/log-script - key: backup-script #ConfigMap中的Key path: path/to/backup-script #指定目录下的一个相对路径path/to/backup-script - name: nfs-client-root #供挂载NFS存储类型 nfs: server: 10.42.0.55 #NFS服务器地址 path: /opt/public #showmount -e 看一下路径 - name: rbd-pvc #挂载PVC磁盘 persistentVolumeClaim: claimName: rbd-pvc1 #挂载已经申请的pvc磁盘 nginx安装例子创建 deployment 1234567891011121314151617181920212223242526272829apiVersion: apps/v1#指定的对象名称kind: Deploymentmetadata: name: nginx-deployment namespace: default labels: web: nginx123spec:#副本数 replicas: 3#选择器 selector:#匹配标签：app: nginx matchLabels: app: nginx#创建具体的pod template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.12 ports: - containerPort: 80 创建 service 1234567891011121314apiVersion: v1kind: Servicemetadata: name: nginx-service namespace: default#标签要跟nginx-deployment中对应上 labels: app: nginxspec: ports: - port: 89 targetPort: 80 selector: app: nginx 常用命令12345678# 使用yaml文件创建，create创建，需要使用replace更新kubectl create -f nginx_service.yaml# apply创建，直接执行即更新kubectl apply -f nginx_service.yaml# 删除配置kubectl delete -f nginx_service.yaml","categories":[{"name":"kubernetes","slug":"kubernetes","permalink":"https://hxqxiaoqi.gitee.io/categories/kubernetes/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://hxqxiaoqi.gitee.io/tags/k8s/"}],"keywords":[{"name":"kubernetes","slug":"kubernetes","permalink":"https://hxqxiaoqi.gitee.io/categories/kubernetes/"}]},{"title":"k8s之内存和cpu配置","slug":"k8s之内存和cpu配置","date":"2020-05-25T07:06:00.000Z","updated":"2020-07-24T03:50:10.424Z","comments":true,"path":"2020/05/25/k8s之内存和cpu配置/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2020/05/25/k8s之内存和cpu配置/","excerpt":"","text":"介绍资源请求（requests）：即允许运行的最小资源，pod调度规则根据该值判断。 资源限制（limits）：即允许运行的最大资源，limits不会影响pod调度规则，因此limits总和可以超过服务器提供的总资源数，服务运行超过该值会被kill重启。 另外：k8s仅会确保pod能够获得他们请求的cpu时间额度，他们能否获得额外的cpu时间，则取决于其他正在运行的作业对cpu资源的占用情况。例如，对于总数为1000m的cpu来说，容器a请求使用200m，容器b请求使用500m，在不超出它们各自的最大限额的前提下，余下的300m在双方都需要时会以2:5的方式进行配置。（限制cpu是限制其运行占用cpu时间） 名称空间资源配置设置名称空间namespaces默认资源 名称空间设置是应用到名称空间下所有未定义资源配置的pod中，如果pod单独定义资源配置，则优先使用pod定义的配置。 12345678# 查看名称空间kubectl get ns# 创建名称空间 defaultkubectl create namespace default# 查看名称空间资源配置信息kubectl describe namespaces default 创建 limit-default.yaml：编辑以下内容 12345678910111213apiVersion: v1kind: LimitRangemetadata: name: limit-rangespec: limits: - default: cpu: 0.25 memory: 2048Mi defaultRequest: cpu: 0.1 memory: 128Mi type: Container 更新配置 12345678# 应用配置kubectl create -f limit-default.yaml --namespace=default# 如果配置还有更改，使用以下命令更新kubectl replace -f limit-default.yaml --namespace=default# 查看名称空间限制kubectl describe namespaces default pod资源配置pod资源配置有deployment 控制器定义的 12345# 查看 deployment 控制器kubectl get deployment# 修改 deployment 控制器kubectl edit deployment nginx-deployment 以下为修改内容 12345678910111213141516spec: containers: - image: nginx:1.16 imagePullPolicy: IfNotPresent lifecycle: &#123;&#125; name: nginx ports: - containerPort: 80 protocol: TCP resources: limits: cpu: 500m memory: 500Mi requests: cpu: 100m memory: 128Mi 查看pod修改后的配置 1kubectl get pod nginx-deployment-79788f59b6-nfvst --output=yaml --namespace=default 查看pod所在node节点资源配置 1kubectl describe node node01 资源配置详解配置示例 1234567891011121314151617181920212223242526272829303132apiVersion: v1kind: LimitRangemetadata: name: mylimitsspec: limits: - max: cpu: \"4\" memory: 2Gi min: cpu: 200m memory: 6Mi maxLimitRequestRatio: cpu: 3 memory: 2 type: Pod - default: cpu: 300m memory: 200Mi defaultRequest: cpu: 200m memory: 100Mi max: cpu: \"2\" memory: 1Gi min: cpu: 100m memory: 3Mi maxLimitRequestRatio: cpu: 5 memory: 4 type: Container pod部分： max表示pod中所有容器资源的Limit值和的上限，也就是整个pod资源的最大Limit，如果pod定义中的Limit值大于LimitRange中的值，则pod无法成功创建。 min表示pod中所有容器资源请求总和的下限，也就是所有容器request的资源总和不能小于min中的值，否则pod无法成功创建。 maxLimitRequestRatio表示pod中所有容器资源请求的Limit值和request值比值的上限，例如该pod中cpu的Limit值为3，而request为0.5，此时比值为6，创建pod将会失败。 container部分 在container的部分，max、min和maxLimitRequestRatio的含义和pod中的类似，只不过是针对单个的容器而言。下面说明几个情况： 如果container设置了max， pod中的容器必须设置limit，如果未设置，则使用defaultlimt的值，如果defaultlimit也没有设置，则无法成功创建 如果设置了container的min，创建容器的时候必须设置request的值，如果没有设置，则使用defaultrequest，如果没有defaultrequest，则默认等于容器的limit值，如果limit也没有，启动就会报错 defaultrequest和defaultlimit则是默认值，注意：pod级别没有这两项设置","categories":[{"name":"kubernetes","slug":"kubernetes","permalink":"https://hxqxiaoqi.gitee.io/categories/kubernetes/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://hxqxiaoqi.gitee.io/tags/k8s/"}],"keywords":[{"name":"kubernetes","slug":"kubernetes","permalink":"https://hxqxiaoqi.gitee.io/categories/kubernetes/"}]},{"title":"k8s之权限管理","slug":"k8s之权限管理","date":"2020-05-24T07:06:00.000Z","updated":"2020-07-24T03:50:16.585Z","comments":true,"path":"2020/05/24/k8s之权限管理/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2020/05/24/k8s之权限管理/","excerpt":"","text":"https://www.orchome.com/1308","categories":[{"name":"kubernetes","slug":"kubernetes","permalink":"https://hxqxiaoqi.gitee.io/categories/kubernetes/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://hxqxiaoqi.gitee.io/tags/k8s/"}],"keywords":[{"name":"kubernetes","slug":"kubernetes","permalink":"https://hxqxiaoqi.gitee.io/categories/kubernetes/"}]},{"title":"k8s之更新回滚","slug":"k8s之更新回滚","date":"2020-05-24T06:06:00.000Z","updated":"2020-07-24T03:50:07.398Z","comments":true,"path":"2020/05/24/k8s之更新回滚/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2020/05/24/k8s之更新回滚/","excerpt":"","text":"介绍记录k8s的更新操作 更新的三种方式： kubectl edit 修改配置 kubectl set image 修改镜像版本（只介绍该方法） kubectl patch 修改配置 更新回滚以一个简单的deployment为例来进行说明： 12345678910111213141516171819202122apiVersion: apps/v1kind: Deploymentmetadata: name: nginx-deployment labels: app: nginxspec: replicas: 2 revisionHistoryLimit: 10 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.12 ports: - containerPort: 80 创建deployment 12# --record：记录版本，没有该参数无法回滚kubectl apply -f nginx-deployment.yaml --record 更新与回滚 只有spec.template.spec.containers.image或者spec.template.metadata.labels发生变化时才会出发更新rolout操作 1234567891011121314151617181920# 更新镜像版本kubectl set image deployment nginx-deployment nginx=nginx:1.14 --record# 查看已有版本，数字最大的为当前使用镜像kubectl rollout history deployment nginx-deployment# 回滚上一个版本 kubectl rollout undo deployment nginx-deployment# 回滚到指定版本kubectl rollout undo deployment nginx-deployment --to-revision=2#查看升级状态kubectl rollout status deploy nginx #升级暂停kubectl rollout pause deployment nginx #恢复升级kubectl rollout resume deployment nginx","categories":[{"name":"kubernetes","slug":"kubernetes","permalink":"https://hxqxiaoqi.gitee.io/categories/kubernetes/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://hxqxiaoqi.gitee.io/tags/k8s/"}],"keywords":[{"name":"kubernetes","slug":"kubernetes","permalink":"https://hxqxiaoqi.gitee.io/categories/kubernetes/"}]},{"title":"k8s安装之sealos","slug":"k8s安装之sealos","date":"2020-05-22T08:00:00.000Z","updated":"2020-07-24T03:50:23.991Z","comments":true,"path":"2020/05/22/k8s安装之sealos/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2020/05/22/k8s安装之sealos/","excerpt":"","text":"介绍极其方便的k8s安装方式 参考资料： github地址：https://github.com/fanux/sealos Kuboard：https://kuboard.cn/install/install-dashboard.html 安装虚拟机环境 主机名 IP地址 系统 etc01 192.168.10.121 centos7.6 etc02 192.168.10.122 centos7.6 etc03 192.168.10.123 centos7.6 node01 192.168.10.124 centos7.6 node02 192.168.10.125 centos7.6 安装环境 每台虚拟机执行以下脚本，简单的系统优化，也可以不需要执行 12345678910111213141516171819202122232425262728293031# CentOS-7.6rm -rf /etc/yum.repos.d/*curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.163.com/.help/CentOS7-Base-163.repoyum clean all &amp;&amp; yum makecacheecho \"export PS1='\\[\\e[1;32m\\][\\u@\\h \\W]\\\\$ \\[\\e[0m\\]'\" &gt;&gt; /etc/bashrcecho \"export TIME_STYLE='+%Y-%m-%d %H:%M:%S'\" &gt;&gt; /etc/bashrcecho \"export HISTTIMEFORMAT='%F %T '\" &gt;&gt; /etc/profilesed -i \"s/^#UseDNS.*/UseDNS no/g\" /etc/ssh/sshd_configsed -i \"s/SELINUX=.*/SELINUX=disabled/g\" /etc/selinux/configsystemctl stop firewalld &amp;&amp; systemctl disable firewalld &amp;&amp; rpm -e --nodeps firewalldsystemctl disable chronydsystemctl stop chronydyum -y install iptables-servicessystemctl start iptables &amp;&amp; iptables -F &amp;&amp; service iptables saveyum -y install lrzsz net-tools vim psmisc bash-completion kernel-tools tree wget dos2unix ntpdate unzip tcpdumpcat &gt;&gt; ~/.vimrc &lt;&lt;EOFset ts=4set expandtabset pasteEOF# 根据虚拟机设置的主机名更改hostnamectl set-hostname node03rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.orgrpm -Uvh http://www.elrepo.org/elrepo-release-7.0-3.el7.elrepo.noarch.rpmyum --disablerepo=\"*\" --enablerepo=\"elrepo-kernel\" list availableyum --enablerepo=elrepo-kernel install kernel-ml -ygrub2-set-default 0grub2-mkconfig -o /boot/grub2/grub.cfgyum install ntp -yntpdate -u ntp1.aliyun.comreboot 安装命令 12345678910111213# 下载并安装sealos, sealos是个golang的二进制工具，直接下载拷贝到bin目录即可, release页面也可下载$ wget -c https://sealyun.oss-cn-beijing.aliyuncs.com/latest/sealos &amp;&amp; \\ chmod +x sealos &amp;&amp; mv sealos /usr/bin # 下载离线资源包$ wget -c https://sealyun.oss-cn-beijing.aliyuncs.com/d551b0b9e67e0416d0f9dce870a16665-1.18.0/kube1.18.0.tar.gz # 安装一个三master的kubernetes集群，密码需要一致$ sealos init --passwd 123456 \\ --master 192.168.10.121 --master 192.168.10.122 --master 192.168.10.123 \\ --node 192.168.10.124 \\ --pkg-url /root/kube1.18.0.tar.gz \\ --version v1.18.0 集群操作 增加master 12sealos join --master 192.168.0.6 --master 192.168.0.7sealos join --master 192.168.0.6-192.168.0.9 # 或者多个连续IP 增加node 12sealos join --node 192.168.0.6 --node 192.168.0.7sealos join --node 192.168.0.6-192.168.0.9 # 或者多个连续IP 删除指定master节点 12sealos clean --master 192.168.0.6 --master 192.168.0.7sealos clean --master 192.168.0.6-192.168.0.9 # 或者多个连续IP 删除指定node节点 12sealos clean --node 192.168.0.6 --node 192.168.0.7sealos clean --node 192.168.0.6-192.168.0.9 # 或者多个连续IP 清理集群 1sealos clean","categories":[{"name":"kubernetes","slug":"kubernetes","permalink":"https://hxqxiaoqi.gitee.io/categories/kubernetes/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://hxqxiaoqi.gitee.io/tags/k8s/"}],"keywords":[{"name":"kubernetes","slug":"kubernetes","permalink":"https://hxqxiaoqi.gitee.io/categories/kubernetes/"}]},{"title":"registry 私有仓库配置","slug":"registry 私有仓库配置","date":"2020-05-19T09:00:00.000Z","updated":"2020-07-24T03:50:32.171Z","comments":true,"path":"2020/05/19/registry 私有仓库配置/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2020/05/19/registry 私有仓库配置/","excerpt":"","text":"介绍Registry是一个几种存放image并对外提供上传下载以及一系列API的服务。可以很容易和本地源代码以及远端Git服务的关系相对应。 搭建1234# 启动# -e REGISTRY_STORAGE_DELETE_ENABLED=true 开启允许删除# -v /data/registry:/var/lib/registry 持久化存储目录docker run --name docker-registry -d -p 5000:5000 -e REGISTRY_STORAGE_DELETE_ENABLED=true -v /data/registry:/var/lib/registry registry 基本操作123456789101112131415161718192021# 查看所有镜像curl -X GET http://&lt;registry_ip&gt;:&lt;registry_port&gt;/v2/_catalog# 列出指定镜像的全部标签curl -X GET http://&lt;registry_ip&gt;:&lt;registry_port&gt;/v2/&lt;image_name&gt;/tags/list# 上传镜像，如果上传失败，需要配置/usr/lib/systemd/system/docker.service中添加私有仓库地址# 例：ExecStart=/usr/bin/dockerd --insecure-registry=http://192.168.40.102:5000# 删除镜像，上面容器启动时已经允许删除# 获取shasha=`ls /data/registry/docker/registry/v2/repositories/$image/_manifests/revisions/sha256`# 根据sha删除镜像，但空间不会释放curl -XDELETE http://&lt;registryurl&gt;/v2/$image/manifests/sha256:$sha# 进入容器docker exec -it registry sh# 垃圾回收，释放空间registry garbage-collect /etc/docker/registry/config.yml# 推出容器，删除残留目录rm -rf /opt/registry/docker/registry/v2/repositories/$image","categories":[{"name":"kubernetes","slug":"kubernetes","permalink":"https://hxqxiaoqi.gitee.io/categories/kubernetes/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://hxqxiaoqi.gitee.io/tags/docker/"},{"name":"k8s","slug":"k8s","permalink":"https://hxqxiaoqi.gitee.io/tags/k8s/"}],"keywords":[{"name":"kubernetes","slug":"kubernetes","permalink":"https://hxqxiaoqi.gitee.io/categories/kubernetes/"}]},{"title":"docker修改存储目录和连接私库","slug":"docker修改存储目录和连接私库","date":"2020-05-14T10:27:43.000Z","updated":"2020-07-24T03:51:08.286Z","comments":true,"path":"2020/05/14/docker修改存储目录和连接私库/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2020/05/14/docker修改存储目录和连接私库/","excerpt":"","text":"两种方式： 方式一： vim /etc/docker/daemon.json 1234567891011121314151617&#123; \"registry-mirrors\": [ \"https://bxsfpjcb.mirror.aliyuncs.com\" ], \"max-concurrent-downloads\": 10, \"log-driver\": \"json-file\", \"log-level\": \"warn\", \"log-opts\": &#123; \"max-size\": \"10m\", \"max-file\": \"3\" &#125;,# 修改私库地址 \"insecure-registries\": [\"127.0.0.1\",\"192.168.10.121:30000\",\"192.168.10.122:30000\",\"192.168.10.123:30000\"],# 修改存储目录 \"data-root\":\"/data/docker\"&#125; 注： 修改存储目录后，cp原docker目录到指定的目录中，重启daemon-reload和docker 方式二： vim /usr/lib/systemd/system/docker.service 1ExecStart=/usr/bin/dockerd --graph /data/docker --insecure-registry=http://192.168.10.121:30000 -H fd:// --containerd=/run/containerd/containerd.sock","categories":[{"name":"kubernetes","slug":"kubernetes","permalink":"https://hxqxiaoqi.gitee.io/categories/kubernetes/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://hxqxiaoqi.gitee.io/tags/docker/"}],"keywords":[{"name":"kubernetes","slug":"kubernetes","permalink":"https://hxqxiaoqi.gitee.io/categories/kubernetes/"}]},{"title":"openldap 安装","slug":"openldap 安装","date":"2020-04-30T04:27:43.000Z","updated":"2020-07-24T04:07:32.519Z","comments":true,"path":"2020/04/30/openldap 安装/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2020/04/30/openldap 安装/","excerpt":"","text":"介绍LDAP（Lightweight Directory Access Protocol）是基于X.500标准的轻量目录访问协议。它比X.500具有更快的查询速度和更低的资源消耗，精简灵活，支持TCP/IP协议。LDAP为用户管理提供了统一认证服务，解决了办公环境中多套用户认证和项目管理系统相互独立分散的难题，而OpenLDAP 是LDAP的开源实现。 其实就是各个支持ldap协议的应用，统一账号的地方，而不需要在每个应用上注册管理单独账号。 cn ：common name 用户名 对象的属性为CN，例如一个用户的名字为：张三，那么“张三”就是一个CN。 ou : OrganizationUnit 组织单位 o和ou都是ldap目录结构的一个属性，建立目录的时候可选新建o，ou 等。在配置我司交换设备ldap的时候具体是配置ou，o还是cn等，要具体看ldap服务器的相应目录是什么属性。 o：organizationName 组织名 uid: userid 对象的属性为uid，例如我司一个员工的名字为：zsq，他的UID为：z02691，ldap查询的时候可以根据cn，也可以根据uid。配置ldap查询的时候需要考虑用何种查询方式。我司两种方式都支持，具体我司设备配置根据何种方式查询需要有ldap服务器的相关配置来决定。 dc：域组件 DC类似于dns中的每个元素，例如h3c.com，“.”符号分开的两个单词可以看成两个DC， dn：Distinguished Name 类似于DNS，DN与DNS的区别是：组成DN的每个值都有一个属性类型，例如:H3c.com是一个dns，那么用dn表示为：dc=h3c,dc=com 级别越高越靠后。H3c和com的属性都是DC。DN可以表示为ldap的某个目录，也可以表示成目录中的某个对象，这个对象可以是用户等。 例如：CN=test,OU=developer,DC=domainname,DC=com 在上面的代码中 cn=test 可能代表一个用户名，ou=developer 代表一个 active directory 中的组织单位。这句话的含义可能就是说明 test 这个对象处在domainname.com 域的 developer 组织单元中。 安装步骤实验环境 主机名 IP 安装服务 系统版本 server 192.168.40.100 openldap openldap-servers openldap-clients centos7.4 client 192.168.40.101 openldap openldap-servers openldap-clients centos7.4 关闭防火墙和selinux 1234systemctl stop firewalldsystemctl disable firewalldsetenforce 0sed -i \"s/SELINUX=enforcing/SELINUX=disabled/g\" /etc/selinux/config 配置epel源 1yum install epel-release -y OpenLDAP安装 注：以下操作没有特殊说明，均在server主机操作。 12345yum install openldap openldap-servers openldap-clients -ycp /usr/share/openldap-servers/DB_CONFIG.example /var/lib/ldap/DB_CONFIGsystemctl start slapdsystemctl enable slapdsystemctl status slapd 配置管理员密码 12slappasswd -s 111111&#123;SSHA&#125;AjIAg98NFvRRlhoBOvsfVqMeAGZwi5O9 生成的密码写入到 rootpwd.ldif 文件中 1234567891011121314cat &lt;&lt;EOF&gt;rootpwd.ldifdn: olcDatabase=&#123;0&#125;config,cn=configchangetype: modifyadd: olcRootPWolcRootPW: &#123;SSHA&#125;AjIAg98NFvRRlhoBOvsfVqMeAGZwi5O9EOF# 相关参数说明：# olcRootPW参数值为slappasswd命令的结果输出。# olcRootPW: &#123;SSHA&#125;AjIAg98NFvRRlhoBOvsfVqMeAGZwi5O9指定了属性值。# ldif文件是LDAP中数据交换的文件格式。文件内容采用的是key-value形式。注意value后面不能有空格。# olc（OnlineConfiguration）表示写入LDAP后立即生效。# changetype: modify表示修改entry，此外changetype的值也可以是add,delete等。# add: olcRootPW表示对这个entry新增olcRootPW的属性。 写入配置 执行命令，添加 rootpwd.ldif 配置 到 openldap 中：ldap所有修改操作都需要编写单独的文件，切记不要直接去修改原有的配置。 1ldapadd -Y EXTERNAL -H ldapi:/// -f rootpwd.ldif 导入schema schema包含支持特殊场景的相关属性，可选择性导入或全部导入 1ls /etc/openldap/schema/*.ldif | while read i; do ldapadd -Y EXTERNAL -H ldapi:/// -f $i; done 新建默认域配置文件 123456789101112131415161718192021222324252627282930cat &lt;&lt;EOF&gt; domain.ldifdn: olcDatabase=&#123;1&#125;monitor,cn=configchangetype: modifyreplace: olcAccessolcAccess: &#123;0&#125;to * by dn.base=\"gidNumber=0+uidNumber=0,cn=peercred,cn=external,cn=auth\" read by dn.base=\"cn=Manager,dc=mydomain,dc=com\" read by * none# olcDatabase=&#123;2&#125;hdb，改配置名需要到/etc/openldap/slapd.d/cn\\=config/目录查看，不是都一样的，需要修改dn: olcDatabase=&#123;2&#125;hdb,cn=configchangetype: modifyreplace: olcSuffixolcSuffix: dc=mydomain,dc=comdn: olcDatabase=&#123;2&#125;hdb,cn=configchangetype: modifyreplace: olcRootDNolcRootDN: cn=Manager,dc=mydomain,dc=comdn: olcDatabase=&#123;2&#125;hdb,cn=configchangetype: modifyadd: olcRootPW# 上面生成的密码填写到这，或可以重新生成一个填写，与管理员密码区分olcRootPW: &#123;SSHA&#125;7AA7V1xy++LVZcUbBWYYM9/81wfODiIKdn: olcDatabase=&#123;2&#125;hdb,cn=configchangetype: modifyadd: olcAccessolcAccess: &#123;0&#125;to attrs=userPassword,shadowLastChange by dn=\"cn=Manager,dc=mydomain,dc=com\" write by anonymous auth by self write by * noneolcAccess: &#123;1&#125;to dn.base=\"\" by * readolcAccess: &#123;2&#125;to * by dn=\"cn=Manager,dc=mydomain,dc=com\" write by * readEOF 写入配置 执行命令，添加 domain.ldif 配置 到 openldap 中 1ldapmodify -Y EXTERNAL -H ldapi:/// -f domain.ldif 添加基本信息 123456789101112131415161718192021cat &lt;&lt;EOF&gt; basedomain.ldifdn: dc=mydomain,dc=comobjectClass: topobjectClass: dcObjectobjectclass: organizationo: mydomain comdc: mydomaindn: cn=Manager,dc=mydomain,dc=comobjectClass: organizationalRolecn: Managerdescription: Directory Managerdn: ou=People,dc=mydomain,dc=comobjectClass: organizationalUnitou: Peopledn: ou=Group,dc=mydomain,dc=comobjectClass: organizationalUnitou: GroupEOF 写入 1ldapadd -x -D cn=Manager,dc=mydomain,dc=com -W -f basedomain.ldif 查看信息 1ldapsearch -LLL -W -x -D \"cn=Manager,dc=mydomain,dc=com\" -H ldap://localhost -b\"dc=mydomain,dc=com\" 如果没有报错，则openldap服务端安装成功。 安装 ldapadmin web 管理在OpenLDAP运行节点安装ldapadmin工具包 1yum install -y httpd php php-mbstring php-pear phpldapadmin 修改 /etc/httpd/httpd.conf 123456789101112131415161718# line 86: 修改admin邮箱地址ServerAdmin root@openldap.mydomain.world# line 95: 修改主机域名ServerName www.mydomain.com:80# line 152: 修改成如下内容：AllowOverride All# line 165: 添加可访问目录名的文件名称DirectoryIndex index.html index.cgi index.php# 在文件末尾增加如下两部分内容# server's response headerServerTokens Prod# keepalive is ONKeepAlive On 启动Apache服务并设置开机自启动 12systemctl start httpdsystemctl enable httpd 编辑 /etc/phpldapadmin/config.php 123#注释掉398行，并取消397行的注释，修改后内容如下：$servers-&gt;setValue('login','attr','dn');// $servers-&gt;setValue('login','attr','uid'); 编辑 /etc/httpd/conf.d/phpldapadmin.conf 123456&lt;Directory/usr/share/phpldapadmin/htdocs&gt; &lt;IfModule mod_authz_core.c&gt; # Apache 2.4 Require local Require all granted &lt;/IfModule&gt; 重启Apache服务使配置生效 1systemctl restart httpd 访问 账号：cn=Manager,dc=mydomain,dc=com 密码：111111 1curl http://192.168.40.100/ldapadmin/","categories":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}],"tags":[{"name":"ldap","slug":"ldap","permalink":"https://hxqxiaoqi.gitee.io/tags/ldap/"}],"keywords":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}]},{"title":"flink 部署","slug":"flink 部署","date":"2020-04-26T05:00:00.000Z","updated":"2020-07-24T03:52:50.318Z","comments":true,"path":"2020/04/26/flink 部署/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2020/04/26/flink 部署/","excerpt":"","text":"介绍Flink 是新的stream计算引擎，用java实现。既可以处理stream data也可以处理batch data，可以同时兼顾Spark以及Spark streaming的功能，与Spark不同的是，Flink本质上只有stream的概念，batch被认为是special stream。Flink在运行中主要有三个组件组成，JobClient，JobManager 和 TaskManager 用户首先提交Flink程序到JobClient，经过JobClient的处理、解析、优化提交到JobManager，最后由TaskManager运行task。 组件说明JobManager JobManager是一个进程，主要负责申请资源，协调以及控制整个job的执行过程，具体包括，调度任务、处理checkpoint、容错等等，在接收到JobClient提交的执行计划之后，针对收到的执行计划，继续解析，因为JobClient只是形成一个operaor层面的执行计划，所以JobManager继续解析执行计划（根据算子的并发度，划分task），形成一个可以被实际调度的由task组成的拓扑图，最后向集群申请资源，一旦资源就绪，就调度task到TaskManager。 TaskManager TaskManager是一个进程，及一个JVM（Flink用java实现）。主要作用是接收并执行JobManager发送的task，并且与JobManager通信，反馈任务状态信息，比如任务分执行中，执行完等状态，上文提到的checkpoint的部分信息也是TaskManager反馈给JobManager的。如果说JobManager是master的话，那么TaskManager就是worker主要用来执行任务。在TaskManager内可以运行多个task。多个task运行在一个JVM内有几个好处，首先task可以通过多路复用的方式TCP连接，其次task可以共享节点之间的心跳信息，减少了网络传输。TaskManager并不是最细粒度的概念，每个TaskManager像一个容器一样，包含一个多或多个Slot。 Slot Slot是TaskManager资源粒度的划分，每个Slot都有自己独立的内存。所有Slot平均分配TaskManger的内存，比如TaskManager分配给Solt的内存为8G，两个Slot，每个Slot的内存为4G，四个Slot，每个Slot的内存为2G，值得注意的是，Slot仅划分内存，不涉及cpu的划分。同时Slot是Flink中的任务执行器（类似Storm中Executor），每个Slot可以运行多个task，而且一个task会以单独的线程来运行。 ResourceManager ResourceManager主要负责管理任务管理器（TaskManager）的插槽（slot），Slot时Flink定义的处理资源单元；ResourceManager将有空闲插槽的TaskManager分配给JobManager。如果ResourceManager没有足够的插槽来满足JobManager的请求，它可以向资源提供平台发起会话，以提供启动TaskManager进程的容器。 flink 部署Flink 有三种部署模式，分别是 Local、Standalone Cluster 和 Yarn Cluster。 Local 单机模式，适合用于实验环境 Standalone Cluster 集群模式，适合用于测试环境，配合zk和hdfs，可部署高可用模式，可用于生产环境 Yarn Cluster 基于hadoop Yarn 组件进行部署，支持高可用，适合用于生产环境 Local 模式 安装jdk 下载包解压 直接运行即可 Standalone 模式实验环境 IP 主机名 安装服务 192.168.40.100 master jdk1.8，flink1.7.1 192.168.40.101 worker1 jdk1.8，flink1.7.1 192.168.40.102 worker2 jdk1.8，flink1.7.1 jdk1.8安装 jdk1.8 安装跳转 所有节点都需要安装 设置ssh免密 在master上执行以下脚本，根据实际情况修改IP和密码。 12345678910111213141516171819cat &gt; ssh.sh &lt;&lt; EOFwget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repocurl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repoyum install -y expect#分发公钥ssh-keygen -t rsa -P \"\" -f /root/.ssh/id_rsafor i in 192.168.40.100 192.168.40.101 192.168.40.102doexpect -c \"spawn ssh-copy-id -i /root/.ssh/id_rsa.pub root@\\$i expect &#123; \\\"*yes/no*\\\" &#123;send \\\"yes\\r\\\"; exp_continue&#125; \\\"*password*\\\" &#123;send \\\"123123\\r\\\"; exp_continue&#125; \\\"*Password*\\\" &#123;send \\\"123123\\r\\\";&#125; &#125; \"doneEOFbash ssh.sh flink1.7.1 安装 以下操作，没有特殊说明，均在master上执行 1234# 下载wget https://archive.apache.org/dist/flink/flink-1.7.1/flink-1.7.1-bin-hadoop27-scala_2.11.tgz# 解压tar xf flink-1.7.1-bin-hadoop27-scala_2.11.tgz -C /opt 修改配置：/opt/flink-1.7.1/conf/masters 1192.168.40.100:8081 修改配置：/opt/flink-1.7.1/conf/slaves 12192.168.40.102192.168.40.101 修改配置：/opt/flink-1.7.1/conf/flink-conf.yaml 1234567891011121314151617# jobmanager地址jobmanager.rpc.address: 192.168.40.100# JobManager的端口号jobmanager.rpc.port: 6123# jobmanager可用最大内存，根据服务器内存设置jobmanager.heap.size: 1024m# taskmanager可用最大内存，也就是每个taskmanager所在的服务器能用的最大内存taskmanager.heap.size: 1024m# 每台taskmanager最大插槽数，可以根据cpu核数设定，用于划分内存，如：上面的值设置16G，slot设置2，每个slot有8G可用taskmanager.numberOfTaskSlots: 2# 默认使用插槽数，每个job默认分配的slot数parallelism.default: 1 配置环境变量 1234cat &gt;&gt; /etc/profile &lt;&lt; EOFexport FLINK_HOME=/opt/flink-1.7.1export PATH=\\$PATH:\\$FLINK_HOME/binEOF 分发配置 1234567for node_ip in 192.168.40.101 192.168.40.102do echo \"&gt;&gt;&gt; $&#123;node_ip&#125;\" scp -r /opt/flink-1.7.1/ root@$&#123;node_ip&#125;:/opt scp /etc/profile root@$&#123;node_ip&#125;:/etc/ ssh root@$&#123;node_ip&#125; \"source /etc/profile\"done 启动与停止 12/opt/flink-1.7.1/bin/start-cluster.sh/opt/flink-1.7.1/bin/stop-cluster.sh 访问 12# flink web管理界面，可以在浏览器访问curl http://192.168.40.100:8081 运行任务 12cd /opt/flink-1.7.1/./bin/flink run examples/streaming/WordCount.jar --input /opt/flink-1.7.1/README.txt Standalone HA 模式首先，我们需要知道 Flink 有两种部署的模式，分别是 Standalone 以及 Yarn Cluster 模式。对于 Standalone 来说，Flink 必须依赖于 Zookeeper 来实现 JobManager 的 HA（Zookeeper 已经成为了大部分开源框架 HA 必不可少的模块）。在 Zookeeper 的帮助下，一个 Standalone 的 Flink 集群会同时有多个活着的 JobManager，其中只有一个处于工作状态，其他处于 Standby 状态。当工作中的 JobManager 失去连接后（如宕机或 Crash），Zookeeper 会从 Standby 中选举新的 JobManager 来接管 Flink 集群。 zookeeper 安装 zookeeper 集群安装跳转 修改配置：conf/flink-conf.yaml 继续之前的配置 1234#jobmanager.rpc.address: master #注释rpchigh-availability:zookeeper #指定高可用模式（必须）high-availability.zookeeper.quorum:master:2181,worker1:2181,worker2:2181 #ZooKeeper仲裁是ZooKeeper服务器的复制组，它提供分布式协调服务（必须）high-availability.storageDir:hdfs:///flink/ha/ #JobManager元数据保存在文件系统storageDir中，只有指向此状态的指针存储在ZooKeeper中（必须） 修改：conf/masters 12master:8081worker1:8081 修改：conf/slaves 123masterworker1worker2 启动 1./bin/start-cluster.sh 查看 1234567891011121314151617181920212223[root@master flink-1.7.1]# jps10402 ResourceManager18563 Jps18261 TaskManagerRunner2056 NameNode17754 StandaloneSessionClusterEntrypoint2252 SecondaryNameNode6879 QuorumPeerMain[root@worker1 flink-1.7.1]# jps1201 DataNode3938 QuorumPeerMain6274 NodeManager10787 StandaloneSessionClusterEntrypoint11273 TaskManagerRunner11453 Jps[root@worker2 flink-1.7.1]# jps6177 Jps5988 TaskManagerRunner2135 QuorumPeerMain2698 NodeManager1199 DataNode 测试 登录web界面，查看master在哪台服务器上 kill掉master 查看master是否有更改 Flink on yarn 部署模式安装hadoop集群 因Flink强大的灵活性及开箱即用的原则， 因此提交作业分为2种情况： yarn seesion Flink run 这2者对于现有大数据平台资源使用率有着很大的区别： 1.第一种yarn seesion(Start a long-running Flink cluster on YARN)这种方式需要先启动集群，然后在提交作业，接着会向yarn申请一块空间后，资源永远保持不变。如果资源满了，下一个作业就无法提交，只能等到yarn中的其中一个作业执行完成后，释放了资源，那下一个作业才会正常提交. 2.第二种Flink run直接在YARN上提交运行Flink作业(Run a Flink job on YARN)，这种方式的好处是一个任务会对应一个job,即每提交一个作业会根据自身的情况，向yarn申请资源，直到作业执行完成，并不会影响下一个作业的正常运行，除非是yarn上面没有任何资源的情况下。 注意事项:如果是平时的本地测试或者开发，可以采用第一种方案；如果是生产环境推荐使用第二种方案； Flink on yarn模式部署时，不需要对Flink做任何修改配置，只需要将其解压传输到各个节点之上。但如果要实现高可用的方案，这个时候就需要到Flink相应的配置修改参数，具体的配置文件是FLINK_HOME/conf/flink-conf.yaml。 对于Flink on yarn模式，我们并不需要在conf配置下配置 masters和slaves。因为在指定TM的时候可以通过参数“-n”来标识需要启动几个TM;Flink on yarn启动后，如果是在分离式模式你会发现，在所有的节点只会出现一个 YarnSessionClusterEntrypoint进程；如果是客户端模式会出现2个进程一个YarnSessionClusterEntrypoint和一个FlinkYarnSessionCli进程。 1234567891011121314151617181920# 客户端模式./bin/yarn-session.sh -n 2 -jm 1024 -tm 1024./bin/flink run ./examples/batch/WordCount.jar -input hdfs://192.168.50.63:9000/LICENSE -output hdfs://192.168.50.63:9000/wordcount-result_1.txtyarn application --list # 查看所有yarn容器yarn application -kill application_1550836652097_0002 # 删除指定yarn# 分离模式./bin/yarn-session.sh -nm test3 -d# Flink run 方式提交./bin/flink run -m yarn-cluster -yn 1 -yjm 1024 -ytm 1024 ./examples/batch/WordCount.jarhdfs dfs -put LICENSE / #上传文件到hdfs./bin/flink run -m yarn-cluster -yn 1 -yjm 1024 -ytm 1024 ./examples/batch/WordCount.jar -input hdfs://192.168.50.63:9000/LICENSE -output hdfs://192.168.50.63:9000/wordcount-result.txt# 运行到指定的yarn session./bin/flink run -yid application_1550579025929_62420 ./examples/batch/WordCount.jar -input hdfs://data-hadoop-112-16.bjrs.zybang.com:8020/flume/events-.1539684881482 -output hdfs://data-hadoop-112-16.bjrs.zybang.com:8020/flink/flink-test02.txt","categories":[{"name":"大数据","slug":"大数据","permalink":"https://hxqxiaoqi.gitee.io/categories/大数据/"}],"tags":[{"name":"flink","slug":"flink","permalink":"https://hxqxiaoqi.gitee.io/tags/flink/"}],"keywords":[{"name":"大数据","slug":"大数据","permalink":"https://hxqxiaoqi.gitee.io/categories/大数据/"}]},{"title":"CA 证书详解","slug":"CA 证书详解","date":"2020-04-21T12:00:00.000Z","updated":"2020-07-24T03:41:41.295Z","comments":true,"path":"2020/04/21/CA 证书详解/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2020/04/21/CA 证书详解/","excerpt":"","text":"介绍博客链接 该博客非常详细的讲解了数字证书及CA 使用openssl生成https证书1234567891011121314# 使用openssl工具生成一个RSA私钥openssl genrsa -des3 -out server.key 2048# 生成CSR（证书签名请求）说明：需要依次输入国家，地区，城市，组织，组织单位，Common Name和Email。其中Common Name，可以写自己的名字或者域名，如果要支持https，Common Name应该与域名保持一致，否则会引起浏览器警告。可以将证书发送给证书颁发机构（CA），CA验证过请求者的身份之后，会出具签名证书，需要花钱。另外，如果只是内部或者测试需求，也可以使用OpenSSL实现自签名。openssl req -new -key server.key -out server.csr# 删除密钥中的密码，说明：如果不删除密码，在应用加载的时候会出现输入密码进行验证的情况，不方便自动化部署。openssl rsa -in server.key -out server.key# 生成自签名证书，内部或者测试使用，只要忽略证书提醒就可以了。openssl x509 -req -days 365 -in server.csr -signkey server.key -out server.crt# 生成pem格式的公钥，有些服务，需要有pem格式的证书才能正常加载，可以用下面的命令：openssl x509 -in server.crt -out server.pem -outform PEM","categories":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}],"tags":[{"name":"CA","slug":"CA","permalink":"https://hxqxiaoqi.gitee.io/tags/CA/"}],"keywords":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}]},{"title":"java进程cpu高排查","slug":"java进程cpu高排查","date":"2020-04-02T13:29:44.000Z","updated":"2020-07-24T04:05:19.515Z","comments":true,"path":"2020/04/02/java进程cpu高排查/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2020/04/02/java进程cpu高排查/","excerpt":"","text":"方法一： 1.jps 获取Java进程的PID。 2.jstack pid &gt;&gt; java.txt 导出CPU占用高进程的线程栈。 3.top -H -p PID 查看对应进程的哪个线程占用CPU过高。 4.echo “obase=16; PID” | bc 将线程的PID转换为16进制,大写转换为小写。 5.在第二步导出的Java.txt中查找转换成为16进制的线程PID。找到对应的线程栈。 6.分析负载高的线程栈都是什么业务操作。优化程序并处理问题。 方法二： 1.使用top 定位到占用CPU高的进程PID top 通过ps aux | grep PID命令 2.获取线程信息，并找到占用CPU高的线程 ps -mp pid -o THREAD,tid,time | sort -rn 3.将需要的线程ID转换为16进制格式 printf “%x\\n” tid 4.打印线程的堆栈信息 jstack pid |grep tid -A 30 脚本 12345#!/bin/bashpid=`ps aux --sort=-pcpu | head -10|awk 'NR==2&#123;print $2&#125;'`tid=`ps -mp $pid -o THREAD,tid,time | sort -rn|awk 'NR==3&#123;print $8&#125;'`ptid=`printf \"%x\\n\" $tid`jstack $pid |grep $ptid -A 30","categories":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}],"tags":[{"name":"java","slug":"java","permalink":"https://hxqxiaoqi.gitee.io/tags/java/"}],"keywords":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}]},{"title":"iptables常用命令","slug":"iptables常用命令","date":"2020-04-02T13:29:43.000Z","updated":"2020-07-24T04:04:59.378Z","comments":true,"path":"2020/04/02/iptables常用命令/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2020/04/02/iptables常用命令/","excerpt":"","text":"1、删除现有规则 在开始建立新的规则之前，您可能需要清理所有默认规则和现有规则。使用iptables如下所示的命令来做这个。 1234567iptables -F #警告：当前命令后将切断linux对外的一切端口请求，请确保你还能连接到vnc或主机上(or)iptables --flush# 删除单条记录iptables -nL --line-numberiptables -D INPUT 2 2、设置默认链策略 默认的iptables策略是ACCEPT。将此更改为如下所示。 123iptables -P INPUT DROPiptables -P FORWARD DROPiptables -P OUTPUT DROP 当将INPUT和OUTPUT默认策略作为DROP时，对于每一个防火墙规则要求都应该定义两条规则。即一个INPUT和一个OUTPUT。如果信任内部用户，则可以忽略上面OUTPUT的设置。默认情况下，不要丢弃所有OUTPUT的数据包。在这种情况下，对于每一个防火墙规则的要求，你只需要定义一个规则。即定义规则传入，因为传出是接受所有数据包。 3、阻止一个特定的IP地址 在我们做其他规则前，如果你想阻止一个特定的IP地址，你应该先做如下所示。当您在日志文件中找到特定的IP地址时发现一些奇怪的活动，并希望在进一步研究时暂时阻止该IP地址，这将很有帮助。 12BLOCK_THIS_IP=\"192.168.1.108\"iptables -A INPUT -s \"$BLOCK_THIS_IP\" -j DROP 你也可以使用下面的一种规则。 12iptables -A INPUT -i eth0 -s \"$BLOCK_THIS_IP\" -j DROP //规则禁止这个IP地址对我们服务器eth0网卡的所有连接iptables -A INPUT -i eth0 -p tcp -s \"$BLOCK_THIS_IP\" -j DROP //规则只禁止这个IP地址对我们服务器eth0网卡的tcp协议的连接 4.允许所有传入SSH 以下规则允许eth0接口上的所有传入的SSH连接。 12iptables -A INPUT -i eth0 -p tcp --dport 22 -m state --state NEW,ESTABLISHED -j ACCEPTiptables -A OUTPUT -o eth0 -p tcp --sport 22 -m state --state ESTABLISHED -j ACCEPT 5.只能从一个特定的网络允许传入的SSH 下面的规则只允许从网络192.168.100.X传入SSH连接。 12iptables -A INPUT -i eth0 -p tcp -s 192.168.100.0/24 --dport 22 -m state --state NEW,ESTABLISHED -j ACCEPTiptables -A OUTPUT -o eth0 -p tcp --sport 22 -m state --state ESTABLISHED -j ACCEPT 6.允许传入的HTTP和HTTPS 以下规则允许所有传入的网络流量。即HTTP流量的端口80。 12iptables -A INPUT -i eth0 -p tcp --dport 80 -m state --state NEW,ESTABLISHED -j ACCEPTiptables -A OUTPUT -o eth0 -p tcp --sport 80 -m state --state ESTABLISHED -j ACCEPT 下面的规则允许所有传入安全的网络流量。即HTTPS流量的端口443。 12iptables -A INPUT -i eth0 -p tcp --dport 443 -m state --state NEW,ESTABLISHED -j ACCEPTiptables -A OUTPUT -o eth0 -p tcp --sport 443 -m state --state ESTABLISHED -j ACCEPT 7.相结合多个规则使用多端口 当你不是写为每个端口单独的规则，而是从外面的世界多个端口传入的连接，可以在一起使用多端口扩展。 下面的示例允许所有传入SSH，HTTP和HTTPS流量。 12iptables -A INPUT -i eth0 -p tcp -m multiport --dports 22,80,443 -m state --state NEW,ESTABLISHED -j ACCEPTiptables -A OUTPUT -o eth0 -p tcp -m multiport --sports 22,80,443 -m state --state ESTABLISHED -j ACCEPT 8.允许OUTPUT SSH 以下规则允许传出ssh连接。也就是说当你从内ssh到外部服务器。 12iptables -A OUTPUT -o eth0 -p tcp --dport 22 -m state --state NEW,ESTABLISHED -j ACCEPT #允许双方新建立的OUTPUT链通信iptables -A INPUT -i eth0 -p tcp --sport 22 -m state --state ESTABLISHED -j ACCEPT #只允许双方已经建立的INPUT链通信 9.允许拨出SSH到特定网络 下面的规则只允许特定的网络传出的ssh连接。即你的SSH只有从内部网络192.168.100.0/24。 12iptables -A OUTPUT -o eth0 -p tcp -d 192.168.100.0/24 --dport 22 -m state --state NEW,ESTABLISHED -j ACCEPTiptables -A INPUT -i eth0 -p tcp --sport 22 -m state --state ESTABLISHED -j ACCEPT 10.允许拨出HTTPS 以下规则允许传出安全的Web流量。当你想允许互联网流量的用户，这是很有帮助。在服务器上，当你想使用wget从外部下载一些文件，这些规则也有帮助。 12iptables -A OUTPUT -o eth0 -p tcp --dport 443 -m state --state NEW,ESTABLISHED -j ACCEPTiptables -A INPUT -i eth0 -p tcp --sport 443 -m state --state ESTABLISHED -j ACCEPT 注：对于传出HTTP Web流量，增加两个额外的规则就像上面，并改变443 80。 11.负载均衡传入的Web流量 您也可以加载使用iptables防火墙规则平衡传入的网络流量。 1234This uses the iptables nth extension. The following example load balances the HTTPS traffic to three different ip-address. For every 3th packet, it is load balanced to the appropriate server (using the counter 0).iptables -A PREROUTING -i eth0 -p tcp --dport 443 -m state --state NEW -m nth --counter 0 --every 3 --packet 0 -j DNAT --to-destination 192.168.1.101:443iptables -A PREROUTING -i eth0 -p tcp --dport 443 -m state --state NEW -m nth --counter 0 --every 3 --packet 1 -j DNAT --to-destination 192.168.1.102:443iptables -A PREROUTING -i eth0 -p tcp --dport 443 -m state --state NEW -m nth --counter 0 --every 3 --packet 2 -j DNAT --to-destination 192.168.1.103:443 12.允许从外部到内部Ping 以下规则允许外部用户能够ping您的服务器。 12iptables -A INPUT -p icmp --icmp-type echo-request -j ACCEPTiptables -A OUTPUT -p icmp --icmp-type echo-reply -j ACCEPT 13.允许从内部到外部ping 以下规则允许您从内部ping到任何外部服务器。 12iptables -A OUTPUT -p icmp --icmp-type echo-request -j ACCEPTiptables -A INPUT -p icmp --icmp-type echo-reply -j ACCEPT 14.允许环回访问 您应该允许在服务器上进行完全环回访问。即使用127.0.0.1访问 12iptables -A INPUT -i lo -j ACCEPTiptables -A OUTPUT -o lo -j ACCEPT 15.允许内部网络到外部网络 在防火墙服务器上，一个以太网卡连接到外部网络，另一个以太网卡连接到内部服务器，请使用以下规则允许内部网络与外部网络通信。 12#在此示例中，eth1连接到外部网络（互联网），eth0连接到内部网络（例如：192.168.1.x）。iptables -A FORWARD -i eth0 -o eth1 -j ACCEPT 16.允许出站DNS 以下规则允许传出DNS连接。 12iptables -A OUTPUT -p udp -o eth0 --dport 53 -j ACCEPTiptables -A INPUT -p udp -i eth0 --sport 53 -j ACCEPT 17.允许NIS连接 如果您正在运行NIS（网络信息服务）来管理您的用户帐户，您应该允许NIS连接。即使允许SSH连接，如果您不允许NIS相关的ypbind连接，用户将无法登录。 NIS端口是动态的。即当ypbind启动时，它分配端口。（ypbind是定义NIS服务器的客户端进程。） 12345678910#首先做一个rpcinfo -p如下所示并获取端口号。在此示例中，它使用端口853和850。rpcinfo -p | grep ypbind#现在允许到端口111的入站连接，以及ypbind使用的端口。iptables -A INPUT -p tcp --dport 111 -j ACCEPTiptables -A INPUT -p udp --dport 111 -j ACCEPTiptables -A INPUT -p tcp --dport 853 -j ACCEPTiptables -A INPUT -p udp --dport 853 -j ACCEPTiptables -A INPUT -p tcp --dport 850 -j ACCEPTiptables -A INPUT -p udp --dport 850 -j ACCEPT 以上不会工作，当你重新启动ypbind，因为它在不同的时间会有不同的端口号。 有两个解决方案：1）使用静态ip地址为您的NIS，或2）使用一些聪明的shell脚本技术来自动抓取动态端口号从“rpcinfo -p”命令输出，并使用上述iptables规则。 18.允许Rsync来自特定网络 以下规则仅允许来自特定网络的rsync。 12iptables -A INPUT -i eth0 -p tcp -s 192.168.101.0/24 --dport 873 -m state --state NEW,ESTABLISHED -j ACCEPTiptables -A OUTPUT -o eth0 -p tcp --sport 873 -m state --state ESTABLISHED -j ACCEPT 19.仅允许来自特定网络的MySQL连接 如果你正在运行MySQL，通常你不想允许从外部直接连接。在大多数情况下，您可能在运行MySQL数据库的同一服务器上运行Web服务器。 但是DBA和开发人员可能需要使用MySQL客户端从他们的笔记本电脑和桌面直接登录到MySQL。在这种情况下，您可能希望允许内部网络直接与MySQL通信，如下所示。 12iptables -A INPUT -i eth0 -p tcp -s 192.168.100.0/24 --dport 3306 -m state --state NEW,ESTABLISHED -j ACCEPTiptables -A OUTPUT -o eth0 -p tcp --sport 3306 -m state --state ESTABLISHED -j ACCEPT 20.允许Sendmail或Postfix流量 以下规则允许邮件通信。它可以是sendmail或postfix。 12iptables -A INPUT -i eth0 -p tcp --dport 25 -m state --state NEW,ESTABLISHED -j ACCEPTiptables -A OUTPUT -o eth0 -p tcp --sport 25 -m state --state ESTABLISHED -j ACCEPT 21.允许IMAP和IMAPS 以下规则允许IMAP / IMAP2流量。 12iptables -A INPUT -i eth0 -p tcp --dport 143 -m state --state NEW,ESTABLISHED -j ACCEPTiptables -A OUTPUT -o eth0 -p tcp --sport 143 -m state --state ESTABLISHED -j ACCEPT 以下规则允许IMAPS流量。 12iptables -A INPUT -i eth0 -p tcp --dport 993 -m state --state NEW,ESTABLISHED -j ACCEPTiptables -A OUTPUT -o eth0 -p tcp --sport 993 -m state --state ESTABLISHED -j ACCEPT 22.允许POP3和POP3S 以下规则允许POP3访问。 12iptables -A INPUT -i eth0 -p tcp --dport 110 -m state --state NEW,ESTABLISHED -j ACCEPTiptables -A OUTPUT -o eth0 -p tcp --sport 110 -m state --state ESTABLISHED -j ACCEPT 以下规则允许POP3S访问。 12iptables -A INPUT -i eth0 -p tcp --dport 995 -m state --state NEW,ESTABLISHED -j ACCEPTiptables -A OUTPUT -o eth0 -p tcp --sport 995 -m state --state ESTABLISHED -j ACCEPT 23.防止DoS攻击 以下iptables规则将帮助您防止对您的Web服务器的拒绝服务（DoS）攻击。 1iptables -A INPUT -p tcp --dport 80 -m limit --limit 25/minute --limit-burst 100 -j ACCEPT 在上面的例子中： -m limit：这使用限制iptables扩展 -limit 25 /分钟：每分钟最多只能连接25个请求包。根据您的具体要求更改此值 -limit-burst 100：此值指示仅在连接的总数达到limit之后才实施限制/分钟 注意“-m limit”只匹配数据包而不是连接，所以上方例子中你将匹配25包每分钟。 如果是想限制每分钟下connect次数呢。限制连接数的解决方案是使用connlimit匹配。 1iptables -A INPUT -p tcp –syn –dport 80 -m connlimit –connlimit-above 15 –connlimit-mask 32 -j REJECT –reject-with tcp-reset 它将拒绝来自一个源IP的15以上的连接 - 一个很好的规则来保护Web服务器。 此外，当与“hashlimit” 结合后在保护免受DDoS攻击时效果更好。 使用“limit”匹配，您可以限制每个时间间隔的数据包的全局速率，但是使用“hashlimit”，您可以限制每个IP，每个组合IP +端口等。 所以一个Web服务器的例子将是这样： 1iptables -A INPUT -p tcp –dport 80 -m hashlimit –hashlimit 45/sec –hashlimit-burst 60 –hashlimit-mode srcip–hashlimit-name DDOS –hashlimit-htable-size 32768 –hashlimit-htable-max 32768 –hashlimit-htable-gcinterval 1000 –hashlimit-htable-expire 100000 -j ACCEPT 24. 端口转发 例：将来自422端口的流量全部转到22端口。 这意味着我们既能通过422端口又能通过22端口进行ssh连接。启用DNAT转发。 1iptables -t nat -A PREROUTING -p tcp -d 192.168.102.37 --dport 422 -j DNAT --to 192.168.102.37:22 除此之外，还需要允许连接到422端口的请求 1iptables -A INPUT -i eth0 -p tcp --dport 422 -m state --state NEW,ESTABLISHED -j ACCEPTiptables -A OUTPUT -o eth0 -p tcp --sport 422 -m state --state ESTABLISHED -j ACCEPT 25. 记录丢弃的数据表 1234iptables -N LOGGING #1.新建名为LOGGING的链iptables -A INPUT -j LOGGING #2.将所有来自INPUT链中的数据包跳转到LOGGING链中iptables -A LOGGING -m limit --limit 2/min -j LOG --log-prefix \"IPTables Packet Dropped: \" --log-level 7 #3.为这些包自定义个前缀，命名为”IPTables Packet Dropped”iptables -A LOGGING -j DROP #4.丢弃这些数据包 26. 例子 12345678910111213141516171819202122[root@iZ233pgwujzZ ~]# iptables-save# Generated by iptables-save v1.4.7 on Wed May 6 14:27:04 2020*filter:INPUT ACCEPT [0:0]:FORWARD ACCEPT [0:0]:OUTPUT ACCEPT [670583527:153247221001]# 允许指定IP访问所有服务-A INPUT -s 172.16.30.0/24 -p tcp -j ACCEPT# 访问端口范围-A INPUT -s 192.168.40.1/32 -p tcp -m tcp --dport 1:65535 -j ACCEPT# 意思是允许进入的数据包只能是刚刚我发出去的数据包的回应，ESTABLISHED：已建立的链接状态。RELATED：该数据包与本机发出的数据包有关。-A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT # 允许所有IP访问22端口-A INPUT -p tcp -m state --state NEW -m tcp --dport 22 -j ACCEPT# 允许icmp和io-A INPUT -p icmp -j ACCEPT -A INPUT -i lo -j ACCEPT # 这两内条的意思是在INPUT表和FORWARD表中拒绝所有其他不符合上述任何一条规则的容数据包。并且发送一条host prohibited的消息给被拒绝的主机。-A INPUT -j REJECT --reject-with icmp-host-prohibited -A FORWARD -j REJECT --reject-with icmp-host-prohibited COMMIT# Completed on Wed May 6 14:27:04 2020","categories":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}],"tags":[{"name":"iptables","slug":"iptables","permalink":"https://hxqxiaoqi.gitee.io/tags/iptables/"}],"keywords":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}]},{"title":"mysql8.0 安装","slug":"mysql 8.0 安装","date":"2020-04-02T02:49:00.000Z","updated":"2020-07-24T03:48:37.752Z","comments":true,"path":"2020/04/02/mysql 8.0 安装/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2020/04/02/mysql 8.0 安装/","excerpt":"","text":"介绍mysql8 安装，复制以下脚本执行即可 脚本123456789101112131415161718192021222324#!/bin/bash# 安装mysql8.0rpm -qa|grep mysql|awk '&#123;print \"yum -y remove\\t\" $1&#125;'|shrpm -qa|grep mariadb|awk '&#123;print \"yum -y remove\\t\" $1&#125;'|shrpm -Uvh http://dev.mysql.com/get/mysql57-community-release-el7-9.noarch.rpm sed -i \"34s/enabled=1/enabled=0/g\" /etc/yum.repos.d/mysql-community.reposed -i \"41s/enabled=0/enabled=1/g\" /etc/yum.repos.d/mysql-community.repoyum repolist enabled | grep mysqlyum install -y mysql-community-serversystemctl start mysqldsystemctl enable mysqldsystemctl daemon-reloaddbpw=`grep 'temporary password' /var/log/mysqld.log|cut -d ' ' -f 13`newdbpw=\"123456Aa\"mysql --connect-expired-password -uroot -p$dbpw &lt;&lt; EOFset global validate_password.policy=0;set global validate_password.length=1;ALTER USER 'root'@'localhost' IDENTIFIED BY $&#123;newdbpw&#125;;create user 'root'@'%' identified by $&#123;newdbpw&#125;;grant all privileges on *.* to root@'%' with grant option;flush privileges;quitEOF my.cnf 默认配置文件 123456789101112131415161718[mysqld]datadir=/var/lib/mysqlsocket=/var/lib/mysql/mysql.sock# Disabling symbolic-links is recommended to prevent assorted security riskssymbolic-links=0# Settings user and group are ignored when systemd is used.# If you need to run mysqld under a different user or group,# customize your systemd unit file for mariadb according to the# instructions in http://fedoraproject.org/wiki/Systemd[mysqld_safe]log-error=/var/log/mariadb/mariadb.logpid-file=/var/run/mariadb/mariadb.pid## include all files from the config directory#!includedir /etc/my.cnf.d","categories":[{"name":"数据库","slug":"数据库","permalink":"https://hxqxiaoqi.gitee.io/categories/数据库/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://hxqxiaoqi.gitee.io/tags/mysql/"}],"keywords":[{"name":"数据库","slug":"数据库","permalink":"https://hxqxiaoqi.gitee.io/categories/数据库/"}]},{"title":"简单的日志收集脚本","slug":"日志收集脚本","date":"2020-03-27T02:27:43.000Z","updated":"2020-07-24T03:39:41.310Z","comments":true,"path":"2020/03/27/日志收集脚本/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2020/03/27/日志收集脚本/","excerpt":"","text":"介绍用于收集服务日志，显示到web浏览器中，使用于单台服务器，只是简单的日志收集脚本。 该脚本是通过cgi-bin显示到web上，所有需要安装httpd服务，httpd服务天生支持cgi。 运行环境httpd 安装1yum -y install httpd 12vim /etc/httpd/conf/httpd.conf# 修改以下内容 12345678910111213# 监听端口Listen 8888# cgi脚本存放路径 ScriptAlias /cgi-bin/ \"/var/www/cgi-bin/\"# 访问cgi的权限设置&lt;Directory \"/var/www/cgi-bin\"&gt; AllowOverride None Options +ExecCGI Order allow,deny Allow from all&lt;/Directory&gt; 12345# 重启httpdsystemctl restart httpd# 加入开机启动systemctl enable httpd 脚本把以下脚本保存到httpd指定的cgi目录下，命名为shell，该脚本功能是收集浏览器url参数，在服务器执行，用户权限是apache。 12345#!/bin/sh alias urldecode='sed \"s@+@ @g;s@%@\\\\\\\\x@g\" | xargs -0 printf \"%b\"'echo -e \"Content-type: text/plain\\n\" decoded_str=`echo $QUERY_STRING | urldecode`echo -e \"`$decoded_str` \\n\" 把以下脚本保存到httpd指定的cgi目录下，命名为index.sh，该脚本功能是收服务的指定日志，并展以自定义命名展现在浏览器上。 1234567891011121314151617181920212223242526272829303132333435363738#!/bin/bash# 当前服务器地址，其中shell为上面的脚本link=\"http://192.168.10.134:8888/cgi-bin/shell?tail%20-500%20\"cat &lt;&lt; AAAContent-Type:text/html;charset=utf-8&lt;html&gt;&lt;head&gt;# 定义超链接样式&lt;style type=\"text/css\"&gt; a &#123; text-decoration: none;color: black&#125; a:hover &#123; text-decoration:underline;color: blue&#125; a:link &#123; text-decoration: none;color: blue&#125; a:active &#123; text-decoration:blink; color: blue&#125; a:visited &#123; text-decoration: none;color: green&#125; .url &#123; margin-left: 90px;margin-top: 50px;font-family:\"Microsoft YaHei\",微软雅黑,\"MicrosoftJhengHei\",华文细黑,STHeiti,MingLiu;letter-spacing:1px;line-height: 28px;font-weight:bold; font-size:18px;&#125;&lt;/style&gt;&lt;title&gt;b2blog&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;pre&gt;AAA# 查找日志并重名，超链接到日志for i in `ls /data/app/*/log.log`do z=`echo $i|cut -d '/' -f4` echo '&lt;a href='$link$i' style=\"text-decoration:none;\"&gt;&lt;font size=8&gt;'$z'&lt;/font&gt;&lt;/a&gt;'donecat &lt;&lt; AAA&lt;pre&gt;&lt;/body&gt;&lt;/html&gt;AAA 12# 赋予执行权限chmod +x /var/www/cgi-bin/* 12# 浏览器访问curl http://192.168.10.134:8888/cgi-bin/index.sh","categories":[{"name":"脚本","slug":"脚本","permalink":"https://hxqxiaoqi.gitee.io/categories/脚本/"}],"tags":[{"name":"shell脚本","slug":"shell脚本","permalink":"https://hxqxiaoqi.gitee.io/tags/shell脚本/"}],"keywords":[{"name":"脚本","slug":"脚本","permalink":"https://hxqxiaoqi.gitee.io/categories/脚本/"}]},{"title":"zookeeper 集群搭建","slug":"zookeeper 集群搭建","date":"2020-03-26T07:27:43.000Z","updated":"2020-07-24T04:00:27.693Z","comments":true,"path":"2020/03/26/zookeeper 集群搭建/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2020/03/26/zookeeper 集群搭建/","excerpt":"","text":"介绍Zookeeper原理简介 ZooKeeper是一个开放源码的分布式应用程序协调服务，它包含一个简单的原语集，分布式应用程序可以基于它实现同步服务，配置维护和命名服务等。 Zookeeper设计目的 最终一致性：client不论连接到那个Server，展示给它的都是同一个视图。 可靠性：具有简单、健壮、良好的性能、如果消息m被到一台服务器接收，那么消息m将被所有服务器接收。 实时性：Zookeeper保证客户端将在一个时间间隔范围内获得服务器的更新信息，或者服务器失效的信息。但由于网络延时等原因，Zookeeper不能保证两个客户端能同时得到刚更新的数据，如果需要最新数据，应该在读数据之前调用sync()接口。 等待无关（wait-free）：慢的或者失效的client不得干预快速的client的请求，使得每个client都能有效的等待。 原子性：更新只能成功或者失败，没有中间状态。 顺序性：包括全局有序和偏序两种：全局有序是指如果在一台服务器上消息a在消息b前发布，则在所有Server上消息a都将在消息b前被发布；偏序是指如果一个消息b在消息a后被同一个发送者发布，a必将排在b前面。 Zookeeper工作原理 在zookeeper的集群中，各个节点共有下面3种角色和4种状态： 角色：leader,follower,observer状态：leading,following,observing,looking Zookeeper的核心是原子广播，这个机制保证了各个Server之间的同步。实现这个机制的协议叫做Zab协议（ZooKeeper Atomic Broadcast protocol）。Zab协议有两种模式，它们分别是恢复模式（Recovery选主）和广播模式（Broadcast同步）。当服务启动或者在领导者崩溃后，Zab就进入了恢复模式，当领导者被选举出来，且大多数Server完成了和leader的状态同步以后，恢复模式就结束了。状态同步保证了leader和Server具有相同的系统状态。 为了保证事务的顺序一致性，zookeeper采用了递增的事务id号（zxid）来标识事务。所有的提议（proposal）都在被提出的时候加上了zxid。实现中zxid是一个64位的数字，它高32位是epoch用来标识leader关系是否改变，每次一个leader被选出来，它都会有一个新的epoch，标识当前属于那个leader的统治时期。低32位用于递增计数。 每个Server在工作过程中有4种状态： LOOKING：当前Server不知道leader是谁，正在搜寻。 LEADING：当前Server即为选举出来的leader。 FOLLOWING：leader已经选举出来，当前Server与之同步。 OBSERVING：observer的行为在大多数情况下与follower完全一致，但是他们不参加选举和投票，而仅仅接受(observing)选举和投票的结果。 安装实验环境配置hosts文件，让集群服务器间互相使用主机名访问 主机IP 主机名 安装服务 安装目录 192.168.40.100 zk0 jdk8，zookeeper /opt 192.168.40.101 zk1 jdk8，zookeeper /opt 192.168.40.102 zk2 jdk8，zookeeper /opt jdk8 安装所有节点安装：jdk 安装教程 zookeeper 安装在 192.168.40.100上安装 1234567891011# 下载wget https://mirror.bit.edu.cn/apache/zookeeper/zookeeper-3.5.7/apache-zookeeper-3.5.7.tar.gztar xf apache-zookeeper-3.5.7.tar.gz -c /opt# 重命名配置文件，zoo_sample.cfg为配置文件模板，默认不生效cd /opt/apache-zookeeper-3.5.7/confcp zoo_sample.cfg zoo.cfg# 创建日志和数据目录mkdir -p /opt/apache-zookeeper-3.5.7/&#123;logs,data&#125; 修改 zoo.cfg 12345678910111213141516171819202122232425262728# tickTime这个时间是作为zookeeper服务器之间或客户端与服务器之间维持心跳的时间间隔,也就是说每个tickTime时间就会发送一个心跳。tickTime=2000# initLimit这个配置项是用来配置zookeeper接受客户端（这里所说的客户端不是用户连接zookeeper服务器的客户端,而是zookeeper服务器集群中连接到leader的follower 服务器）初始化连接时最长能忍受多少个心跳时间间隔数。initLimit=10# syncLimit这个配置项标识leader与follower之间发送消息,请求和应答时间长度,最长不能超过多少个tickTime的时间长度,总的时间长度就是5*2000=10秒。syncLimit=5# 日志存储目录dataLogDir=/opt/apache-zookeeper-3.5.7/logs# 数据存储目录dataDir=/opt/apache-zookeeper-3.5.7/data# 端口clientPort=2181# 这个参数指定了需要保留的文件数目。默认是保留3个。autopurge.snapRetainCount=500# 3.4.0及之后版本，ZK提供了自动清理事务日志和快照文件的功能，这个参数指定了清理频率，单位是小时，需要配置一个1或更大的整数，默认是0，表示不开启自动清理功能。autopurge.purgeInterval=24# server.A=B:C:D中的A是一个数字,表示这个是第几号服务器,B是这个服务器的IP地址，C第一个端口用来集群成员的信息交换,表示这个服务器与集群中的leader服务器交换信息的端口，D是在leader挂掉时专门用来进行选举leader所用的端口。server.1=192.168.40.100:2888:3888server.2=192.168.40.101:2888:3888server.3=192.168.40.102:2888:3888 创建集群标识文件 12# 这里的\"1\"，就是zoo.cfg文件中server.1的\"1\"echo \"1\" &gt; /opt/apache-zookeeper-3.5.7/data/myid 把zookeeper目录传到其它节点 12scp -r /opt/apache-zookeeper-3.5.7 root@192.168.40.101:/optscp -r /opt/apache-zookeeper-3.5.7 root@192.168.40.102:/opt 在其它节点上操作 创建数据目录和日志目录，与192.168.40.100上操作一样 创建集群标识文件，与配置文件中对应 启动 1234/opt/apache-zookeeper-3.5.7/bin/zkServer.sh start# 查看状态/opt/apache-zookeeper-3.5.7/bin/zkServer.sh status 登录 12# 登录后，可以使用help查看操作命令/opt/apache-zookeeper-3.5.7/bin/zkCli.sh zkui 安装提请安装好 git 和 maven 123456789101112131415# 下载git clone https://github.com/DeemOpen/zkui.git# 编译cd zkuimvn clean install# 修改配置文件，修改zk地址和登录的账号密码vim config.cfg# 启动java -jar target/zkui-2.0-SNAPSHOT-jar-with-dependencies.jar# 访问curl http://192.168.40.100:9090","categories":[{"name":"中间件","slug":"中间件","permalink":"https://hxqxiaoqi.gitee.io/categories/中间件/"}],"tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"https://hxqxiaoqi.gitee.io/tags/zookeeper/"}],"keywords":[{"name":"中间件","slug":"中间件","permalink":"https://hxqxiaoqi.gitee.io/categories/中间件/"}]},{"title":"kafka 集群搭建","slug":"kafka 集群搭建","date":"2020-03-25T09:07:00.000Z","updated":"2020-07-24T03:59:55.378Z","comments":true,"path":"2020/03/25/kafka 集群搭建/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2020/03/25/kafka 集群搭建/","excerpt":"","text":"介绍kafka 是一个分布式的消息队列系统，消息以topic分类传输，生产者往topic发送消息时，消息会被分散到topic的不同分区中，消费者以组的形式消费topic中的数据，一个topic的一个分区，只能被同一个组里的一个消费者消费，但同一个消费者，可以消费多个分区数据，每个组自己维护topic每个分区的消费偏移量。 kafka 不能保证不同分区消息的消费顺序，因此若对于消息消费顺序有要求，必须确保该类消息处于同一分区，可以通过发送消息时，指定相同key来处理。 搭建实验环境配置hosts文件，让集群服务器间互相使用主机名访问 服务器ip 主机名 服务 安装目录 192.168.40.100 kafka0 kafka，zookeeper，jdk8 /opt 192.168.40.101 kafka1 kafka，zookeeper，jdk8 /opt 192.168.40.102 kafka2 kafka，zookeeper，jdk8 /opt jdk8 安装所有节点安装：jdk 安装教程 zookeeper 集群安装zk集群安装教程 kafka 集群安装在 kafka0 主机上配置 12345# 下载wget http://archive.apache.org/dist/kafka/2.4.0/kafka_2.13-2.4.0.tgztar xf kafka_2.13-2.4.0.tgz -C /optcd /opt/kafka_2.13-2.4.0/config 修改 server.properties 文件 1234567891011121314# 集群识别号，每台服务器上的kafka都不能相同broker.id=0# 监听地址，填写本机地址listeners=PLAINTEXT://kafka0:9092# 外网监听地址，返回给客户端的地址，填写本机地址advertised.listeners=PLAINTEXT://kafka0:9092# 数据存储目录,默认/tmp下，建议不要设置到/tmp下，否则有可能服务崩溃log.dirs=/data/kafka-logs# zookeeper地址zookeeper.connect=kafka0:2181,kafka1:2181,kafka2:2181 修改/opt/kafka_2.13-2.4.0/bin/kafka-server-start.sh 文件 12345if [ \"x$KAFKA_HEAP_OPTS\" = \"x\" ]; then export KAFKA_HEAP_OPTS=\"-Xmx1G -Xms1G\" # 添加以下这条设置，用于kafka-manager监控 export JMX_PORT=\"9999\"fi 复制 kafka 目录到其它集群服务器上，并修改相应配置 123# 如果没有免密，需要输入密码scp -r /opt/kafka_2.13-2.4.0 root@kafka1:/optscp -r /opt/kafka_2.13-2.4.0 root@kafka1:/opt 启动与关闭 12345678# 前台启动/opt/kafka_2.13-2.4.0/bin/kafka-server-start.sh /opt/kafka_2.13-2.4.0/config/server.properties# 后台启动/opt/kafka_2.13-2.4.0/bin/kafka-server-start.sh -daemon /opt/kafka_2.13-2.4.0/config/server.properties# 关闭/opt/kafka_2.13-2.4.0/bin/kafka-server-stop.sh kafka-manager安装kafka-manager用于监控kafka集群状态 1wget https://github.com/yahoo/CMAK/archive/3.0.0.4.tar.gz 常用命令12345678910111213141516171819202122232425262728293031323334cd /opt/kafka_2.13-2.4.0/bin/# 创建topic，--replication-facto：副本，--partitions：分区./kafka-topics.sh --create --zookeeper kafka0:2181,kafka1:2181,kafka2:2181 --replication-factor 3 --partitions 1 --topic kafka-test# 查看top信息./kafka-topics.sh --describe --zookeeper kafka0:2181,kafka1:2181,kafka2:2181 --topic kafka-test# 启动生产者./kafka-console-producer.sh --broker-list kafka0:9092,kafka1:9092,kafka2:9092 --topic kafka-test# 启动消费者，--from-beginning：从头开始消费./kafka-console-consumer.sh --bootstrap-server kafka0:9092,kafka1:9092,kafka2:9092 --topic kafka-test --from-beginning# 查看topic列表./kafka-topics.sh --list --zookeeper kafka0:2181,kafka1:2181,kafka2:2181# 删除topic./kafka-topics.sh --zookeeper kafka0:2181,kafka1:2181,kafka2:2181 --delete --topic kafka-test# 查看topic策略bin/kafka-configs.sh --zookeeper 192.168.10.111:2181,192.168.10.112:2181,192.168.10.113:2181 --describe --entity-type topics --entity-name TOPIC_DW_USER_STATS# 设置topic策略，保存时间bin/kafka-configs.sh --zookeeper 192.168.10.111:2181,192.168.10.112:2181,192.168.10.113:2181 --entity-type topics --entity-name TOPIC_DW_USER_STATS --alter --add-config retention.ms=10000# 取消topic策略bin/kafka-configs.sh --zookeeper 192.168.10.111:2181,192.168.10.112:2181,192.168.10.113:2181 --entity-type topics --entity-name TOPIC_DW_USER_STATS --alter --delete-config retention.ms# 查看所有消费者bin/kafka-consumer-groups.sh --bootstrap-server 192.168.10.111:9092,192.168.10.112:9092,192.168.10.113:9092 --list# 查看指定消费者信息bin/kafka-consumer-groups.sh --describe --bootstrap-server 192.168.10.111:9092,192.168.10.112:9092,192.168.10.113:9092 --group member-star-member-count-job server.properties 配置文件详解123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116# broker在集群中的唯一标识，不能为负数broker.id# 数据存放的目录，这个目录可以配置为“，”逗号分割的表达式，下面的num.io.threads要大于这个目录的个数，如果配置多个目录，新创建topic消息持久化的地方是，当前以逗号分割的目录中，分区数最少的那一个log.dirs# 相当于下面的host.name+portlisteners PLAINTEXT://hostname:port# 外网客户端访问返回的地址 PLAINTEXT://hostname:portadvertised.listeners # broker的主机地址，若是设置了，那么会绑定到这个地址上，若是没有，会绑定到所有的接口上，并将其中之一发送到ZKhost.name # 监听端口port# 消息最大字节message.max.bytes# broker处理网络消息的最大线程数num.network.threads# broker处理磁盘IO的线程数，数值应该大于你的目录数num.io.threads# 处理后台任务的线程数，例如过期消息文件的删除等background.threads# 等待IO线程处理的请求队列最大数，若是等待IO的请求超过这个数值，那么会停止接受外部消息，应该是一种自我保护机制queued.max.requests# socket的发送缓冲区socket.send.buffer.bytes# socket的接受缓冲区socket.receive.buffer.bytes# socket请求的最大字节数值，防止serverOOM，message.max.bytes必然要小于socket.request.max.bytes，会被topic创建时的指定参数覆盖socket.request.max.bytes# topic的分区是以一堆segment文件存储的，这个控制每个segment的大小，会被topic创建时的指定参数覆盖log.segment.bytes# 在日志segment没有达到log.segment.bytes设置的大小，但超过设定时间，也会强制新建一个segment。会被 topic创建时的指定参数覆盖log.roll.hours# 日志清理策略选择有：delete和compact主要针对过期数据的处理，或是日志文件达到限制的额度，会被 topic创建时的指定参数覆盖log.cleanup.policy# 数据存储的最大时间超过这个时间会根据log.cleanup.policy设置的策略处理数据，也就是消费端能够多久去消费数据，log.retention.bytes和log.retention.minutes任意一个达到要求，都会执行删除，会被topic创建时的指定参数覆盖log.retention.minutes# topic每个分区的最大文件大小，一个topic的大小限制 =分区数*log.retention.bytes。-1没有大小限log.retention.bytes和log.retention.minutes任意一个达到要求，都会执行删除，会被topic创建时的指定参数覆盖log.retention.bytes# 文件大小检查的周期时间，是否执行 log.cleanup.policy中设置的策略log.retention.check.interval.ms# 是否开启日志压缩log.cleaner.enable# 日志压缩运行的线程数log.cleaner.threads# 日志压缩时每秒处理的最大大小log.cleaner.io.max.bytes.per.second# 日志压缩去重时候的缓存空间，在空间允许的情况下，越大越好log.cleaner.dedupe.buffer.size# 日志清理时候用到的IO块大小一般不需要修改log.cleaner.io.buffer.size# 日志清理中hash表的扩大因子一般不需要修改log.cleaner.io.buffer.load.factor# 检查是否触发日志清理的间隔log.cleaner.backoff.ms# 日志清理的频率控制，越大意味着更高效的清理，同时会存在一些空间上的浪费，会被topic创建时的指定参数覆盖log.cleaner.min.cleanable.ratio# 对于压缩的日志保留的最长时间，也是客户端消费消息的最长时间，与log.retention.minutes的区别在于一个控制未压缩数据，一个控制压缩后的数据。会被topic创建时的指定参数覆盖log.cleaner.delete.retention.ms# 对于segment日志的索引文件大小限制，会被topic创建时的指定参数覆盖log.index.size.max.bytes# 当执行一个fetch操作后，需要一定的空间来扫描最近的offset大小，设置越大，代表扫描速度越快，但是也更好内存，一般情况下不需要搭理这个参数log.index.interval.bytes# log文件”sync”到磁盘之前累积的消息条数,因为磁盘IO操作是一个慢操作,但又是一个”数据可靠性\"的必要手段,所以此参数的设置,需要在\"数据可靠性\"与\"性能\"之间做必要的权衡.如果此值过大,将会导致每次\"fsync\"的时间较长(IO阻塞),如果此值过小,将会导致\"fsync\"的次数较多,这也意味着整体的client请求有一定的延迟.物理server故障,将会导致没有fsync的消息丢失.log.flush.interval.messages# 检查是否需要固化到硬盘的时间间隔log.flush.scheduler.interval.ms# 仅仅通过interval来控制消息的磁盘写入时机,是不足的.此参数用于控制\"fsync\"的时间间隔,如果消息量始终没有达到阀值,但是离上一次磁盘同步的时间间隔达到阀值,也将触发.log.flush.interval.ms# 文件在索引中清除后保留的时间一般不需要去修改log.delete.delay.ms# 控制上次固化硬盘的时间点，以便于数据恢复一般不需要去修改log.flush.offset.checkpoint.interval.ms # 消息时间戳类型，CreateTime 和 LogAppendTime ；前者表示producer创建这条消息的时间；后者表示broker接收到这条消息的时间(严格来说，是leader broker将这条消息写入到log的时间log.message.timestamp.type # 是否允许自动创建topic，若是false，就需要通过命令创建topicauto.create.topics.enable # 每个topic的分区个数，会被topic创建时的指定参数覆盖num.partitions","categories":[{"name":"大数据","slug":"大数据","permalink":"https://hxqxiaoqi.gitee.io/categories/大数据/"}],"tags":[{"name":"kafka","slug":"kafka","permalink":"https://hxqxiaoqi.gitee.io/tags/kafka/"}],"keywords":[{"name":"大数据","slug":"大数据","permalink":"https://hxqxiaoqi.gitee.io/categories/大数据/"}]},{"title":"hbase 分布式搭建","slug":"hbash分布式搭建","date":"2020-03-20T10:00:00.000Z","updated":"2020-07-24T03:58:44.457Z","comments":true,"path":"2020/03/20/hbash分布式搭建/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2020/03/20/hbash分布式搭建/","excerpt":"","text":"介绍HBase 简介 1、HBase是Apache Hadoop的数据库，能够对大型数据提供随机、实时的读写访问，是Google的BigTable的开源实现。 2、HBase的目标是存储并处理大型的数据，更具体地说仅用普通的硬件配置，能够处理成千上万的行和列所组成的大型数据库。3、HBase是一个开源的、分布式的、多版本的、面向列的存储模型。可以直接使用本地文件系统，也可使用Hadoop的HDFS文件存储系统。 为了提高数据的可靠性和系统的健壮性，并且发挥HBase处理大型数据的能力，还是使用HDFS作为文件存储系统更佳。 另外，HBase存储的是松散型数据，具体来说，HBase存储的数据介于映射（key/value）和关系型数据之间。HBase存储的数据从逻辑上看就是一张很大的表，并且它的数据列可以根据需要动态增加。每一个cell中的数据又可以有多个版本（通过时间戳来区别），从下图来看，HBase还具有 “ 向下提供存储，向上提供运算 “ 的特点。 HBase 体系结构 HBase的服务器体系结构遵从简单的主从服务器架构，它由HRegion Server群和HBase Master服务器构成。 HBase Master负责管理所有的HRegion Server，而HBase中的所有RegionServer都是通过ZooKeeper来协调，并处理HBase服务器运行期间可能遇到的错误。 HBase Master Server本身并不存储HBase中的任何数据，HBase逻辑上的表可能会被划分成多个Region，然后存储到HRegion Server群中。HBase Master Server中存储的是从数据到HRegion Server的映射。 Client：HBase Client 使用HBase的RPC机制与HMaster和HRegionServer进行通信：对于管理类操作，Client与HMaster进行RPC；对于数据读写类操作，Client与HRegionServer进行RPC。 Zookeeper：Zookeeper Quorum中除了存储了-ROOT-表的地址和HMaster的地址，HRegionServer也会把自己以Ephemeral方式注册到 Zookeeper中，使得HMaster可以随时感知到各个HRegionServer的健康状态。此外，Zookeeper也避免了HMaster的 单点问题。 HMaster：每台HRegionServer都会与HMaster进行通信，HMaster的主要任务就是要告诉每台HRegion Server它要维护哪些HRegion。当一台新的HRegionServer登录到HMaster时，HMaster会告诉它等待分配数据。而当一台HRegion死机时，HMaster会把它负责的HRegion标记为未分配，然后再把它们分配到其他的HRegion Server中。HBase已经解决了HMaster单点故障问题（SPFO），并且HBase中可以启动多个HMaster，那么它就能够通过Zookeeper来保证系统中总有一个Master在运行。HMaster在功能上主要负责Table和Region的管理工作。 HRegion：当表的大小超过设置值得时候，HBase会自动地将表划分为不同的区域，每个区域包含所有行的一个子集。对用户来说，每个表是一堆数据的集合，靠主键来区分。从物理上来说，一张表被拆分成了多块，每一块就是一个HRegion。我们用表名+开始/结束主键来区分每一个HRegion，一个HRegion会保存一个表里面某段连续的数据，从开始主键到结束主键，一张完整的表格是保存在多个HRegion上面。 管理用户对Table的增删改查操作 管理HRegionServer的负载均衡，调整Region分布 在Region Split后，负责新Region的分配 在HRegionServer停机后，负责失效HRegionServer上的Region迁移 HRegionServer：主要负责响应用户I/O请求，向HDFS文件系统中读写数据，是HBase中最核心的模块。HRegionServer内部管理了一系列HRegion对象，每个HRegion对应了Table中的一个 Region，HRegion中由多个HStore组成。每个HStore对应了Table中的一个Column Family的存储，可以看出每个Column Family其实就是一个集中的存储单元，因此最好将具备共同IO特性的column放在一个Column Family中，这样最高效。 HStore：存储是HBase存储的核心，其中由两部分组成，一部分是MemStore，一部分是StoreFiles。 MemStore是Sorted Memory Buffer，用户写入的数据首先会放入MemStore，当MemStore满了以后会Flush成一个StoreFile(底层实现是HFile)， 当StoreFile文件数量增长到一定阈值，会触发Compact合并操作，将多个StoreFiles合并成一个StoreFile，合并过程中会进行版本合并和数据删除，因此可以看出HBase其实只有增加数据，所有的更新和删除操作都是在后续的compact过程中进行的，这使得用户的写操作只要 进入内存中就可以立即返回，保证了HBase I/O的高性能。当StoreFiles Compact后，会逐步形成越来越大的StoreFile，当单个StoreFile大小超过一定阈值后，会触发Split操作，同时把当前 Region Split成2个Region，父Region会下线，新Split出的2个孩子Region会被HMaster分配到相应的HRegionServer 上，使得原先1个Region的压力得以分流到2个Region上。 安装hadoop 安装hadoop 分布式集群安装教程 ：hbase是基于hadoop的hdfs所设计的NoSql数据库，所以需要先安装hadoop集群 zookeeper 安装zookeeper 安装教程 hbase 安装在 192.168.40.100 上操作： 1234# 下载wget https://mirror.bit.edu.cn/apache/hbase/stable/hbase-2.2.3-bin.tar.gztar xf hbase-2.2.3-bin.tar.gz -C /opt/cd /opt/hbase-2.2.3/conf/ 修改 hbase-env.sh，添加以下内容： 123456# jdk 环境变量export JAVA_HOME=/opt/jdk1.8.0_221# hbase 配置目录环境变量export HBASE_CLASSPATH=/opt/hbase-2.2.3/conf# 关闭内部zookeeper，使用外部zookeeper的配置export HBASE_MANAGES_ZK=false 修改 hbase-site.xml ： 1234567891011121314151617181920212223242526&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hbase.unsafe.stream.capability.enforce&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.property.clientPort&lt;/name&gt; &lt;value&gt;2181&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt; &lt;value&gt;hadoop0,hadoop1,hadoop2&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt; &lt;value&gt;/var/zookeeper&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.rootdir&lt;/name&gt; &lt;value&gt;hdfs://hadoop0:9000/hbase&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.cluster.distributed&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 修改 regionservers ： 123hadoop0hadoop1hadoop2 配置高可用 1echo \"hadoop1\" &gt; /opt/hbase-2.2.3/conf/backup-masters 分发配置 12scp -r /opt/hbase-2.2.3/ root@hadoop1:/opt/scp -r /opt/hbase-2.2.3/ root@hadoop2:/opt/ 启动与关闭 12345678# 在master上启动集群/opt/hbase-2.2.3/bin/start-hbase.sh/opt/hbase-2.2.3/bin/stop-hbase.sh# 单独启动masterbin/hbase-daemon.sh start master# 单独启动HRegionServerbin/hbase-daemon.sh start regionserver 访问 1curl http://192.168.40.100:16010/ hbase 常用操作命令123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106# 登录hbase数据库cd /opt/hbase-2.2.3/bin/./hbase shell# 列出当前数据库中的所有namespace：&gt; list_namespace# 列出hbase中的表：&gt; list# 查看帮助信息，找到创建的语法格式，注意要加上引号：&gt; help 'create_namespace'# 创建namespace：&gt; create_namespace 'nstest'# 描述查看namespace的结构：&gt; drop_namespace 'nstest'# 创建表，表名user，列簇info：示例：create 'ns1:t1', &#123;NAME =&gt; 'f1', VERSIONS =&gt; 5&#125;# 1）ns1指的就是namespace# 2）t1代表table_name# 3）ns1:t1这样的格式就是唯一确定了一张表# 4）在hbase中=&gt;符号表示等于# 5）f指的是列簇，建表时要指定一个列簇# 6）VERSIONS =&gt; 5代表同时能够存储的版本数# 7）可以指定多个列簇，一个大括号中只能指定一个NAME（变量）# 8）一个列簇就是一个大括号# 9）在建表的时候可以指定在某个namespace下，比如：ns1:t1，没有指定就是在默认的数据库下面创建&gt; create 'user','info'# 查看表user的结构：&gt; describe 'user'# 向表user中插入数据。表名user，rowkey为10001，列簇info，列名name等，cell值为zhangsan：&gt; put 'user','10001','info:name','zhangsan'&gt; put 'user','10001','info:age','25'&gt; put 'user','10001','info:sex','male'&gt; put 'user','10001','info:address','shanghai'# HBase中的数据查询有三种方式：# 1）依据rowkey查询，这是最快的，使用get命令；# 2）依据范围查询，这是最常用的，使用scan range命令；# 3）全表扫描，这是最慢的，使用scan命令。# 查询user表中rowkey为10001的信息：&gt; get 'user','10001'# 查询user表中rowkey为10001，列簇为info的信息：&gt; get 'user','10001','info'# 查询user表中rowkey为10001，列簇为info，列名为name的信息：&gt; get 'user','10001','info:name'# 插入rowkey为10002的信息：&gt; put 'user','10002','info:name','wangwu'&gt; put 'user','10002','info:age','30'&gt; put 'user','10002','info:tel','25354212'&gt; put 'user','10002','info:qq','232523551'# 全表扫描：&gt; scan# 全表扫描user表：&gt; scan 'user'# 插入user表中列簇为10003的信息：&gt; put 'user','10003','info:name','zhaoliu'# 范围查询：查询user表中的name列和age列的信息：&gt; scan 'user',&#123;COLUMNS =&gt; ['info:name','info:age']&#125;# 范围查询：查询user表中起始rowkey为10002开始的行信息：&gt; scan 'user', &#123;STARTROW=&gt;'10002'&#125;# STARTROW代表开始的行号，大括号中的所有变量都必须是大写：&gt; scan 'ns1:t1', &#123;COLUMNS =&gt; ['c1', 'c2'], LIMIT =&gt; 10, STARTROW =&gt; 'xyz'&#125;&gt; scan 'nstest:tb1', &#123;STARTROW =&gt; '20170521_10002'&#125;# STOPROW代表结束的行号，包头不包尾：&gt; scan 'nstest:tb1', &#123;STARTROW =&gt; '20170521_10001',STOPROW =&gt; '20170521_10003'&#125;# 删除user表中rowkey为10001，列簇为info，列名为name，值为zhangsan的数据（可能该值有多个版本）：&gt; delete 'user','10001','info:name','zhangsan'# 删除user表中rowkey为10001，列簇为info，列名为name的列数据：全表扫描user表：查看结果&gt; delete 'user','10001','info:name'# 删除user表中rowkey为10001的全部信息：全表扫描user表：查看结果&gt; deleteall 'user','10001'# 禁用user表：&gt; disable 'user'# 启用user表：&gt; enable 'user'# 删除user表：&gt; drop 'user'# 退出hbase shell命令行：&gt; exit# 删除g开头的表,\\ny：自动确认echo -e \"disable_all 'g.*'\\ny\" | /data/hbase-2.2.3/bin/hbase shell -necho -e \"drop_all 'g.*'\\ny\" | /data/hbase-2.2.3/bin/hbase shell -n","categories":[{"name":"大数据","slug":"大数据","permalink":"https://hxqxiaoqi.gitee.io/categories/大数据/"}],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"https://hxqxiaoqi.gitee.io/tags/hadoop/"}],"keywords":[{"name":"大数据","slug":"大数据","permalink":"https://hxqxiaoqi.gitee.io/categories/大数据/"}]},{"title":"hadoop完全分布式搭建","slug":"hadoop 完全分布式搭建","date":"2020-03-20T07:00:00.000Z","updated":"2020-07-24T03:52:53.645Z","comments":true,"path":"2020/03/20/hadoop 完全分布式搭建/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2020/03/20/hadoop 完全分布式搭建/","excerpt":"","text":"介绍HadoopHadoop是一个由Apache基金会所开发的分布式系统基础架构。 Hadoop实现了一个分布式文件系统（Hadoop Distributed File System），简称HDFS。HDFS有高容错性的特点，并且设计用来部署在低廉的（low-cost）硬件上；而且它提供高吞吐量（high throughput）来访问应用程序的数据，适合那些有着超大数据集（large data set）的应用程序。HDFS放宽了（relax）POSIX的要求，可以以流的形式访问（streaming access）文件系统中的数据。 Hadoop的框架最核心的设计就是：HDFS和MapReduce。HDFS为海量的数据提供了存储，则MapReduce为海量的数据提供了计算。 YARN： (分布式资源管理器) 不同计算框架可以共享同一个HDFS集群上的数据，享受整体的资源调度。 YARN的基本思想是将资源管理和作业调度/监控的功能分解为单独的守护进程（守护进程(daemon)是一类在后台运行的特殊进程，用于执行特定的系统任务。很多守护进程在系统引导的时候启动，并且一直运行直到系统关闭。另一些只在需要的时候才启动，完成任务后就自动结束。）。 这个想法是有一个全局的ResourceManager（RM）和每个应用程序的ApplicationMaster（AM）。 应用程序可以是单个作业，也可以是DAG作业。 工作组件介绍 Client：客户端，系统使用者。 文件切分。文件上传 HDFS 的时候，Client 将文件切分成 一个一个的Block，然后进行存储。 与 NameNode 交互，获取文件的位置信息。 与 DataNode 交互，读取或者写入数据。 Client 提供一些命令来管理 HDFS，比如启动或者关闭HDFS。 Client 可以通过一些命令来访问 HDFS。 NameNode：就是 master，它是一个主管、管理者。 管理 HDFS 的名称空间。 管理数据块（Block）映射信息 配置副本策略 处理客户端读写请求。 DataNode：就是Slave。NameNode 下达命令，DataNode 执行实际的操作。 存储实际的数据块。 执行数据块的读/写操作。 定期向NameNode发送心跳信息，汇报本身及其所有的block信息，健康情况。 Secondary NameNode：并非 NameNode 的热备。当NameNode 挂掉的时候，它并不能马上替换 NameNode 并提供服务。注意：在hadoop 2.x 版本，当启用 hdfs ha 时，将没有这一角色 辅助 NameNode，分担其工作量。 定期合并 fsimage和fsedits，并推送给NameNode。 在紧急情况下，可辅助恢复 NameNode。 ResourceManager， 简称RM，ResourceManager是仲裁系统中所有应用程序之间资源的最终权威机构。（大管理员） 整个集群同一时间提供服务的RM只有一个，它负责集群资源的统一管理和调度。 处理客户端的请求，例如：提交作业或结束作业等。 监控集群中的NM，一旦某个NM挂了，那么就需要将该NM上运行的任务告诉AM来如何进行处理。 ResourceManager主要有两个组件：Scheduler 和 ApplicationManager。 Scheduler是一个资源调度器，它主要负责协调集群中各个应用的资源分配，保障整个集群的运行效率。Scheduler的角色是一个纯调度器，它只负责调度Containers，不会关心应用程序监控及其运行状态等信息。同样，它也不能重启因应用失败或者硬件错误而运行失败的任务。Scheduler是一个可插拔的插件，它可以调度集群中的各种队列、应用等。 ApplicationManager主要负责接收job的提交请求，为应用分配第一个Container来运行ApplicationMaster，还有就是负责监控ApplicationMaster，在遇到失败时重启ApplicationMaster运行的Container。 NodeManager， 简称NM，（执行者，小员工） 整个集群中会有多个NM，它主要负责自己本身节点的资源管理和使用。 定时向RM汇报本节点的资源使用情况。 接收并处理来自RM的各种命令，例如：启动Container。 NM还需要处理来自AM的命令，例如：AM会告诉NM需要启动多少个Container来跑task，单个节点的资源管理。 ApplicationMaster， 简称AM，应用级别（小管理员） 每个应用程序都对应着一个AM。例如：MapReduce会对应一个、Spark会对应一个，它主要负责应用程序的管理。 为应用程序向RM申请资源（Core、Memory），将资源分配给内部的task。 AM需要与NM通信，以此来启动或停止task。遇到失败的任务还负责重启它。 Container 封装了CPU、Memory等资源的一个容器 是一个任务运行环境的抽象 搭建实验环境： 主机名 IP地址 运行组件 hadoop0 192.168.40.100 NameNode，ResourceManager，SecondaryNameNode hadoop1 192.168.40.101 NodeManager，DataNode hadoop2 192.168.40.102 NodeManager，DataNode JDK 安装所有节点均安装：jdk安装教程 hosts 配置所有节点均配置 12345cat &gt;&gt; /etc/hosts &lt;&lt; EOF192.168.40.100 hadoop0192.168.40.101 hadoop1192.168.40.102 hadoop2EOF ssh 免密配置在所有节点上执行： 12# 需要输入的，一路回车就行ssh-keygen -t rsa 在 192.168.40.100 执行： 1cp ~/.ssh/id_rsa.pub ~/.ssh/authorized_keys 将其他节点的公钥添加进authorized_keys，之后执行以下命令： 12scp ~/.ssh/authorized_keys root@hadoop1:/root/.ssh/scp ~/.ssh/authorized_keys root@hadoop2:/root/.ssh/ ntp 时间同步所有节点执行 12yum install ntpntpdate -u ntp1.aliyun.com 关闭防火墙所有节点执行 12345678# 查看防火墙状态firewall-cmd --state# 停止firewallsystemctl stop firewalld.service# 禁止firewall开机启动systemctl disable firewalld.service hadoop 安装以下操作只有在 192.168.40.100 上执行，全部配置好后，再传给其它节点。 12345678# 下载wget http://mirror.bit.edu.cn/apache/hadoop/common/hadoop-2.7.7/hadoop-2.7.7.tar.gz# 解压tar xf hadoop-2.7.7.tar.gz -C /opt/# 切换到配置目录cd /opt/hadoop-2.7.7/etc/hadoop/ 修改 hadoop-env.sh 12# 修改jdk环境变量export JAVA_HOME=/opt/jdk1.8.0_221 修改 yarn-env.sh 12# 添加jdk环境变量export JAVA_HOME=/opt/jdk1.8.0_221/ 修改 core-site.xml 注：file后的路径下的temp文件夹需要自己创建，所有节点均创建 123456789101112131415161718192021222324&lt;configuration&gt; &lt;!-- 指定HDFS老大（namenode）的通信地址 --&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://hadoop0:9000&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;io.file.buffer.size&lt;/name&gt; &lt;value&gt;131072&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定hadoop运行时产生文件的存储路径 --&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;file:/usr/temp&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.hosts&lt;/name&gt; &lt;value&gt;*&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.groups&lt;/name&gt; &lt;value&gt;*&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 修改 hdfs-site.xml 注：file后的路径下的/dfs/文件夹需要自己创建，所有节点均创建 12345678910111213141516171819202122232425262728293031323334&lt;configuration&gt; &lt;!-- 设置secondarynamenode的http通讯地址 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt; &lt;value&gt;hadoop0:9001&lt;/value&gt; &lt;/property&gt; &lt;!-- 设置namenode存放的路径 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;file:/usr/dfs/name&lt;/value&gt; &lt;/property&gt; &lt;!-- 设置datanode存放的路径 --&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;file:/usr/dfs/data&lt;/value&gt; &lt;/property&gt; &lt;!-- 设置hdfs副本数量 --&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;2&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.webhdfs.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.permissions&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.web.ugi&lt;/name&gt; &lt;value&gt;supergroup&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 修改 mapred-site.xml 注：要将mapred-site.xml.template重命名为 .xml的文件 mv mapred-site.xml.template mapred-site.xml 123456789101112131415&lt;configuration&gt; &lt;!-- 通知框架MR使用YARN --&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt; &lt;value&gt;hadoop0:10020&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt; &lt;value&gt;hadoop0:19888&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 修改 yarn-site.xml 1234567891011121314151617181920212223242526272829303132&lt;configuration&gt; &lt;!-- reducer取数据的方式是mapreduce_shuffle --&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt; &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt; &lt;value&gt;hadoop0:8032&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt; &lt;value&gt;hadoop0:8030&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt; &lt;value&gt;hadoop0:8031&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt; &lt;value&gt;hadoop0:8033&lt;/value&gt; &lt;/property&gt; &lt;!-- resourcemanager web访问端口 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt; &lt;value&gt;hadoop0:8088&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 修改 slaves 指定从节点：会运行 NodeManager 与 DataNode 组件 12hadoop1hadoop2 配置 hadoop 环境变量 1234567cat &gt;&gt; /etc/profile &lt;&lt; EOF# hadoop环境变量export HADOOP_HOME=/opt/hadoop-2.7.7/export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbinEOFsource /etc/profile 拷贝文件到其它节点 1234567# 拷贝hadoop-2.7.scp -r /opt/hadoop-2.7.7/ root@hadoop1:/opt/scp -r /opt/hadoop-2.7.7/ root@hadoop2:/opt/# 拷贝profile文件，之后需要在其它节点执行：source /etc/profile 使配置生效scp /etc/profile root@hadoop1:/etc/scp /etc/profile root@hadoop2:/etc/ 格式化主节点的namenode，我的主节点是 192.168.40.100 12345678# 主节点上进入hadoop目录cd /opt/hadoop-2.7.7/# 然后执行：提示：successfully formatted表示格式化成功./bin/hadoop namenode -format#新版本用下面的语句不用hadoop命令了./bin/hdfs namenode -format 启动与关闭 123cd /opt/hadoop-2.7.7/./sbin/start-all.sh./sbin/stop-all.sh 查看各节点进程 123456789101112# 主节点[root@hadoop0 hadoop]# jps4051 NameNode4389 ResourceManager9611 Jps4238 SecondaryNameNode# 两个子节点[root@hadoop1 hadoop]# jps1990 NodeManager3575 Jps1885 DataNode 如果全部启动成功，表示安装完成 访问 12345# 访问 hdfs web管理界面curl http://192.168.40.100:50070# 访问 yarn web管理界面curl http://192.168.40.100:8088 HA自动切换配置参考文档：https://blog.csdn.net/weixin_37838429/article/details/81710045 zk安装安装zookeeper 修改配置在192.168.40.100上执行 12mkdir /opt/HAcp -r /opt/hadoop-2.7.7/ /opt/HA 修改core-site.xml 1234567891011121314151617181920212223&lt;configuration&gt;&lt;!-- 把两个NameNode）的地址组装成一个集群mycluster --&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://mycluster&lt;/value&gt; &lt;/property&gt; &lt;!-- 声明journalnode服务本地文件系统存储目录--&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt; &lt;value&gt;/opt/HA/hadoop-2.7.7/data/jn&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定hadoop运行时产生文件的存储目录 --&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/opt/HA/hadoop-2.7.7/data/tmp&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt; &lt;value&gt;hadoop0:2181,hadoop1:2181,hadoop2:2181&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 修改hdfs-site.xml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071&lt;configuration&gt; &lt;!-- 完全分布式集群名称 --&gt; &lt;property&gt; &lt;name&gt;dfs.nameservices&lt;/name&gt; &lt;value&gt;mycluster&lt;/value&gt; &lt;/property&gt; &lt;!-- 集群中NameNode节点都有哪些 --&gt; &lt;property&gt; &lt;name&gt;dfs.ha.namenodes.mycluster&lt;/name&gt; &lt;value&gt;nn1,nn2&lt;/value&gt; &lt;/property&gt; &lt;!-- nn1的RPC通信地址 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.mycluster.nn1&lt;/name&gt; &lt;value&gt;hadoop0:8020&lt;/value&gt; &lt;/property&gt; &lt;!-- nn2的RPC通信地址 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.mycluster.nn2&lt;/name&gt; &lt;value&gt;hadoop1:8020&lt;/value&gt; &lt;/property&gt; &lt;!-- nn1的http通信地址 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.mycluster.nn1&lt;/name&gt; &lt;value&gt;hadoop0:50070&lt;/value&gt; &lt;/property&gt; &lt;!-- nn2的http通信地址 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.mycluster.nn2&lt;/name&gt; &lt;value&gt;hadoop1:50070&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定NameNode元数据在JournalNode上的存放位置 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt; &lt;value&gt;qjournal://hadoop0:8485;hadoop1:8485;hadoop2:8485/mycluster&lt;/value&gt; &lt;/property&gt; &lt;!-- 配置隔离机制，即同一时刻只能有一台服务器对外响应 --&gt; &lt;property&gt; &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt; &lt;value&gt;sshfence&lt;/value&gt; &lt;/property&gt; &lt;!-- 使用隔离机制时需要ssh无秘钥登录--&gt; &lt;property&gt; &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt; &lt;value&gt;/root/.ssh/id_rsa&lt;/value&gt; &lt;/property&gt; &lt;!-- 关闭权限检查--&gt; &lt;property&gt; &lt;name&gt;dfs.permissions.enable&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;/property&gt; &lt;!-- 访问代理类：client，mycluster，active配置失败自动切换实现方式--&gt; &lt;property&gt; &lt;name&gt;dfs.client.failover.proxy.provider.mycluster&lt;/name&gt; &lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 分发配置到其它机器上 启动步骤123456789101112131415161718# 关闭所有HDFS服务：sbin/stop-dfs.sh# 启动Zookeeper集群：bin/zkServer.sh start# 初始化HA在Zookeeper中状态，在master上执行bin/hdfs zkfc -formatZK# 启动HDFS服务：sbin/start-dfs.sh# 在各个NameNode节点上启动DFSZK Failover Controller，先在哪台机器启动，哪个机器的NameNode就是Active NameNode# 说明：如果使用start-dfs.sh启动集群，不需要单独启动zkfcsbin/hadoop-daemon.sh start zkfc# 验证:将Active NameNode进程killkill -9 namenode的进程id 常用命令1234567891011121314151617181920# 单独启动journalnodesbin/hadoop-daemon.sh start journalnode# 格式化bin/hdfs namenode -format# 单独启动namenodesbin/hadoop-daemon.sh start namenode# 在[nn2]上，同步nn1的元数据信息：bin/hdfs namenode -bootstrapStandby# 启动所有datenodesbin/hadoop-daemons.sh start datanode# 将[nn1]切换为Activebin/hdfs haadmin -transitionToActive nn1# 查看是否Activebin/hdfs haadmin -getServiceState nn1","categories":[{"name":"大数据","slug":"大数据","permalink":"https://hxqxiaoqi.gitee.io/categories/大数据/"}],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"https://hxqxiaoqi.gitee.io/tags/hadoop/"}],"keywords":[{"name":"大数据","slug":"大数据","permalink":"https://hxqxiaoqi.gitee.io/categories/大数据/"}]},{"title":"nginx重写与重定向","slug":"nginx重写与重定向","date":"2020-03-18T13:00:00.000Z","updated":"2020-07-24T04:07:46.663Z","comments":true,"path":"2020/03/18/nginx重写与重定向/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2020/03/18/nginx重写与重定向/","excerpt":"","text":"介绍重写与重定向功能是现在大多数Web服务器都支持的一项功能，相对于其他产品而言,Nginx中的rewrite模块提供的功能在配置上更加的灵活自由,可定制性非常的高。它的实现方式也非常的简单,只需要通过rewrite指令根据Nginx提供的全局变量或自定义的变量,结合正则表达式以及进一步处理的标识就可以完成URL重写或重定向。 rewrite参数： last 本条规则匹配完成后继续向下匹配新的location URI规则 break 本条规则匹配完成后终止，不在匹配任何规则 redirect 返回302临时重定向 permanent 返回301永久重定向 注：当flag的值为last或break时，标识当前的设置为重写，当flag的值为redirect或permanent时表示重定向。 rewrite 重写123456789server &#123; listen 80; server_name localhost; index index.html index.htm; root html; if (!-e $request_filename)&#123; rewrite \"^/.*\" /default/default.html break; &#125;&#125; 上述第6行配置,通过if指令判断访问不到用户请求的文件或目录时,执行第7行指令。其中,!-e用于判断不存在指定的文件或目录时，执行if块内的语句。内置变量$request_ filename 表示当前请求的文件路径;^/.*用于匹配当前网站下的所有请求，/default/default.html用于替换符合指定规则的请求。 值得一提的是,if指令根据给定的条件进行判断,如果判断结果为true,则执行大括号“{}”内的指令。当判断条件仅是一个变量时,如果值为空或任何以0开头的字符串都会当做false,不再执行大括号内的指令。 在根目录下创建default目录，并在该目录下编写default.html文件： 1&lt;h1&gt;Welcome to html/default/default.html!&lt;/h&gt; 访问一个不存在的文件：localhost/ffff.df break和last标识的区别： 在使用rewrite实现重写时,需要注意flag可选参数值break和last的区别，前者在rewrite指令匹配成功后就不再进行匹配，而后者在rewrite后会根据rewrite匹配的规则重新发起一个请求继续进行匹配。为了明确地看到两者的区别，下面通过二个案例进行验证。 12345678910111213141516server &#123; listen 80; server_name localhost; root html; location /break/ &#123; rewrite ^/break/(.*) /test/$1 break; echo \"break page\"; &#125; location /last/ &#123; rewrite ^/last/(.*) /test/$1 last; echo \"last page\"; &#125; location /test/ &#123; echo \"test page\"; &#125;&#125; 当用户的请求符合第5行location 规则时,执行第6行rewrite指令后，根据break的指定,继续执行第7行配置。而当用户的请求符合第9行location规则时,执行第10行rewrite指令后,根据last的指定,按照匹配到的替换算法发起一个新的请求http://test. ng. test/ test/ last. html,最终匹配到第13行的location规则,然后执行第14行的echo输出语句。 因此,在实际使用rewrite配置重写时，要根据实际情况选择合适的flag可选参数值，，否则会造成与预期不一样的结果。 rewrite重定向1234567891011121314server &#123; listen 80; server_name localhost; root html; set $name $1; rewrite ^/img-([0-9]+).jpg$/img/$name.jpg permanent;&#125;# 域名重写server &#123; listen 80; server_name localhost; root html; rewrite ^/(.*)$ https://winbb.com/$1 permanent;&#125; 上述第5行配置，利用set指令为变量$name赋值，$1表示符合正则表达式第一个子模式的值，如第6行中的子模式([0-9]+ )匹配到的值,可以是2、45等由一个或多个数字组成的字符串。第6行用于在用户请求“http://localhost/img-数字. jpg”时，重定向到“http://localhost/img/数字jpg&quot;。 接下来，在localhost的网站目录中创建一个用于存放图片的img目录，然后在该目录中保存一个文件名为2.jpg的图片。为了测试当前配置是否成功，通过浏览器访问http://localhost/img-2. jpg，会跳转到http://localhost/img/2.jpg。 需要注意的是，redirect和permanent在使用时有一定的区别，前者返回的HTTP状态码是302(临时重定向),使得搜索引擎在抓取新内容的同时保留旧的网址,后者返回的HTTP状态码是，301(永久重定向)会让搜索引擎在抓取新内容的同时也将旧的网址永久替换为重定向之后的网址。","categories":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://hxqxiaoqi.gitee.io/tags/nginx/"}],"keywords":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}]},{"title":"canal adapter（同步到es）安装使用","slug":"canal adapter（同步到es）安装使用","date":"2020-03-18T12:00:00.000Z","updated":"2020-07-24T03:41:52.191Z","comments":true,"path":"2020/03/18/canal adapter（同步到es）安装使用/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2020/03/18/canal adapter（同步到es）安装使用/","excerpt":"","text":"介绍canal 1.1.1版本之后, 增加客户端数据落地的适配及启动功能, 目前支持功能: 客户端启动器 同步管理REST接口 日志适配器, 作为DEMO 关系型数据库的数据同步(表对表同步), ETL功能 HBase的数据同步(表对表同步), ETL功能 ElasticSearch多表数据同步,ETL功能 安装请先安装以下服务： 安装高可用教程 安装elasticsearch教程 安装canal adapter适配器123456# 下载地址wget https://github.com/alibaba/canal/releases/download/canal-1.1.4/canal.deployer-1.1.4.tar.gztar xf canal.deployer-1.1.4.tar.gz -C /data/canal.deployervim /data/canal.deployer/conf/application.yml# 修改以下配置 1234567891011121314151617181920212223242526272829303132333435363738394041server: port: 8081spring: jackson: date-format: yyyy-MM-dd HH:mm:ss time-zone: GMT+8 default-property-inclusion: non_nullcanal.conf: mode: tcp # kafka rocketMQ# canalServerHost为单机模式，zookeeperHosts为集群模式# canalServerHost: 127.0.0.1:11111 zookeeperHosts: 192.168.40.101:2181# mqServers: 127.0.0.1:9092 #or rocketmq# flatMessage: true batchSize: 500 syncBatchSize: 1000 retries: 0 timeout: accessKey: secretKey:# 源数据库信息 srcDataSources: defaultDS: url: jdbc:mysql://192.168.40.100:3306/test?useUnicode=true username: root password: 123123 canalAdapters: # instance的名称 - instance: elastic groups: - groupId: g1 outerAdapters: - name: logger # elasticsearch集群信息，9300需要es配置相应端口 - name: es hosts: 192.168.40.101:9300 properties: # mode: transport # or rest # security.auth: test:123456 cluster.name: canal-es 创建mysql–elasticsearch映射表文件 1vim /data/canal.deployer/conf/es/test.yml 12345678910dataSourceKey: defaultDSdestination: elasticgroupId:esMapping: _index: test _type: _doc _id: _id upsert: true sql: \"select a.id as _id,a.name,a.address from test a\" commitBatch: 3000 mysql表结构 123456CREATE TABLE `test` ( `id` int(11) NOT NULL, `name` varchar(200) NOT NULL, `address` varchar(1000) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; elasticsearch索引创建 123456789101112131415curl -XPUT http://127.0.0.1:9200/test -d '&#123; \"mappings\":&#123; \"_doc\":&#123; \"properties\":&#123; \"name\":&#123; \"type\":\"text\" &#125;, \"address\":&#123; \"type\":\"text\" &#125; &#125; &#125; &#125;&#125;' elastic配置文件 123456789cluster.name: canal-esnode.name: node-1network.host: 192.168.40.101http.port: 9200discovery.zen.ping.unicast.hosts: [\"192.168.40.101\"]transport.tcp.port: 9300transport.tcp.compress: truehttp.cors.enabled: truehttp.cors.allow-origin: \"*\" 启动 12/data/canal.deployer/bin/startup.sh/data/canal.deployer/bin/stop.sh 测试 在mysql插入记录 查看es文档数据","categories":[{"name":"中间件","slug":"中间件","permalink":"https://hxqxiaoqi.gitee.io/categories/中间件/"}],"tags":[{"name":"canal","slug":"canal","permalink":"https://hxqxiaoqi.gitee.io/tags/canal/"}],"keywords":[{"name":"中间件","slug":"中间件","permalink":"https://hxqxiaoqi.gitee.io/categories/中间件/"}]},{"title":"redis备份策略详解","slug":"redis备份策略详解","date":"2020-03-14T14:00:00.000Z","updated":"2020-07-24T03:49:07.048Z","comments":true,"path":"2020/03/14/redis备份策略详解/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2020/03/14/redis备份策略详解/","excerpt":"","text":"介绍redis有三种不同的数据持久化机制： rdb aof 混合持久化 rdb 持久化RDB 持久化可以在指定的时间间隔内生成数据集的时间点快照（point-in-time snapshot）。 RDB 的优点： RDB 是一个非常紧凑的文件，也就是数据保存的非常小，它保存了 Redis 在某个时间点上的数据集。 RDB 可以最大化 Redis 的性能：父进程在保存 RDB 文件时唯一要做的就是 fork 出一个子进程，然后这个子进程就会处理接下来的所有保存工作，父进程无须执行任何磁盘 I/O 操作。 RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。 RDB 的缺点： 如果你需要尽量避免在服务器故障时丢失数据，那么 RDB 不适合你。 虽然 Redis 允许你设置不同的保存点（save point）来控制保存 RDB 文件的频率， 但是， 因为RDB 文件需要保存整个数据集的状态， 所以它并不是一个轻松的操作。 因此你可能会至少 5 分钟才保存一次 RDB 文件。 在这种情况下， 一旦发生故障停机， 你就可能会丢失好几分钟的数据。每次保存 RDB 的时候，Redis 都要 fork() 出一个子进程，并由子进程来进行实际的持久化工作。 在数据集比较庞大时， fork() 可能会非常耗时，造成服务器在某某毫秒内停止处理客户端； 如果数据集非常巨大，并且 CPU 时间非常紧张的话，那么这种停止时间甚至可能会长达整整一秒。 aof 持久化AOF 持久化记录服务器执行的所有写操作命令，并在服务器启动时，通过重新执行这些命令来还原数据集。 AOF 的优点： 使用 AOF 持久化会让 Redis 变得非常耐久（much more durable）：你可以设置不同的 fsync 策略，比如无 fsync ，每秒钟一次 fsync ，或者每次执行写入命令时 fsync 。AOF 的默认策略为每秒钟 fsync 一次，在这种配置下，Redis 仍然可以保持良好的性能，并且就算发生故障停机，也最多只会丢失一秒钟的数据（ fsync 会在后台线程执行，所以主线程可以继续努力地处理命令请求）。 AOF 文件是一个只进行追加操作的日志文件（append only log）， 因此对 AOF 文件的写入不需要进行 seek ， 即使日志因为某些原因而包含了未写入完整的命令（比如写入时磁盘已满，写入中途停机，等等）， redis-check-aof 工具也可以轻易地修复这种问题。 Redis 可以在 AOF 文件体积变得过大时，自动地在后台对 AOF 进行重写： 重写后的新 AOF 文件包含了恢复当前数据集所需的最小命令集合。 整个重写操作是绝对安全的，因为 Redis 在创建新 AOF 文件的过程中，会继续将命令追加到现有的 AOF 文件里面，即使重写过程中发生停机，现有的 AOF 文件也不会丢失。 而一旦新 AOF 文件创建完毕，Redis 就会从旧 AOF 文件切换到新 AOF 文件，并开始对新 AOF 文件进行追加操作。 AOF 文件有序地保存了对数据库执行的所有写入操作， 这些写入操作以 Redis 协议的格式保存， 因此 AOF 文件的内容非常容易被人读懂， 对文件进行分析（parse）也很轻松。 导出（export） AOF 文件也非常简单： 举个例子， 如果你不小心执行了 FLUSHALL 命令， 但只要 AOF 文件未被重写， 那么只要停止服务器， 移除 AOF 文件末尾的 FLUSHALL 命令， 并重启 Redis ， 就可以将数据集恢复到 FLUSHALL 执行之前的状态。 AOF 的缺点： 对于相同的数据集来说，AOF 文件的体积通常要大于 RDB 文件的体积。根据所使用的 fsync 策略，AOF 的速度可能会慢于 RDB 。 在一般情况下， 每秒 fsync 的性能依然非常高， 而关闭 fsync 可以让 AOF 的速度和 RDB 一样快， 即使在高负荷之下也是如此。 不过在处理巨大的写入载入时，RDB 可以提供更有保证的最大延迟时间（latency）。AOF 在过去曾经发生过这样的 bug ： 因为个别命令的原因，导致 AOF 文件在重新载入时，无法将数据集恢复成保存时的原样。 （举个例子，阻塞命令 BRPOPLPUSH 就曾经引起过这样的 bug 。） 测试套件里为这种情况添加了测试： 它们会自动生成随机的、复杂的数据集， 并通过重新载入这些数据来确保一切正常。 虽然这种 bug 在 AOF 文件中并不常见， 但是对比来说， RDB 几乎是不可能出现这种 bug 的。 动态配置 为最新的 dump.rdb 文件创建一个备份。将备份放到一个安全的地方。执行以下两条命令：redis-cli&gt; CONFIG SET appendonly yesredis-cli&gt; CONFIG SET save “”确保命令执行之后，数据库的键的数量没有改变。确保写命令会被正确地追加到 AOF 文件的末尾。步骤 3 执行的第一条命令开启了 AOF 功能： Redis 会阻塞直到初始 AOF 文件创建完成为止， 之后 Redis 会继续处理命令请求， 并开始将写入命令追加到 AOF 文件末尾。步骤 3 执行的第二条命令用于关闭 RDB 功能。 这一步是可选的， 如果你愿意的话， 也可以同时使用 RDB 和 AOF 这两种持久化功能。别忘了在 redis.conf 中打开 AOF 功能！ 否则的话， 服务器重启之后， 之前通过 CONFIG SET 设置的配置就会被遗忘， 程序会按原来的配置来启动服务器。 save bgsave bgrewriteaof aof-use-rdb-preamble yes","categories":[{"name":"数据库","slug":"数据库","permalink":"https://hxqxiaoqi.gitee.io/categories/数据库/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://hxqxiaoqi.gitee.io/tags/redis/"}],"keywords":[{"name":"数据库","slug":"数据库","permalink":"https://hxqxiaoqi.gitee.io/categories/数据库/"}]},{"title":"route使用","slug":"route使用","date":"2020-02-28T07:00:00.000Z","updated":"2020-07-24T04:06:20.435Z","comments":true,"path":"2020/02/28/route使用/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2020/02/28/route使用/","excerpt":"","text":"linux:主机路由 主机路由是路由选择表中指向单个IP地址或主机名的路由记录。主机路由的Flags字段为H。例如，在下面的示例中，本地主机通过IP地址192.168.1.1的路由器到达IP地址为10.0.0.10的主机。 1234567# 添加route add -host 192.168.1.2 dev eth0 route add -host 10.20.30.148 gw 10.20.30.40# 删除route del -host 192.168.1.2 dev eth0 route del -host 10.20.30.148 gw 10.20.30.40 网络路由 网络路由是代表主机可以到达的网络。网络路由的Flags字段为N。例如，在下面的示例中，本地主机将发送到网络192.19.12的数据包转发到IP地址为192.168.1.1的路由器。 12345# 添加route add -net 100.96.174.0/24 gw 192.168.10.126# 删除route del -net 100.96.174.0/24 gw 192.168.10.126 默认路由 当主机不能在路由表中查找到目标主机的IP地址或网络路由时，数据包就被发送到默认路由（默认网关）上。默认路由的Flags字段为G。例如，在下面的示例中，默认路由是IP地址为192.168.1.1的路由器。 12345# 添加route add default gw 192.168.1.1 # 删除route del default gw 192.168.1.1 windows:网络路由 12345# 添加route add 100.117.144.0/24 192.168.10.124# 删除route del 100.117.144.0/24 192.168.10.124","categories":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}],"tags":[{"name":"route","slug":"route","permalink":"https://hxqxiaoqi.gitee.io/tags/route/"}],"keywords":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}]},{"title":"SkyWalking单点安装","slug":"SkyWalking单点安装","date":"2020-02-28T07:00:00.000Z","updated":"2020-07-24T04:05:31.404Z","comments":true,"path":"2020/02/28/SkyWalking单点安装/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2020/02/28/SkyWalking单点安装/","excerpt":"","text":"介绍随着微服务架构的流行，一些微服务架构下的问题也会越来越突出，比如一个请求会涉及多个服务，而服务本身可能也会依赖其他服务，整个请求路径就构成了一个网状的调用链，而在整个调用链中一旦某个节点发生异常，整个调用链的稳定性就会受到影响。 面对以上情况， 我们就需要一些可以帮助理解系统行为、用于分析性能问题的工具，以便发生故障的时候，能够快速定位和解决问题。这时候分布式追踪系统就该闪亮登场了。 SkyWalking 是针对分布式系统的 APM 系统，也被称为分布式追踪系统 全自动探针监控，不需要修改应用程序代码。查看支持的中间件和组件库列表：https://github.com/apache/incubator-skywalking 支持手动探针监控, 提供了支持 OpenTracing 标准的SDK。覆盖范围扩大到 OpenTracing-Java 支持的组件。查看OpenTracing组件支持列表：https://github.com/opentracing-contrib/meta 自动监控和手动监控可以同时使用，使用手动监控弥补自动监控不支持的组件，甚至私有化组件。 纯 Java 后端分析程序，提供 RESTful 服务，可为其他语言探针提供分析能力。 高性能纯流式分析 安装步骤安装环境 安装：jdk1.8 安装：elasticsearch-6.x 安装：SkyWalking 安装jdk1.8点击：安装jdk1.8 安装elasticsearch-6.x点击：安装elasticsearch-6.x 安装SkyWalking12345678# 下载wget https://archive.apache.org/dist/skywalking/6.4.0/apache-skywalking-apm-6.4.0.tar.gz# 解压tar xf apache-skywalking-apm-6.4.0.tar.gz -C /opt/# 修改配置文件vim /opt/apache-skywalking-apm-bin/config/application.yml 12345678910111213# 取消es配置的注释，使用es作为存储库storage: elasticsearch: nameSpace: $&#123;SW_NAMESPACE:\"my-application\"&#125; clusterNodes: $&#123;SW_STORAGE_ES_CLUSTER_NODES:192.168.10.131:9200&#125; protocol: $&#123;SW_STORAGE_ES_HTTP_PROTOCOL:\"http\"&#125; # 注释以下配置，h2为SkyWalking自用的存储库，存储在内存中# h2:# driver: $&#123;SW_STORAGE_H2_DRIVER:org.h2.jdbcx.JdbcDataSource&#125;# url: $&#123;SW_STORAGE_H2_URL:jdbc:h2:mem:skywalking-oap-db&#125;# user: $&#123;SW_STORAGE_H2_USER:sa&#125;# metadataQueryMaxSize: $&#123;SW_STORAGE_H2_QUERY_MAX_SIZE:5000&#125; 12345# 启动/opt/apache-skywalking-apm-bin/bin/startup.sh# 访问curl http://localhost:8080 客户端连接测试客户端说明： /opt/apache-skywalking-apm-bin/agent/目录是数据收集的服务客户端 要监控哪台服务器上的jar服务，就需要把该目录复制到被监控的服务器上 通过以下方式指定配置启动后，需要再访问被监控的服务，skywalking上才可接收到该请求信息。 方式一：手动指定配置启动 1234java -javaagent:/opt/apache-skywalking-apm-bin/agent/skywalking-agent.jar \\-Dskywalking.agent.service_name=eureka \\-Dskywalking.collector.backend_service=localhost:11800 \\-jar eureka-1.0.0-SNAPSHOT.jar -javaagent：指定agent地址 -Dskywalking.agent.service_name：指定要运行的服务名称，可自由定义 -Dskywalking.collector.backend_service：skywalking服务端连接地址 eureka-1.0.0-SNAPSHOT.jar：为测试用的jar包 方式二：修改配置文件启动 12vim /opt/apache-skywalking-apm-bin/agent/config/agent.config# 修改以下配置 12345# 定义服务名agent.service_name=$&#123;SW_AGENT_NAME:mmhsy-eureka-1.0.0-SNAPSHOT&#125;# 修改连接skywalking地址collector.backend_service=$&#123;SW_AGENT_COLLECTOR_BACKEND_SERVICES:localhost:11800&#125; 12# 启动java -javaagent:/opt/apache-skywalking-apm-bin/agent/skywalking-agent.jar -jar eureka-1.0.0-SNAPSHOT.jar 配置文件说明application.ymlOAP(Collector)链路数据归集器，主要用于数据落地，大部分都会选择 Elasticsearch 6，OAP配置文件为 /opt/apache-skywalking-apm-6.2.0/config/application.yml，配置单点的 OAP(Collector)配置如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788cluster: # 单节点模式 standalone: # zk用于管理collector集群协作. # zookeeper: # 多个zk连接地址用逗号分隔. # hostPort: localhost:2181 # sessionTimeout: 100000 # 分布式 kv 存储设施，类似于zk，但没有zk重型（除了etcd，consul、Nacos等都是类似功能） # etcd: # serviceName: $&#123;SW_SERVICE_NAME:\"SkyWalking_OAP_Cluster\"&#125; # 多个节点用逗号分隔, 如: 10.0.0.1:2379,10.0.0.2:2379,10.0.0.3:2379 # hostPort: $&#123;SW_CLUSTER_ETCD_HOST_PORT:localhost:2379&#125;core: default: # 混合角色：接收代理数据，1级聚合、2级聚合 # 接收者：接收代理数据，1级聚合点 # 聚合器：2级聚合点 role: $&#123;SW_CORE_ROLE:Mixed&#125; # Mixed/Receiver/Aggregator # rest 服务地址和端口 restHost: $&#123;SW_CORE_REST_HOST:localhost&#125; restPort: $&#123;SW_CORE_REST_PORT:12800&#125; restContextPath: $&#123;SW_CORE_REST_CONTEXT_PATH:/&#125; # gRPC 服务地址和端口 gRPCHost: $&#123;SW_CORE_GRPC_HOST:localhost&#125; gRPCPort: $&#123;SW_CORE_GRPC_PORT:11800&#125; downsampling: - Hour - Day - Month # 设置度量数据的超时。超时过期后，度量数据将自动删除. # 单位分钟 recordDataTTL: $&#123;SW_CORE_RECORD_DATA_TTL:90&#125; # 单位分钟 minuteMetricsDataTTL: $&#123;SW_CORE_MINUTE_METRIC_DATA_TTL:90&#125; # 单位小时 hourMetricsDataTTL: $&#123;SW_CORE_HOUR_METRIC_DATA_TTL:36&#125; # 单位天 dayMetricsDataTTL: $&#123;SW_CORE_DAY_METRIC_DATA_TTL:45&#125; # 单位月 monthMetricsDataTTL: $&#123;SW_CORE_MONTH_METRIC_DATA_TTL:18&#125; storage: elasticsearch: # elasticsearch 的集群名称 nameSpace: $&#123;SW_NAMESPACE:\"local-ES\"&#125; # elasticsearch 集群节点的地址及端口 clusterNodes: $&#123;SW_STORAGE_ES_CLUSTER_NODES:192.168.2.10:9200&#125; # elasticsearch 的用户名和密码 user: $&#123;SW_ES_USER:\"\"&#125; password: $&#123;SW_ES_PASSWORD:\"\"&#125; # 设置 elasticsearch 索引分片数量 indexShardsNumber: $&#123;SW_STORAGE_ES_INDEX_SHARDS_NUMBER:2&#125; # 设置 elasticsearch 索引副本数 indexReplicasNumber: $&#123;SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:0&#125; # 批量处理配置 # 每2000个请求执行一次批量 bulkActions: $&#123;SW_STORAGE_ES_BULK_ACTIONS:2000&#125; # 每 20mb 刷新一次内存块 bulkSize: $&#123;SW_STORAGE_ES_BULK_SIZE:20&#125; # 无论请求的数量如何，每10秒刷新一次堆 flushInterval: $&#123;SW_STORAGE_ES_FLUSH_INTERVAL:10&#125; # 并发请求的数量 concurrentRequests: $&#123;SW_STORAGE_ES_CONCURRENT_REQUESTS:2&#125; # elasticsearch 查询的最大数量 metadataQueryMaxSize: $&#123;SW_STORAGE_ES_QUERY_MAX_SIZE:5000&#125; # elasticsearch 查询段最大数量 segmentQueryMaxSize: $&#123;SW_STORAGE_ES_QUERY_SEGMENT_SIZE:200&#125; webapp.yml Skywalking 的 WebApp 主要是用来展示落地的数据，因此只需要配置 Web 的端口及获取数据的 OAP(Collector)的IP和端口，webApp 配置文件地址为 /opt/apache-skywalking-apm-6.2.0/webapp/webapp.yml 配置如下： 123456789101112131415server: port: 9000collector: path: /graphql ribbon: ReadTimeout: 10000 # 指向所有后端collector 的 restHost:restPort 配置，多个使用, 分隔 listOfServers: localhost:12800 security: user: # username admin: # password password: admin agent.configSkywalking 的 Agent 主要用于收集和发送数据到 OAP(Collector)，因此需要进行配置 Skywalking OAP(Collector)的地址，Agent 的配置文件地址为 /opt/apache-skywalking-apm-6.2.0/agent/config/agent.config，配置如下： 1234567891011121314151617# 设置Agent命名空间，它用来隔离追踪和监控数据，当两个应用使用不同的名称空间时，跨进程传播链会中断。agent.namespace=$&#123;SW_AGENT_NAMESPACE:default-namespace&#125; # 设置服务名称，会在 Skywalking UI 上显示的名称agent.service_name=$&#123;SW_AGENT_NAME:Your_ApplicationName&#125; # 每 3秒采集的样本跟踪比例，如果是负数则表示 100%采集agent.sample_n_per_3_secs=$&#123;SW_AGENT_SAMPLE:-1&#125; # 启用 Debug ，如果为 true 则将把所有检测到的类文件保存在\"/debug\"文件夹中# agent.is_open_debugging_class = $&#123;SW_AGENT_OPEN_DEBUG:true&#125; # 后端的 collector 端口及地址collector.backend_service=$&#123;SW_AGENT_COLLECTOR_BACKEND_SERVICES:192.168.2.215:11800&#125; # 日志级别logging.level=$&#123;SW_LOGGING_LEVEL:DEBUG&#125;","categories":[{"name":"监控","slug":"监控","permalink":"https://hxqxiaoqi.gitee.io/categories/监控/"}],"tags":[{"name":"SkyWalking","slug":"SkyWalking","permalink":"https://hxqxiaoqi.gitee.io/tags/SkyWalking/"}],"keywords":[{"name":"监控","slug":"监控","permalink":"https://hxqxiaoqi.gitee.io/categories/监控/"}]},{"title":"监控redis存活脚本","slug":"监控redis存活脚本","date":"2020-01-23T09:58:55.000Z","updated":"2020-07-24T03:39:54.227Z","comments":true,"path":"2020/01/23/监控redis存活脚本/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2020/01/23/监控redis存活脚本/","excerpt":"","text":"介绍redis监控状态脚本 脚本12345678910111213141516171819202122232425262728293031323334353637#!/bin/bash#redis主从切换报警脚本#sendEmail命令下载链接：http://caspian.dotconf.net/menu/Software/SendEmail/sendEmail-v1.56.tar.gz#获取redis主从状态值role=`/data/redis32/bin/redis-cli -p 6379 info replication|grep role|cut -d \":\" -f 2|tr -d -c 'a-zA-z'`#获取本机IPlocalIP=`/sbin/ifconfig -a|grep inet|grep -v 127.0.0.1|grep -v inet6|awk '&#123;print $2&#125;'|tr -d \"addr:\"`#改文件用于判断redis状态if [ ! -e \"/tmp/redis_err\" ];then echo 0 &gt; /tmp/redis_errfidir=\"/tmp/redis_err\"#拥有判断是否执行过邮件发送，如果存在，则不发送邮件，需要手动删除err=`cat /tmp/redis_err`if [ \"$role\" == \"slave\" ];then if [ ! \"$err\" == 1 ];then /usr/local/bin/sendEmail -o message-charset=utf8 -f 123.com -t 123.com -s smtp.mamahao.com -u 'redis主从切换' -xu '123.com' -xp '123.1234' -m \"IP：$localIP date：`date` redis主切换为从\" echo 1 &gt; $dir fielif [ \"$role\" == \"master\" ];then if [ \"$err\" == 0 ];then echo 0 &gt; $dir elif [ ! \"$err\" == 0 ];then /usr/local/bin/sendEmail -o message-charset=utf8 -f 123.com -t 123.com -s smtp.mamahao.com -u 'redis主从切换' -xu '123.com' -xp '123.1234' -m \"IP：$localIP date：`date` redis从切换为主\" echo 0 &gt; $dir fielse if [ ! \"$err\" == 2 ];then /usr/local/bin/sendEmail -o message-charset=utf8 -f 123.com -t 123.com -s smtp.mamahao.com -u 'redis故障' -xu '123.com' -xp '123.1234' -m \"IP：$localIP date：`date` 故障：无法获取主从状态\" echo 2 &gt; $dir fifi","categories":[{"name":"脚本","slug":"脚本","permalink":"https://hxqxiaoqi.gitee.io/categories/脚本/"}],"tags":[{"name":"shell脚本","slug":"shell脚本","permalink":"https://hxqxiaoqi.gitee.io/tags/shell脚本/"}],"keywords":[{"name":"脚本","slug":"脚本","permalink":"https://hxqxiaoqi.gitee.io/categories/脚本/"}]},{"title":"通用备份脚本","slug":"通用备份脚本","date":"2020-01-23T09:57:55.000Z","updated":"2020-07-24T03:40:05.026Z","comments":true,"path":"2020/01/23/通用备份脚本/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2020/01/23/通用备份脚本/","excerpt":"","text":"介绍日志备份通用脚本 脚本以下脚本添加到定时任务即可 12345678910111213141516171819#!/usr/bin/bash# 通用备份脚本# 日志目录dir=\"/root/.pm2/logs\"# 保存日志的时间Tday=`date --date=\"1 days ago\" \"+%Y_%m_%d\"`# 删除日志的时间Tday2=`date --date=\"7 days ago\" \"+%Y_%m_%d\"`log=`ls $dir|grep \"^.*log$\"`cd $dirfor i in $logdo cp -a $i \"$i\"_$Tday echo \"\" &gt; $i rm -rf \"$i\"_$Tday2 done","categories":[{"name":"脚本","slug":"脚本","permalink":"https://hxqxiaoqi.gitee.io/categories/脚本/"}],"tags":[{"name":"shell脚本","slug":"shell脚本","permalink":"https://hxqxiaoqi.gitee.io/tags/shell脚本/"}],"keywords":[{"name":"脚本","slug":"脚本","permalink":"https://hxqxiaoqi.gitee.io/categories/脚本/"}]},{"title":"oss安装","slug":"oss命令工具","date":"2020-01-23T09:00:00.000Z","updated":"2020-07-24T04:07:15.895Z","comments":true,"path":"2020/01/23/oss命令工具/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2020/01/23/oss命令工具/","excerpt":"","text":"介绍oss是阿里云存储服务，可以使用客户端或命令行工具上传下载文件。 使用下载 123wget http://gosspublic.alicdn.com/ossutil/1.6.10/ossutil64?spm=a2c4g.11186623.2.12.3467448aqUzNnHmv ossutil64?spm=a2c4g.11186623.2.12.3467448aqUzNnH ossutil64chmod 755 ossutil64 注册 12345678# 配置信息ossutil64 config# 创建的bucket上可以看到endpoint信息endpoint=oss-cn-hangzhou-fawefwae.aliyuncs.com# 登录账号设置accessKeyID=efwaefawaccessKeySecret=efawefawefwae 上传 1ossutil64 cp delete_promoter_memcache.py oss://aliyun-mysql-storage 下载 1/usr/local/bin/ossutil64 cp oss://aliyun-mysql-storage/test.sql.gz .","categories":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}],"tags":[{"name":"阿里云","slug":"阿里云","permalink":"https://hxqxiaoqi.gitee.io/tags/阿里云/"}],"keywords":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}]},{"title":"elasticstarch执行语句","slug":"elasticsearch执行语句","date":"2020-01-22T03:00:00.000Z","updated":"2020-07-24T03:59:24.186Z","comments":true,"path":"2020/01/22/elasticsearch执行语句/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2020/01/22/elasticsearch执行语句/","excerpt":"","text":"介绍索引是ElasticSearch存放数据的地方，可以理解为关系型数据库中的一个数据库。 es与数据库对应关系 数据库类型 库名 表名 记录 字段 Relational DB Databases Tables Rows Columns Elasticsearch Indices Types Documents Fields 文档元数据 一个文档不只有数据。它还包含了元数据(metadata)——关于文档的信息。三个必须的元数据节点是（其实就是数据库字段）： 节点 说明 _index 文档存储的地方 _type 文档代表的对象的类 _id 文档的唯一标识 索引创建原则 类似的数据放在一个索引，非类似的数据放不同索引：product index（包含了所有的商品），sales index（包含了所有的商品销售数据），inventory index（包含了所有库存相关的数据）。如果你把比如product，sales，human resource（employee），全都放在一个大的index里面，比如说company index，不合适的。 index中包含了很多类似的document：类似是什么意思，其实指的就是说，这些document的fields很大一部分是相同的，你说你放了3个document，每个document的fields都完全不一样，这就不是类似了，就不太适合放到一个index里面去了。 索引名称必须是小写的，不能用下划线开头，不能包含逗号：product，website，blog 语法示例运维相关查看ES集群中所有节点信息，以及各个节点内存和CPU相关的指标 1curl -X GET 'http://192.168.40.100:9200/_cat/nodes?v' 查看整个ES集群的状态，以及节点、分片等信息 1curl -XGET 'http://192.168.40.100:9200/_cluster/health?pretty' 如果集群状态不正常了（status是yellow或者red），可以通过以下命令查看具体是哪个index中的哪些shard出问题了： 12curl -XGET 'http://192.168.40.100:9200/_cluster/health?pretty&amp;level=indices' curl -XGET 'http://192.168.40.100:9200/_cluster/health?pretty&amp;level=shards' 列出ES集群中所有的index信息 1curl -XGET 'http://192.168.40.100:9200/_cat/indices?v' 显示索引的别名信息、过滤器和路由信息 1GET _cat/aliases?v 查看每个节点的分片数量以及每个节点的磁盘空间使用情况 1GET _cat/allocation?v 查看索引或集群的文档数量 12345# 查询全部GET _cat/count?v# 查询单个索引GET _cat/count/books?v 查看每个数据节点上被fielddata所使用的堆内存大小 1GET _cat/fielddata?v 显示master节点的id、ip和节点名 1GET _cat/master?v 返回集群中各节点信息 1GET _cat/nodes?v 查看节点所运行插件信息 1GET /_cat/plugins?v 查看索引分片恢复进度 1GET /_cat/recovery?v 查看集群中的快照库 1GET /_cat/repositories?v 查看集群每个节点的线程池统计信息 1GET /_cat/thread_pool?v 查看集群中每个节点的分片信息，包括分片名称、编号、是否是主分片、状态、文档数据、空间大小、所有节点ip、节点名称 1GET /_cat/shards?v 查看索引的segment信息，注意，索引数据实际上是以一个个segment的方式进行存储的 1GET /_cat/segments?v 查看集群的健康状态 1GET /_cluster/health 返回集群的完整状态信息。 1GET /_cluster/state 返回集群的完整状态信息。 1GET /_cluster/state/version 获取各种统计数据。包括两部分数据： 索引层面：分片数、存储大小、内存使用等； 节点层面：节点数量、节点角色、操作系统、jvm信息、内存、CPU、插件等； 1GET /_cluster/stats 明确地执行集群重新路由分配命令。 1POST /_cluster/reroute 更新集群中的配置，如果是永久配置，需要重启集群；临时配置的訞 不不需要重启集群 123456PUT /_cluster/settings&#123; \"persistent\": &#123; \"discovery.zen.minimum_master_nodes\":1 &#125;&#125; 统计集群中一个或多个节点的统计信息。 1GET /_nodes 或： 1GET /_nodes/es01,es02 获取集群中正在节点中执行的任务信息。 1GET /_tasks 查看分片没有被分配的原因，比如通过GET /_cat/shards?v看到某个索引没有被分配，就可以使用下面的命令来查看没有被分配的原因。 123456GET /_cluster/allocation/explain&#123; \"index\":\"twitter\", \"shard\":0, \"primary\":true&#125; 创建索引 1curl -X PUT \"http://192.168.40.100:9200/索引名?pretty\" 删除索引 1curl -XDELETE 'http://192.168.40.100:9200/索引名' 关闭索引 1curl -XPOST 'http://192.168.40.100:9200/索引名/_close' 开启索引 1curl -XPOST 'http://192.168.40.100:9200/索引名/_open' 动态修改ES相关配置 1curl -XPUT 'http://192.168.40.100:9200/索引名/_settings' -d '&#123;\"index\":&#123;\"refresh_interval\":\"60s\"&#125;&#125;' 设置最大查询条数 1curl -XPUT 'http://192.168.40.100:9200/索引名/_settings' -d'&#123;\"index\":&#123;\"max_result_window\":1000000&#125;&#125;' 设置默认副本和分片 123456789101112131415curl -XPOST http://192.168.40.100:9200/_template/template_http_request_record -H 'Content-Type: application/json' -d '&#123; \"order\": 0, \"index_patterns\": [ \"*\" #匹配的索引 ], \"settings\": &#123; \"index\": &#123; \"number_of_shards\": \"5\", \"number_of_replicas\": \"0\" &#125; &#125;, \"mappings\": &#123;&#125;, \"aliases\": &#123;&#125;&#125;' 变更之前的副本数 1curl -XPUT http://192.168.40.100:9200/_settings -H 'Content-Type: application/json' -d '&#123;\"index\":&#123;\"number_of_replicas\":0&#125;&#125;' 基本语法查询语法参考该文档 查询文档 1curl -XGET 'http://192.168.40.100:9200/索引名/类型/ID' 新增文档 12345678curl -XPOST 'http://192.168.40.100:9200/索引名/类型/ID?pretty' -d '&#123;\"zbbm\": \"10010103Y\",\"zzid\": \"0600\",\"tjqj\": \"201712\",\"gwxd\": 3124543444.71,\"nbys\":2073344433.12&#125;' 删除文档 1curl -XDELETE 'http://192.168.40.100:9200/索引名/类型/ID' 修改文档 1234567curl -XPOST 'http://192.168.40.100:9200/索引名/类型/ID/_update' -d '&#123;\"doc\":&#123;\"gwxd\":1237674.23,\"nbys\": 123233221212&#125;&#125;'","categories":[{"name":"数据库","slug":"数据库","permalink":"https://hxqxiaoqi.gitee.io/categories/数据库/"}],"tags":[{"name":"es","slug":"es","permalink":"https://hxqxiaoqi.gitee.io/tags/es/"}],"keywords":[{"name":"数据库","slug":"数据库","permalink":"https://hxqxiaoqi.gitee.io/categories/数据库/"}]},{"title":"elasticstarch集群搭建","slug":"elasticsearch集群搭建","date":"2020-01-22T01:00:00.000Z","updated":"2020-07-24T03:52:46.498Z","comments":true,"path":"2020/01/22/elasticsearch集群搭建/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2020/01/22/elasticsearch集群搭建/","excerpt":"","text":"介绍针对一个索引，Elasticsearch 中其实有专门的衡量索引健康状况的标志，分为三个等级： green，绿色。这代表所有的主分片和副本分片都已分配。你的集群是 100% 可用的。 yellow，黄色。所有的主分片已经分片了，但至少还有一个副本是缺失的。不会有数据丢失，所以搜索结果依然是完整的。不过，你的高可用性在某种程度上被弱化。如果更多的分片消失，你就会丢数据了。所以可把 yellow 想象成一个需要及时调查的警告。 red，红色。至少一个主分片以及它的全部副本都在缺失中。这意味着你在缺少数据：搜索只能返回部分数据，而分配到这个分片上的写入请求会返回一个异常。 如果你只有一台主机的话，其实索引的健康状况也是 yellow，因为一台主机，集群没有其他的主机可以防止副本，所以说，这就是一个不健康的状态，因此集群也是十分有必要的。 搭建步骤主机环境： jdk + es：192.168.40.100 jdk + es：192.168.40.101 jdk + es：192.168.40.102 安装步骤： 参考elasticsearch安装 在两台主机上安装 修改配置文件 192.168.40.100配置文件 12345678910111213141516171819202122232425262728# ======================== Elasticsearch Configuration ========================= # 集群名称 cluster.name: mmh-es # 节点名称，不同节点命名不能一样 node.name: node-1# ----------------------------------- Memory ----------------------------------- #因为centos6.x操作系统不支持SecComp，而elasticsearch5.5.2默认bootstrap.system_call_filter为true进行检测，所以导致检测失败，失败后直接导致ES不能启动。 bootstrap.memory_lock: false bootstrap.system_call_filter: false # 当前节点Ip，不同节点配置不一样 network.host: 192.168.40.100 # 设置对外服务的http端口,默认为9200 http.port: 9200 # 设置节点间交互的tcp端口,默认是9300 transport.tcp.port: 9300 # 这是一个集群中的主节点的初始列表,当节点(主节点或者数据节点)启动时使用这个列表进行探测 discovery.zen.ping.unicast.hosts: [\"192.168.40.100\",\"192.168.40.101\",\"192.168.40.102\"] # 设置这个参数来保证集群中的节点可以知道其它N个有master资格的节点.默认为1,对于大的集群来说,可以设置大一点的值(2-4) discovery.zen.minimum_master_nodes: 1 #使用head等插件监控集群信息，需要打开以下配置项 http.cors.enabled: true http.cors.allow-origin: \"*\" 192.168.40.101配置文件 其它与192.168.40.100配置一致 12node.name: node-2network.host: 192.168.40.101 192.168.40.102配置文件 其它与192.168.40.100配置一致 12node.name: node-3network.host: 192.168.40.102 安装head插件由于head插件本质上还是一个nodejs的工程，因此需要安装node，使用npm来安装依赖的包。（npm可以理解为maven） 在192.168.40.100操作 node安装 123456789101112# 下载nodejs最新的bin包wget https://nodejs.org/dist/v9.3.0/node-v9.3.0-linux-x64.tar.xz # 解压xz -d node-v9.3.0-linux-x64.tar.xztar -xf node-v9.3.0-linux-x64.tar# 部署bin文件，先确定nodejs的bin路径ln -s ~/node-v9.3.0-linux-x64/bin/node /usr/bin/node ln -s ~/node-v9.3.0-linux-x64/bin/npm /usr/bin/npm# npm加速 全局安装cnpm 指定来源淘宝镜像npm install -g cnpm --registry=https://registry.npm.taobao.org elasticsearch-head安装 1234cd /usr/local/git clone git://github.com/mobz/elasticsearch-head.gitcd elasticsearch-headnpm install 注： 5.0以上，elasticsearch-head 不能放在elasticsearch的 plugins、modules 目录下，否则elasticsearch启动会报错。 这里如果grunt没有安装成功也无所谓，可以通过其他方式启动elasticsearch-head插件（npm run start）。 grunt安装 1234# grunt是一个很方便的构建工具，可以进行打包压缩、测试、执行等等的工作，5.0里的head插件就是通过grunt启动的。cd /usr/local/elasticsearch-headnpm install -g grunt-cli //执行后会生成node_modules文件夹npm install 修改配置 123cd /usr/local/elasticsearch-headvim _site/app.js# 修改以下内容 12# 这里的 localhost 是指进入elasticsearch-head页面时默认访问的ES集群地址，把他修改为其中一台ES节点的地址即可this.base_uri = this.config.base_uri || this.prefs.get(\"app-base_uri\") || \"http://192.168.40.100:9200\"; 123cd /usr/local/elasticsearch-headvim Gruntfile.js# 修改以下内容 12345678910connect: &#123; server: &#123; options: &#123; port: 9100, base: '.', keepalive: true, hostname: '*' &#125; &#125;&#125; 启动 123cd /usr/local/elasticsearch-head # 若想在后台运行，结尾追加“&amp;”,也可以使用 npm run start启动grunt server 访问 12# 到浏览器访问curl http://192.168.40.100:9100 验证 访问，有两个节点即成功 head可以操作和查看es的所有索引 集群备份和恢复备份es集群是使用snapshot API快照功能，需要一个共同的数据保存仓库，可以是： 共享文件系统，比如 NAS，NFS Amazon S3 HDFS (Hadoop 分布式文件系统) Azure Cloud 这里，我们使用NFS做共享仓库，服务地址为：192.168.40.103，注意，需要集群外的NFS服务端提供目录共享，集群内搭建的NFS服务端会连接报错。 NFS 搭建 NFS 搭建教程跳转 创建es系统仓库 1234567PUT _snapshot/my_backup &#123; \"type\": \"fs\", \"settings\": &#123; \"location\": \"/mount/backups/my_backup\" &#125;&#125; _snapshot es快照接口 my_backup 快照仓库，自定义 /mount/backups/my_backup NFS共享目录挂在地址，自定义，注意：共享文件系统路径必须确保集群所有节点都可以访问到。 快照备份 12345678# 备份索引打开索引PUT _snapshot/my_backup/snapshot_1# 备份单个索引PUT _snapshot/my_backup/snapshot_2&#123; \"indices\": \"index_1,index_2\"&#125; snapshot_1 快照名称，自定义 查看快照 1GET _snapshot/my_backup/snapshot_2 删除快照 1DELETE _snapshot/my_backup/snapshot_2 恢复快照 12345678910# 恢复所有索引POST _snapshot/my_backup/snapshot_1/_restore# 恢复单个索引POST /_snapshot/my_backup/snapshot_1/_restore&#123; \"indices\": \"index_1\", \"rename_pattern\": \"index_(.+)\", \"rename_replacement\": \"restored_index_$1\" &#125; 只恢复 index_1 索引，忽略快照中存在的其余索引。 查找所提供的模式能匹配上的正在恢复的索引。 然后把它们重命名成替代的模式。 这个会恢复 index_1 到你及群里，但是重命名成了 restored_index_1 。","categories":[{"name":"数据库","slug":"数据库","permalink":"https://hxqxiaoqi.gitee.io/categories/数据库/"}],"tags":[{"name":"es","slug":"es","permalink":"https://hxqxiaoqi.gitee.io/tags/es/"}],"keywords":[{"name":"数据库","slug":"数据库","permalink":"https://hxqxiaoqi.gitee.io/categories/数据库/"}]},{"title":"RocketMQ分布式部署","slug":"RocketMQ分布式部署","date":"2020-01-21T08:00:00.000Z","updated":"2020-07-24T06:22:55.285Z","comments":true,"path":"2020/01/21/RocketMQ分布式部署/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2020/01/21/RocketMQ分布式部署/","excerpt":"","text":"介绍RocketMQ的多Master多Slave的模式在Linux服务器部署案例进行详细的说明。 部署步骤主机环境： Nameserver1 + Master1 + Master2-Slave：192.168.40.100 Nameserver2 + Master2 + Master1-Slave：192.168.40.101 系统环境： 64位JDK 1.8+; Maven 3.6.x; git； 操作步骤： 全部安装jdk 全部安装maven 全部安装RocketMQ，修改配置 安装web管理服务 jdk安装jdk安装跳转 maven安装maven安装跳转 RocketMQ分布式安装下载 RocketMQ安装参考 两台主机按文档安装 创建数据目录 在192.168.40.100操作 1234# Master1数据目录mkdir -p /data/rocketmq/data/&#123;commitlog,consumequeue,index&#125;# Master2-Slave数据目录mkdir -p /data/rocketmq/datas/&#123;commitlog,consumequeue,index&#125; 在192.168.40.101操作 1234# Master2数据目录mkdir -p /data/rocketmq/data/&#123;commitlog,consumequeue,index&#125;# Master1-Slave数据目录mkdir -p /data/rocketmq/datas/&#123;commitlog,consumequeue,index&#125; 修改配置文件 在192.168.40.100操作 12# 修改Master1配置vim /data/rocketmq/conf/2m-2s-async/broker-a.properties 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263#所属集群名字brokerClusterName=rocketmq-cluster#broker名字，注意此处不同的配置文件填写的不一样brokerName=broker-a#0 表示 Master，&gt;0 表示 SlavebrokerId=0#nameServer地址，分号分割namesrvAddr=192.168.40.100:9876;192.168.40.101:9876#在发送消息时，自动创建服务器不存在的topic，默认创建的队列数defaultTopicQueueNums=4#是否允许 Broker 自动创建Topic，建议线下开启，线上关闭autoCreateTopicEnable=true#是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭autoCreateSubscriptionGroup=true#Broker 对外服务的监听端口listenPort=10911haListenPort=10912#删除文件时间点，默认凌晨 4点deleteWhen=04#文件保留时间，默认 48 小时fileReservedTime=18#commitLog每个文件的大小默认1GmapedFileSizeCommitLog=1073741824#ConsumeQueue每个文件默认存30W条，根据业务情况调整mapedFileSizeConsumeQueue=300000#destroyMapedFileIntervalForcibly=120000#redeleteHangedFileInterval=120000#检测物理文件磁盘空间diskMaxUsedSpaceRatio=88#存储路径storePathRootDir=/mnt/rocketmq-all-4.6.0-bin-release/data#commitLog 存储路径storePathCommitLog=/mnt/rocketmq-all-4.6.0-bin-release/data/commitlog#消费队列存储路径存储路径storePathConsumeQueue=/mnt/rocketmq-all-4.6.0-bin-release/data/consumequeue#消息索引存储路径storePathIndex=/mnt/rocketmq-all-4.6.0-bin-release/data/index#checkpoint 文件存储路径storeCheckpoint=/mnt/rocketmq-all-4.6.0-bin-release/data/checkpoint#abort 文件存储路径abortFile=/mnt/rocketmq-all-4.6.0-bin-release/data/abort#限制的消息大小maxMessageSize=65536#flushCommitLogLeastPages=4#flushConsumeQueueLeastPages=2#flushCommitLogThoroughInterval=10000#flushConsumeQueueThoroughInterval=60000#Broker 的角色#- ASYNC_MASTER 异步复制Master#- SYNC_MASTER 同步双写Master#- SLAVEbrokerRole=SYNC_MASTER#刷盘方式#- ASYNC_FLUSH 异步刷盘#- SYNC_FLUSH 同步刷盘flushDiskType=ASYNC_FLUSH#checkTransactionMessageEnable=false#发消息线程池数量#sendMessageThreadPoolNums=128#拉消息线程池数量#pullMessageThreadPoolNums=128#强制指定本机IP，需要根据每台机器进行修改。官方介绍可为空，系统默认自动识别，但多网卡时IP地址可能读取错误brokerIP1=192.168.40.100 12# 修改Master2-Slave配置vim /data/rocketmq/conf/2m-2s-async/broker-b-s.properties 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263#所属集群名字brokerClusterName=rocketmq-cluster#broker名字，注意此处不同的配置文件填写的不一样brokerName=broker-b#0 表示 Master，&gt;0 表示 SlavebrokerId=1#nameServer地址，分号分割namesrvAddr=192.168.40.100:9876;192.168.40.101:9876#在发送消息时，自动创建服务器不存在的topic，默认创建的队列数defaultTopicQueueNums=4#是否允许 Broker 自动创建Topic，建议线下开启，线上关闭autoCreateTopicEnable=true#是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭autoCreateSubscriptionGroup=true#Broker 对外服务的监听端口listenPort=10923haListenPort=10924#删除文件时间点，默认凌晨 4点deleteWhen=04#文件保留时间，默认 48 小时fileReservedTime=18#commitLog每个文件的大小默认1GmapedFileSizeCommitLog=1073741824#ConsumeQueue每个文件默认存30W条，根据业务情况调整mapedFileSizeConsumeQueue=300000#destroyMapedFileIntervalForcibly=120000#redeleteHangedFileInterval=120000#检测物理文件磁盘空间diskMaxUsedSpaceRatio=88#存储路径storePathRootDir=/mnt/rocketmq-all-4.6.0-bin-release/datas#commitLog 存储路径storePathCommitLog=/mnt/rocketmq-all-4.6.0-bin-release/datas/commitlog#消费队列存储路径存储路径storePathConsumeQueue=/mnt/rocketmq-all-4.6.0-bin-release/datas/consumequeue#消息索引存储路径storePathIndex=/mnt/rocketmq-all-4.6.0-bin-release/datas/index#checkpoint 文件存储路径storeCheckpoint=/mnt/rocketmq-all-4.6.0-bin-release/datas/checkpoint#abort 文件存储路径abortFile=/mnt/rocketmq-all-4.6.0-bin-release/datas/abort#限制的消息大小maxMessageSize=65536#flushCommitLogLeastPages=4#flushConsumeQueueLeastPages=2#flushCommitLogThoroughInterval=10000#flushConsumeQueueThoroughInterval=60000#Broker 的角色#- ASYNC_MASTER 异步复制Master#- SYNC_MASTER 同步双写Master#- SLAVEbrokerRole=SLAVE#刷盘方式#- ASYNC_FLUSH 异步刷盘#- SYNC_FLUSH 同步刷盘flushDiskType=ASYNC_FLUSH#checkTransactionMessageEnable=false#发消息线程池数量#sendMessageThreadPoolNums=128#拉消息线程池数量#pullMessageThreadPoolNums=128#强制指定本机IP，需要根据每台机器进行修改。官方介绍可为空，系统默认自动识别，但多网卡时IP地址可能读取错误brokerIP1=192.168.40.100 在192.168.40.101操作 12# 修改Master2配置vim /data/rocketmq/conf/2m-2s-async/broker-b.properties 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263#所属集群名字brokerClusterName=rocketmq-cluster#broker名字，注意此处不同的配置文件填写的不一样brokerName=broker-b#0 表示 Master，&gt;0 表示 SlavebrokerId=0#nameServer地址，分号分割namesrvAddr=192.168.40.100:9876;192.168.40.101:9876#在发送消息时，自动创建服务器不存在的topic，默认创建的队列数defaultTopicQueueNums=4#是否允许 Broker 自动创建Topic，建议线下开启，线上关闭autoCreateTopicEnable=true#是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭autoCreateSubscriptionGroup=true#Broker 对外服务的监听端口listenPort=10911haListenPort=10912#删除文件时间点，默认凌晨 4点deleteWhen=04#文件保留时间，默认 48 小时fileReservedTime=18#commitLog每个文件的大小默认1GmapedFileSizeCommitLog=1073741824#ConsumeQueue每个文件默认存30W条，根据业务情况调整mapedFileSizeConsumeQueue=300000#destroyMapedFileIntervalForcibly=120000#redeleteHangedFileInterval=120000#检测物理文件磁盘空间diskMaxUsedSpaceRatio=88#存储路径storePathRootDir=/mnt/rocketmq-all-4.6.0-bin-release/data#commitLog 存储路径storePathCommitLog=/mnt/rocketmq-all-4.6.0-bin-release/data/commitlog#消费队列存储路径存储路径storePathConsumeQueue=/mnt/rocketmq-all-4.6.0-bin-release/data/consumequeue#消息索引存储路径storePathIndex=/mnt/rocketmq-all-4.6.0-bin-release/data/index#checkpoint 文件存储路径storeCheckpoint=/mnt/rocketmq-all-4.6.0-bin-release/data/checkpoint#abort 文件存储路径abortFile=/mnt/rocketmq-all-4.6.0-bin-release/data/abort#限制的消息大小maxMessageSize=65536#flushCommitLogLeastPages=4#flushConsumeQueueLeastPages=2#flushCommitLogThoroughInterval=10000#flushConsumeQueueThoroughInterval=60000#Broker 的角色#- ASYNC_MASTER 异步复制Master#- SYNC_MASTER 同步双写Master#- SLAVEbrokerRole=ASYNC_MASTER#刷盘方式#- ASYNC_FLUSH 异步刷盘#- SYNC_FLUSH 同步刷盘flushDiskType=ASYNC_FLUSH#checkTransactionMessageEnable=false#发消息线程池数量#sendMessageThreadPoolNums=128#拉消息线程池数量#pullMessageThreadPoolNums=128#强制指定本机IP，需要根据每台机器进行修改。官方介绍可为空，系统默认自动识别，但多网卡时IP地址可能读取错误brokerIP1=192.168.40.101 12# 修改Master1-Slave配置vim /data/rocketmq/conf/2m-2s-async/broker-b.properties 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263#所属集群名字brokerClusterName=rocketmq-cluster#broker名字，注意此处不同的配置文件填写的不一样brokerName=broker-a#0 表示 Master，&gt;0 表示 SlavebrokerId=1#nameServer地址，分号分割namesrvAddr=192.168.40.100:9876;192.168.40.101:9876#在发送消息时，自动创建服务器不存在的topic，默认创建的队列数defaultTopicQueueNums=4#是否允许 Broker 自动创建Topic，建议线下开启，线上关闭autoCreateTopicEnable=true#是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭autoCreateSubscriptionGroup=true#Broker 对外服务的监听端口listenPort=10923haListenPort=10924#删除文件时间点，默认凌晨 4点deleteWhen=04#文件保留时间，默认 48 小时fileReservedTime=18#commitLog每个文件的大小默认1GmapedFileSizeCommitLog=1073741824#ConsumeQueue每个文件默认存30W条，根据业务情况调整mapedFileSizeConsumeQueue=300000#destroyMapedFileIntervalForcibly=120000#redeleteHangedFileInterval=120000#检测物理文件磁盘空间diskMaxUsedSpaceRatio=88#存储路径storePathRootDir=/mnt/rocketmq-all-4.6.0-bin-release/datas#commitLog 存储路径storePathCommitLog=/mnt/rocketmq-all-4.6.0-bin-release/datas/commitlog#消费队列存储路径存储路径storePathConsumeQueue=/mnt/rocketmq-all-4.6.0-bin-release/datas/consumequeue#消息索引存储路径storePathIndex=/mnt/rocketmq-all-4.6.0-bin-release/datas/index#checkpoint 文件存储路径storeCheckpoint=/mnt/rocketmq-all-4.6.0-bin-release/datas/checkpoint#abort 文件存储路径abortFile=/mnt/rocketmq-all-4.6.0-bin-release/datas/abort#限制的消息大小maxMessageSize=65536#flushCommitLogLeastPages=4#flushConsumeQueueLeastPages=2#flushCommitLogThoroughInterval=10000#flushConsumeQueueThoroughInterval=60000#Broker 的角色#- ASYNC_MASTER 异步复制Master#- SYNC_MASTER 同步双写Master#- SLAVEbrokerRole=SLAVE#刷盘方式#- ASYNC_FLUSH 异步刷盘#- SYNC_FLUSH 同步刷盘flushDiskType=ASYNC_FLUSH#checkTransactionMessageEnable=false#发消息线程池数量#sendMessageThreadPoolNums=128#拉消息线程池数量#pullMessageThreadPoolNums=128#强制指定本机IP，需要根据每台机器进行修改。官方介绍可为空，系统默认自动识别，但多网卡时IP地址可能读取错误brokerIP1=192.168.40.101 启动Nameserver 在192.168.40.100操作 12cd /data/rocketmq/nohup sh bin/mqnamesrv &amp; 在192.168.40.101操作 12cd /data/rocketmq/nohup sh bin/mqnamesrv &amp; 启动Broker 在192.168.40.100操作 123cd /data/rocketmq/binsh mqbroker -c /data/rocketmq/conf/2m-2s-async/broker-a.propertiessh mqbroker -c /data/rocketmq/conf/2m-2s-async/broker-b-s.properties 在192.168.40.101操作 123cd /data/rocketmq/binsh mqbroker -c /data/rocketmq/conf/2m-2s-async/broker-a-s.propertiessh mqbroker -c /data/rocketmq/conf/2m-2s-async/broker-b.properties RocketMQ监控平台部署下载 在192.168.40.100操作 123yum -y install gitcd /optgit clone https://github.com/apache/rocketmq-externals.git 配置 123cd rocketmq-externals/rocketmq-console/src/main/resources/vim application.properties# 修改以下内容 1rocketmq.config.namesrvAddr=192.168.40.100:9876;192.168.40.101:9876 编译 1mvn clean package -Dmaven.test.skip=true 运行 12cd /opt/rocketmq-externals-master/rocketmq-console/targetjava -jar target/rocketmq-console-ng-1.0.1.jar 访问 1curl http://192.168.40.100:8080/ 在监控平台查看：集群选项，即可看到集群信息。","categories":[{"name":"大数据","slug":"大数据","permalink":"https://hxqxiaoqi.gitee.io/categories/大数据/"}],"tags":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://hxqxiaoqi.gitee.io/tags/RocketMQ/"}],"keywords":[{"name":"大数据","slug":"大数据","permalink":"https://hxqxiaoqi.gitee.io/categories/大数据/"}]},{"title":"RocketMQ安装","slug":"RocketMQ安装","date":"2020-01-21T02:00:00.000Z","updated":"2020-07-24T04:11:20.085Z","comments":true,"path":"2020/01/21/RocketMQ安装/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2020/01/21/RocketMQ安装/","excerpt":"","text":"介绍RocketMQ是一款分布式、队列模型的消息中间件，是由阿里巴巴设计的，具有以下特点： 支持严格的消息顺序 支持Topic与Queue两种模式 亿级消息堆积能力 比较友好的分布式特性 同时支持Push与Pull方式消费消息 RocketMQ是纯java编写，基于通信框架Netty 相关术语 Producer：消息生产者，负责产生消息，一般由业务系统负责产生消息。 Producer Group：一类Producer的集合名称，这类Producer通常发送一类消息，且发送逻辑一致。 Consumer：消息消费者，负责消费消息，一般是后台系统负责异步消费。 Push Consumer：Consumer的一种，应用通常向Consumer对象注册一个Listener接口，一旦收到消息，Consumer对象立 刻回调Listener接口方法。 Pull Consumer：Consumer的一种，应用通常主动调用Consumer的拉消息方法从Broker拉消息，主动权由应用控制。 Consumer Group：一类Consumer的集合名称，这类Consumer通常消费一类消息，且消费逻辑一致。 Broker：消息中转角色，负责存储消息，转发消息，一般也称为Server。 Nameserver：专为RocketMQ设计的轻量级名称服务。集群中Nameserver互相独立，彼此没有通信关系，单台Nameserver挂掉，不影响其他Nameserver，即使全部挂掉，也不影响业务系统使用。而且Nameserver不会有频繁的读写，所以性能开销非常小，稳定性很高。 广播消费：一条消息被多个Consumer消费，即使这些Consumer属于同一个Consumer Group，消息也会被Consumer Group中的每个Consumer都消费一次，广播消费中的Consumer Group概念可以认为在消息划分方面无意义。 集群消费：一个Consumer Group中的Consumer实例平均分摊消费消息。例如某个Topic有9条消息，其中一个Consumer Group有3个实例（可能是3个进程，或者3台机器），那么每个实例只消费其中的3条消息。 顺序消息：消费消息的顺序要同发送消息的顺序一致，在RocketMQ中，主要指的是局部顺序，即一类消息为满足顺序性，必须Producer单线程顺序发送，且发送到同一个队列，这样Consumer就可以按照Producer发送的顺序去消费消息。 普通顺序消息：顺序消息的一种，正常情况下可以保证完全的顺序消息，但是一旦发生通信异常，Broker重启，由于队列总数发生变化，哈希取模后定位的队列会变化，产生短暂的消息顺序不一致。如果业务能容忍在集群异常情况（如某个Broker宕机或者重启）下，消息短暂的乱序，使用普通顺序方式比较合适。 严格顺序消息：顺序消息的一种，无论正常异常情况都能保证顺序，但是牺牲了分布式Failover特性，即Broker集群中只要有一台机器不可用，则整个集群都不可用，服务可用性大大降低。如果服务器部署为同步双写模式，此缺陷可通过备机自动切换为主避免，不过仍然会存在几分钟的服务不可用。 Message Queue：在RocketMQ中，所有消息队列都是持久化，长度无限的数据结构，所谓长度无限是指队列中的每个存储单元都是定长，访问其中的存储单元使用Offset来访问，offset为java long类型，64位，理论上在100年内不会溢出，所以认为是长度无限，另外队列中只保存最近几天的数据，之前的数据会按照过期时间来删除。也可以认为Message Queue是一个长度无限的数组，offset就是下标。 异步复制：消息写入master节点，再由master节点异步复制到slave节点，类似mysql中的master-slave机制。 同步双写：消息同时写入master节点和slave节点。 异步刷盘：Broker的一种持久化策略，消息写入pagecache后，直接返回。由异步线程负责将pagecache写入硬盘。 同步刷盘：Broker的一种持久化策略，消息写入pagecache后，由同步线程将pagecache写入硬盘后，再返回。 集群部署模式RocketMQ作为消息中间件，其主要功能为消息的Publish/Subscribe。而Broker担任的消息转发和存储功能，其部署方式有很多种： 单Master 优点：除了配置简单没什么优点。 缺点：不可靠，该机器重启或宕机，将导致整个服务不可用。 多Master 优点：配置简单，性能最高。 缺点：可能会有少量消息丢失，单台机器重启或宕机期间，该机器下未被消费的消息在机器恢复前不可订阅，影响消息实时性。 异步多Master多Slave 每个Master配一个Slave，有多对Master-Slave，集群采用异步复制方式，主备有短暂消息延迟，毫秒级。 优点：性能同多Master几乎一样，实时性高，主备间切换对应用透明，不需人工干预。 缺点：Master宕机或磁盘损坏时会有少量消息丢失。 同步多Master多Slave 每个Master配一个Slave，有多对Master-Slave，集群采用同步双写方式，主备都写成功，向应用返回成功。 优点：服务可用性与数据可用性非常高。 缺点：性能比异步集群略低，当前版本主宕备不能自动切换为主。 单机安装jdk1.8安装 jdk安装跳转 下载rocketmq 12345wget https://www.apache.org/dyn/closer.cgi?path=rocketmq/4.6.0/rocketmq-all-4.6.0-bin-release.zipunzip rocketmq-all-4.6.0-bin-release.zipmv rocketmq-all-4.6.0-bin-release /data/rocketmqcd /data/rocketmq 启动Nameserver 123# 要先启动Nameserver，之后启动Brokernohup sh bin/mqnamesrv &amp;tail -f ~/logs/rocketmqlogs/namesrv.log 启动Broker 123# 内存需要4G以上，否正启动报错，修改启动文件nohup sh bin/mqbroker -n localhost:9876 &amp;tail -f ~/logs/rocketmqlogs/broker.log Broker启动内存报错 12vim bin/runbroker.sh# 修改 1JAVA_OPT=\"$&#123;JAVA_OPT&#125; -server -Xms512m -Xmx512m -Xmn256m\" 12vim bin/runserver.sh # 修改 1JAVA_OPT=\"$&#123;JAVA_OPT&#125; -server -Xms256m -Xmx256m -Xmn128m -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=320m\" 测试消息发送和接收 123456# 声明Nameserver地址export NAMESRV_ADDR=localhost:9876# 发送消息sh bin/tools.sh org.apache.rocketmq.example.quickstart.Producer# 接收消息sh bin/tools.sh org.apache.rocketmq.example.quickstart.Consumer 关闭服务 123# 要先关闭broker，之后关闭Nameserversh bin/mqshutdown brokersh bin/mqshutdown namesrv 常用命令除了上面几个命令之外，还有如下一些较常用的命令，ip请以实际为准： 12345678910# 查看集群情况： ./mqadmin clusterList -n 127.0.0.1:9876# 查看 broker 状态： ./mqadmin brokerStatus -n 127.0.0.1:9876 -b 172.20.1.138:10911# 查看 topic 列表： ./mqadmin topicList -n 127.0.0.1:9876# 查看 topic 状态： ./mqadmin topicStatus -n 127.0.0.1:9876 -t MyTopic (换成想查询的 topic)# 查看 topic 路由： ./mqadmin topicRoute -n 127.0.0.1:9876 -t MyTopic","categories":[{"name":"大数据","slug":"大数据","permalink":"https://hxqxiaoqi.gitee.io/categories/大数据/"}],"tags":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://hxqxiaoqi.gitee.io/tags/RocketMQ/"}],"keywords":[{"name":"大数据","slug":"大数据","permalink":"https://hxqxiaoqi.gitee.io/categories/大数据/"}]},{"title":"canal高可用安装","slug":"canal高可用安装","date":"2020-01-20T08:00:00.000Z","updated":"2020-07-24T03:43:00.698Z","comments":true,"path":"2020/01/20/canal高可用安装/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2020/01/20/canal高可用安装/","excerpt":"","text":"介绍canal高可用模式是通过zookeeper注册canal当前服务状态来实现的。 搭建参考地址：https://github.com/alibaba/canal/wiki/AdminGuide 搭建步骤主机环境： canal+admin+zookeeper+jdk：192.168.40.100 mysql+jdk+canal：192.168.40.101 搭建步骤： 安装mysql 安装jdk 安装zookeeper 安装2个canal 安装admin管理界面 mysql安装mysql安装 在192.168.40.101安装 jdk安装参照canal安装 在192.168.40.100和192.168.40.101安装 zookeeper安装参照zookeeper安装 在192.168.40.100安装 canal.admin安装在192.168.40.100安装 12345# 下载地址wget https://github.com/alibaba/canal/releases/download/canal-1.1.4/canal.admin-1.1.4.tar.gztar xf canal.admin-1.1.4.tar.gz -C /data/canal.adminvim /data/canal.admin/conf/application.yml 12345678910111213141516171819202122server: port: 8089spring: jackson: date-format: yyyy-MM-dd HH:mm:ss time-zone: GMT+8spring.datasource: address: 127.0.0.1:3306 #数据地址 database: canal_manager #数据库名 username: canal #数据库账号，数据库授权需要写权限 password: canal #数据库密码 driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://$&#123;spring.datasource.address&#125;/$&#123;spring.datasource.database&#125;?useUnicode=true&amp;characterEncoding=UTF-8&amp;useSSL=false hikari: maximum-pool-size: 30 minimum-idle: 1# canal-server需要凭此账号密码连接到admin上，不是登录密码，是服务间的连接校验canal: adminUser: admin adminPasswd: admin 登录数据库，加载初始化配置 1mysql -uroot -p123123 1mysql&gt; source /data/canal.admin/conf/canal_manager.sql; 启动 1234# 启动/data/admin/bin/startup.sh# 关闭/data/admin/bin/stop.sh 访问web 1curl http://192.168.40.100:8089 web界面配置 访问 http://192.168.40.100:8089 登录：账号：admin，密码：123456 点击集群管理 –&gt; 新建集群 –&gt; 填写zookeeper信息 在新建的集群右侧点击操作 –&gt; 主配置 –&gt; 载入模板 –&gt; 把canal.user与canal.passwd注释 –&gt; 修改canal.admin.manager为IP地址，注释canal.instance.global.spring.xml = classpath:spring/file-instance.xml 开启canal.instance.global.spring.xml = classpath:spring/default-instance.xml –&gt; 添加canal.zkServers地址 –&gt;保存 server管理：为canal.deployer服务配置 instance管理：为example数据源配置 canal 安装canal安装教程链接 canal.deployer配置中声明admin配置，才可以注册到admin服务上 修改canal_local.properties配置，canal_local.properties为canal最简化的配置，高可用模式使用该配置，单机模式可以使用默认文件canal.properties 1vim /data/canal/conf/canal_local.properties 12345678910111213# 本机IPcanal.register.ip =# canal admin configcanal.admin.manager = 192.168.40.100:8089canal.admin.port = 11110# 该账号密码对应admin配置，密码由mysql生成：select password('admin')，去掉*号canal.admin.user = admincanal.admin.passwd = 4ACFE3202A5FF5CF467898FC58AAB1D615029441# 自动注册到admin服务canal.admin.register.auto = true# 如果是高可用，填写zookeeper地址，如果是单机，可不填写canal.admin.register.cluster = zk 启动 123456# 必须先启动admin服务，也可直接使用canal_local.properties重命名覆盖canal.properties文件，即可正常启动cd /data/canal.admin/sh bin/startup.sh local# 查看日志tailf logs/admin.log 注： 启动canal后，在admin界面即可查看到注册信息 多台注册，配置与上面一样 如果注册到同一个集群，配置文件为统一配置 可在admin界面管理instance，直接创建，不需要在服务器上手动创建 zookeeper上也可查看到集群信息","categories":[{"name":"中间件","slug":"中间件","permalink":"https://hxqxiaoqi.gitee.io/categories/中间件/"}],"tags":[{"name":"canal","slug":"canal","permalink":"https://hxqxiaoqi.gitee.io/tags/canal/"}],"keywords":[{"name":"中间件","slug":"中间件","permalink":"https://hxqxiaoqi.gitee.io/categories/中间件/"}]},{"title":"elk监控容器日志","slug":"elk监控容器日志","date":"2020-01-20T03:00:00.000Z","updated":"2020-07-24T04:03:52.118Z","comments":true,"path":"2020/01/20/elk监控容器日志/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2020/01/20/elk监控容器日志/","excerpt":"","text":"介绍本章使用sebp/elk镜像直接启动elk环境，使用rtoma/logspout-redis-logstash镜像收集改镜像运行主机的所有容器日志。 搭建步骤主机环境： elk+redis：192.168.40.100 eureka+logspout：192.168.40.102 整体架构：eureka日志源–&gt;logspout-redis-logstash收集日志–&gt;redis存储日志–&gt;elk处理，存储，展示日志 安装sebp/elk镜像，并修改logstash配置 安装redis镜像 安装rtoma/logspout-redis-logstash镜像 安装eureka 登录kibana查看es索引，并创建kibana日志索引 sebp/elk安装12345# 创建持久化目录mkdir -p /data/elk/&#123;elasticsearch,logstash&#125;# 配置logstashcd /data/elk/logstash 12vim 02-beats-input.conf# 添加以下内容 123456789input &#123; redis &#123; host =&gt; \"192.168.40.100\" port =&gt; \"6379\" data_type =&gt; \"list\" key =&gt; \"logspout\" codec =&gt; \"json\" &#125;&#125; 12vim 30-output.conf# 添加以下内容 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354filter &#123; # 丢弃[docker][image]包含内容的日志 if [docker][image] =~ /acs\\// or [docker][image] =~ /logstash/ or [docker][image] =~ /zookeeper/ &#123; drop &#123;&#125; &#125; # 合并多行错误日志 multiline &#123; pattern =&gt; \"(^\\s)|(^Caused by)\" negate =&gt; false what =&gt; \"previous\" &#125; # 丢弃[message]包含内容的日志 if [message] =~ \"Xmemcached is stopped at\" or [message] =~ \"Unable to read additional data from client sessionid\" &#123; drop &#123;&#125; &#125; # 移除标签 mutate &#123; remove_field =&gt; [ '[docker][labels]' ] &#125; # 匹配message包含指定字段的日志，添加标签，用于区分正确和错误日志 grok &#123; match =&gt; [ \"message\", \"Exception\" ] add_tag =&gt; [\"exception-log\"] tag_on_failure =&gt; [] add_field =&gt; &#123; \"Levels\" =&gt; \"Errs\" &#125; &#125; grok &#123; match =&gt; [ \"message\", \"ERROR\" ] add_tag =&gt; [\"exception-log\"] tag_on_failure =&gt; [] add_field =&gt; &#123; \"Levels\" =&gt; \"Errs\" &#125; &#125;&#125;# 定义索引，存储到esoutput &#123;if \"exception-log\" in [tags] &#123; elasticsearch &#123; hosts =&gt; [\"localhost\"] manage_template =&gt; false index =&gt; \"err-dockerlogs-%&#123;+YYYY.MM.dd&#125;\" document_type =&gt; \"%&#123;[@metadata][type]&#125;\" codec =&gt; rubydebug &#125;&#125;else &#123; elasticsearch &#123; hosts =&gt; [\"localhost\"] manage_template =&gt; false index =&gt; \"dockerlogs-%&#123;+YYYY.MM.dd&#125;\" document_type =&gt; \"%&#123;[@metadata][type]&#125;\" codec =&gt; rubydebug &#125;&#125;&#125; 123456789101112131415# 启动elk容器docker run --restart always -p 5601:5601 -p 9200:9200 -p 5044:5044 -e ES_MIN_MEM=128m -e ES_MAX_MEM=2048m -v /data/elk/logstash/:/etc/logstash/conf.d/ -v /data/elk/elasticsearch/:/var/lib/elasticsearch/ -v /etc/localtime:/etc/localtime -it --name elk -d sebp/elk# 查看容器日志，会有报错：filter/multilinedocker logs -f elk# 登录容器并安装：logstash-filter-multiline插件docker exec -it elk bash# 容器内执行/opt/logstash/bin/logstash-plugin install logstash-filter-multiline# 退出容器并重启exit# 重启容器docker restart elk redis安装1docker run --restart always --name redis-elk -p 6379:6379 -d redis rtoma/logspout-redis-logstash安装12345# 启动容器docker run --restart -d --name \"elk-logspout-redis\" --publish=127.0.0.1:8123:80 -v /var/run/docker.sock:/var/run/docker.sock:ro rtoma/logspout-redis-logstash 'redis://192.168.40.100:6379'# 查看logspout是否收集日志curl http://127.0.0.1:8123/logs eureka安装12345# 启动容器docker run --name eureka -p 8761:8761 -d springcloud/eureka# 监控容器日志docker logs -f eureka kibana设置索引 浏览器登录kibana：http://192.168.40.100:5601 查看elasticsearch索引 创建kibana索引","categories":[{"name":"监控","slug":"监控","permalink":"https://hxqxiaoqi.gitee.io/categories/监控/"}],"tags":[{"name":"elk","slug":"elk","permalink":"https://hxqxiaoqi.gitee.io/tags/elk/"}],"keywords":[{"name":"监控","slug":"监控","permalink":"https://hxqxiaoqi.gitee.io/categories/监控/"}]},{"title":"canal安装","slug":"canal安装","date":"2020-01-19T02:00:00.000Z","updated":"2020-07-24T03:42:38.543Z","comments":true,"path":"2020/01/19/canal安装/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2020/01/19/canal安装/","excerpt":"","text":"介绍canal [kə’næl]，主要用途是基于 MySQL 数据库增量日志解析，提供增量数据订阅和消费。支持数据同步到elasticsearch、redis、kafka等服务。 当前的 canal 支持源端 MySQL 版本包括 5.1.x , 5.5.x , 5.6.x , 5.7.x , 8.0.x 搭建参考地址：https://github.com/alibaba/canal/wiki/AdminGuide canal 工作原理 canal 模拟 MySQL slave 的交互协议，伪装自己为 MySQL slave ，向 MySQL master 发送dump 协议 MySQL master 收到 dump 请求，开始推送 binary log 给 slave (即 canal ) canal 解析 binary log 对象(原始为 byte 流) canal安装主机环境： canal+mysql：192.168.40.100 系统环境： jdk1.8.0_221 MySQL5.5.64 canal下载地址 canal 服务端：canal.deployer-1.1.4.tar.gz canal 客户端测试：canal.example-1.1.4.tar.gz canal web管理界面：canal.admin-1.1.4.tar.gz canal 适配器：canal.adapter-1.1.4.tar.gz 安装步骤： 安装mysql，并开启bin-log 安装jdk 安装canal.deployer，修改配置 安装canal.example测试服务是否成功 mysql安装mysql安装跳转 canal的原理是基于mysql binlog技术，所以这里一定需要开启mysql的binlog写入功能，并且配置binlog模式为row，重启mysql。 1vim /etc/my.cnf 1234[mysqld] log-bin=mysql-bin #添加这一行就ok binlog-format=ROW #选择row模式 server_id=1 #配置mysql replaction需要定义，不能和canal的slaveId重复 登录mysql查看bin-log是否开启 12mysql&gt; show variables like 'binlog_format';mysql&gt; show variables like 'log_bin'; 配置canal服务使用的账号权限 123456# 创建用户授权mysql&gt; CREATE USER canal IDENTIFIED BY 'canal'; mysql&gt; GRANT SELECT, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'canal'@'%'; mysql&gt; FLUSH PRIVILEGES; # 查看授权mysql&gt; show grants for 'canal'; jdk安装jdk安装跳转 canal.deployer安装1234# 下载地址wget https://github.com/alibaba/canal/releases/download/canal-1.1.4/canal.deployer-1.1.4.tar.gzmkdir -p /data/&#123;canal.deployer,canal.admin,canal.example&#125;tar xf canal.deployer-1.1.4.tar.gz -C /data/canal.deployer 配置文件说明： conf/canal.properties：canal全局配置文件 conf/example/instance.properties：一个数据源配置文件 logs/canal/canal.log：canal.deployer服务日志 logs/example/example.log：数据源日志 修改配置 1vim conf/example/instance.properties 123456789101112131415161718# 数据库连接地址canal.instance.master.address=127.0.0.1:3306# 数据库账号canal.instance.dbUsername=canalcanal.instance.dbPassword=canal# mysql 数据解析关注的表，Perl正则表达式.多个正则之间以逗号(,)分隔，转义符需要双斜杠(\\\\)# 常见例子：# 1. 所有表：.* or .*\\\\..*# 2. canal schema下所有表： canal\\\\..*# 3. canal下的以canal打头的表：canal\\\\.canal.*# 4. canal schema下的一张表：canal\\\\.test1# 5. 多个规则组合使用：canal\\\\..*,mysql.test1,mysql.test2 (逗号分隔)# table regex：白名单，指定收集的库或表canal.instance.filter.regex=.*\\\\..*# table black regex：黑名单canal.instance.filter.black.regex= 注： 一个example目录为一个数据源，如果需要配置多个数据源，可以复制example为其它名字，再修改 example目录为canal默认数据源，不能改名或删除，否正会报错 canal每5秒，自动加载conf下的数据源目录，配置数据源不需要重启服务 123# 启动服务端口为11111，11112./bin/startup.sh./bin/stop.sh canal.example安装12345678# 下载地址wget https://github.com/alibaba/canal/releases/download/canal-1.1.4/canal.example-1.1.4.tar.gztar xf canal.example-1.1.4.tar.gz -C /data/canal.examplecd /data/canal.example./bin/startup.sh# 监控example日志tailf logs/example/entry.log 注： canal.example服务只能收集example数据源操作数据，如果是新增的数据源，需要java编写客户端获取数据。 测试服务 监控example日志 操作mysql增加、删除、更新 example日志显示相应的bin-log日志 至此，最简单canal服务搭建成功","categories":[{"name":"中间件","slug":"中间件","permalink":"https://hxqxiaoqi.gitee.io/categories/中间件/"}],"tags":[{"name":"canal","slug":"canal","permalink":"https://hxqxiaoqi.gitee.io/tags/canal/"}],"keywords":[{"name":"中间件","slug":"中间件","permalink":"https://hxqxiaoqi.gitee.io/categories/中间件/"}]},{"title":"mongodb 非正常关闭","slug":"mongodb 非正常关闭","date":"2020-01-01T03:00:00.000Z","updated":"2020-07-24T03:48:15.408Z","comments":true,"path":"2020/01/01/mongodb 非正常关闭/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2020/01/01/mongodb 非正常关闭/","excerpt":"","text":"问题mongodb 没有一个正常的关闭指令，经常会遇到服务器重启，或磁盘满了等问题，导致mongodb崩溃，无法启动。 解决方法 删除 mongodb data目录下的mongod.lock 文件 启动修复模式：/opt/mongodb/bin/mongod -f /opt/mongodb/mongodb.conf –repair 修复后再次正常启动：/opt/mongodb/bin/mongod -f /opt/mongodb/mongodb.conf 如果以上方法无效，需要删除 data/journal 目录下的文件再次执行以上操作启动。 mongodb的journal，简单来说就是用于数据故障恢复和持久化数据的，它以日志方式来记录。从1.8版本开始有此功能，2.0开始默认打开此功能，但32位的系统是默认关闭的。journal除了故障恢复的作用之外，还可以提高写入的性能，批量提交（batch-commit），journal一般默认100ms刷新一次，在这个过程中，所有的写入都可以一次提交，是单事务的，全部成功或者全部失败，刷新时间，可以更改，范围是2-300ms。当系统非正常情况下突然挂掉，再次启动时候mongodb就会从journal日志中恢复数据，而确保数据不丢失，最多丢失s级别的数据。","categories":[{"name":"数据库","slug":"数据库","permalink":"https://hxqxiaoqi.gitee.io/categories/数据库/"}],"tags":[{"name":"mongodb","slug":"mongodb","permalink":"https://hxqxiaoqi.gitee.io/tags/mongodb/"}],"keywords":[{"name":"数据库","slug":"数据库","permalink":"https://hxqxiaoqi.gitee.io/categories/数据库/"}]},{"title":"linux查询命令","slug":"linux查询命令","date":"2019-12-27T08:56:00.000Z","updated":"2020-07-24T04:09:08.129Z","comments":true,"path":"2019/12/27/linux查询命令/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2019/12/27/linux查询命令/","excerpt":"","text":"介绍查看系统的相关信息 常用查看命令系统硬件信息#查看 CPU 物理个数grep ‘physical id’ /proc/cpuinfo | sort -u | wc -l #查看 CPU 核心数量grep ‘core id’ /proc/cpuinfo | sort -u | wc -l #查看 CPU 线程数grep ‘processor’ /proc/cpuinfo | sort -u | wc -l #查看 CPU 型号dmidecode -s processor-version #查看 CPU 的详细信息：cat /proc/cpuinfo 系统信息#查看内核/操作系统/CPU信息的linux系统信息命令uname -a #系统版本cat /etc/redhat-release 系统资源信息#系统最大打开文件描述符数cat /proc/sys/fs/file-max #单个进程可分配最大文件数cat/proc/sys/fs/nr_open #查看当前系统使用的打开文件描述符数cat /proc/sys/fs/file-nr yum|rpm查询命令#列出所有可更新的软件清单命令yum check-update #更新所有软件命令yum update #仅安装指定的软件命令yum install #仅更新指定的软件命令yum update #列出所有可安裝的软件清单命令yum list #删除软件包命令yum remove #查找软件包 命令yum search #清除缓存命令yum clean all #建立缓存yum makecache systemctl系统命令#查看服务启动项systemctl list-unit-files","categories":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://hxqxiaoqi.gitee.io/tags/linux/"}],"keywords":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}]},{"title":"mysql常用命令","slug":"mysql常用命令","date":"2019-12-19T02:49:00.000Z","updated":"2020-07-24T03:48:56.763Z","comments":true,"path":"2019/12/19/mysql常用命令/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2019/12/19/mysql常用命令/","excerpt":"","text":"介绍记录mysql常用命令 常用命令慢查询设置 1234567891011121314# 开启慢查询日志mysql&gt; set global slow_query_log=1;# 定义时间SQL查询的超时时间mysql&gt; set global long_query_time = 0.005;# 查看慢查询信息mysql&gt; show global variables;mysql&gt; show global variables like 'slow_query_log_file';mysql&gt; show global variables like 'long_query_time';mysql&gt; show global variables like 'slow_query_log';# 查看慢查询cat /var/log/mysql/slow.log 慢查询分析 1234567891011121314151617181920212223# 按时间截取日志sed -n '/# Time: 200220/,$'p slow.log &gt; test.log# 获取执行时间最长的 10个 TOP SQL。mysqldumpslow -s t -t 10 test10.log &gt; slow_t_top_sql.txt# 获取平均查询时间最长的 10 个 TOP SQL。mysqldumpslow -s at -t 10 test10.log &gt; slow_at_top_sql.txt# 获取锁定时间最长的 10个 TOP SQL。mysqldumpslow -s l -t 10 test10.log &gt; slow_l_top_sql.txt# 获取平均锁定时间最长的 10个 TOP SQL。mysqldumpslow -s al -t 10 test10.log &gt; slow_l_top_sql.txt# 获取返回记录最多的 10个 TOP SQL。mysqldumpslow -s r -t 10 test10.log &gt; slow_r_top_sql.txt# 获取平均返回记录最多的 10个 TOP SQL。mysqldumpslow -s ar -t 10 test10.log &gt; slow_r_top_sql.txt# 获取执行次数最多的 10个 TOP SQL。mysqldumpslow -s c -t 10 test10.log &gt; slow_r_top_sql.txt","categories":[{"name":"数据库","slug":"数据库","permalink":"https://hxqxiaoqi.gitee.io/categories/数据库/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://hxqxiaoqi.gitee.io/tags/mysql/"}],"keywords":[{"name":"数据库","slug":"数据库","permalink":"https://hxqxiaoqi.gitee.io/categories/数据库/"}]},{"title":"mongodb监控与日志分析","slug":"mongodb监控与日志分析","date":"2019-11-13T06:22:00.000Z","updated":"2020-07-24T03:48:28.531Z","comments":true,"path":"2019/11/13/mongodb监控与日志分析/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2019/11/13/mongodb监控与日志分析/","excerpt":"","text":"介绍mongodb自带监控命令 监控命令mongostatmongostat是mongodb自带的状态检测工具，在命令行下使用，会间隔固定时间获取mongodb的当前运行状态，并输出。 常用命令格式： mongostat –host 192.168.1.100:27017 -uroot -p123456 –authenticationDatabase admin参数说明：host:指定IP地址和端口，也可以只写IP，然后使用–port参数指定端口号-u： 如果开启了认证，则需要在其后填写用户名-p: 不用多少，肯定是密码–authenticationDatabase：若开启了认证，则需要在此参数后填写认证库（注意是认证上述账号的数据库） 命令输出格式解释 insert/s : 官方解释是每秒插入数据库的对象数量，如果是slave，则数值前有,则表示复制集操作*query/s :** 每秒的查询操作次数update/s : 每秒的更新操作次数delete/s : 每秒的删除操作次数getmore/s: 每秒查询cursor(游标)时的getmore操作数command: 每秒执行的命令数，在主从系统中会显示两个值(例如 3|0),分表代表 本地|复制 命令注： 一秒内执行的命令数比如批量插入，只认为是一条命令（所以意义应该不大）dirty: 仅仅针对WiredTiger引擎，官网解释是脏数据字节的缓存百分比used: 仅仅针对WiredTiger引擎，官网解释是正在使用中的缓存百分比flushes:For WiredTiger引擎：指checkpoint的触发次数在一个轮询间隔期间For MMAPv1 引擎：每秒执行fsync将数据写入硬盘的次数注：一般都是0，间断性会是1， 通过计算两个1之间的间隔时间，可以大致了解多长时间flush一次。flush开销是很大的，如果频繁的flush，可能就要找找原因了vsize: 虚拟内存使用量，单位MB （这是 在mongostat 最后一次调用的总数据）res: 物理内存使用量，单位MB （这是 在mongostat 最后一次调用的总数据）注：这个和你用top看到的一样, vsize一般不会有大的变动， res会慢慢的上升，如果res经常突然下降，去查查是否有别的程序狂吃内存。 qr: 客户端等待从MongoDB实例读数据的队列长度qw： 客户端等待从MongoDB实例写入数据的队列长度ar: 执行读操作的活跃客户端数量aw: 执行写操作的活客户端数量注：如果这两个数值很大，那么就是DB被堵住了，DB的处理速度不及请求速度。看看是否有开销很大的慢查询。如果查询一切正常，确实是负载很大，就需要加机器了netIn: MongoDB实例的网络进流量netOut: MongoDB实例的网络出流量注：此两项字段表名网络带宽压力，一般情况下，不会成为瓶颈conn: 打开连接的总数，是qr,qw,ar,aw的总和注：MongoDB为每一个连接创建一个线程，线程的创建与释放也会有开销，所以尽量要适当配置连接数的启动参数，maxIncomingConnections，阿里工程师建议在5000以下，基本满足多数场景 mongotopmongotop用来跟踪MongoDB的实例， 提供每个集合的统计数据。默认情况下，mongotop每一秒刷新一次。 输出字段说明 ns：数据库命名空间，后者结合了数据库名称和集合。db：数据库的名称。名为 . 的数据库针对全局锁定，而非特定数据库。total：mongod在这个命令空间上花费的总时间。read：在这个命令空间上mongod执行读操作花费的时间。write：在这个命名空间上mongod进行写操作花费的时间。 日志分析日志信息的格式&lt;日志时间&gt; &lt;严重级别&gt; &lt;信息所属分类&gt; [&lt;内容&gt;] &lt;消息&gt; 日志信息严重级别 级别 级别描述F FatalE ErrorW WarningI Informational, for Verbosity Level of 0D Debug, for All Verbosity Levels &gt; 0 信息所属分类 登入信息ACCESS：登入访问相关的信息，例如登录验证情况。 命令信息COMMAND：数据库执行命令相关信息，例如，查询。 控制管理信息CONTROL：记录控制管理相关的信息，例如数据库初始化。 FTDC信息FTDC（full-time diagnostic data ）：全程检测数据信息，例如Server的状态统计信息。 索引信息INDEX：索引相关信息，例如索引的创建过程信息。 网络信息NETWORK：网络相关信息，例如网络连接信息。 查询信息QUERY：查询相关信息，例如查询计划信息。 副本集信息REPL：副本集相关信息，例如副本集初始过程、心跳、回滚等信息 分片信息SHARDING：分片相关信息，例如mongos的启动信息 存储信息STORAGE：存储相关信息，例如将 storage 层的数据刷入磁盘的信息。 还原信息RECOVERY：还原活动相关的信息 日志信息JOURNAL：日志相关的信息 写操作信息WRITE：写操作相关的信息，例如更新（update）的命令。","categories":[{"name":"数据库","slug":"数据库","permalink":"https://hxqxiaoqi.gitee.io/categories/数据库/"}],"tags":[{"name":"mongodb","slug":"mongodb","permalink":"https://hxqxiaoqi.gitee.io/tags/mongodb/"}],"keywords":[{"name":"数据库","slug":"数据库","permalink":"https://hxqxiaoqi.gitee.io/categories/数据库/"}]},{"title":"linux优化","slug":"linux优化","date":"2019-11-05T06:29:00.000Z","updated":"2020-07-24T04:09:03.398Z","comments":true,"path":"2019/11/05/linux优化/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2019/11/05/linux优化/","excerpt":"","text":"介绍linux相关优化 虚拟机优化用于第一次安装完linux后，执行，关闭防火墙和安装常用工具。 1234567891011121314151617181920# CentOS-7.4.1708rm -rf /etc/yum.repos.d/*curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.163.com/.help/CentOS7-Base-163.repo yum clean all &amp;&amp; yum makecacheecho \"export PS1='\\[\\e[1;32m\\][\\u@\\h \\W]\\\\$ \\[\\e[0m\\]'\" &gt;&gt; /etc/bashrcecho \"export TIME_STYLE='+%Y-%m-%d %H:%M:%S'\" &gt;&gt; /etc/bashrcecho \"export HISTTIMEFORMAT='%F %T '\" &gt;&gt; /etc/profilesed -i \"s/^#UseDNS.*/UseDNS no/g\" /etc/ssh/sshd_config sed -i \"s/SELINUX=.*/SELINUX=disabled/g\" /etc/selinux/configsystemctl stop firewalld &amp;&amp; systemctl disable firewalld &amp;&amp; rpm -e --nodeps firewalldsystemctl disable chronyd systemctl stop chronydyum -y install iptables-servicessystemctl start iptables &amp;&amp; iptables -F &amp;&amp; service iptables saveyum -y install lrzsz net-tools vim psmisc bash-completion kernel-tools tree wget dos2unix ntpdate unzip tcpdump cat &gt;&gt; ~/.vimrc &lt;&lt;EOFset ts=4set expandtabset pasteEOF 123456789101112131415161718192021222324# CentOS-8.2rm -rf /etc/yum.repos.d/*curl -o /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-8.repoyum clean all &amp;&amp; yum makecacheecho \"export PS1='\\[\\e[1;32m\\][\\u@\\h \\W]\\\\$ \\[\\e[0m\\]'\" &gt;&gt; /etc/bashrcecho \"export TIME_STYLE='+%Y-%m-%d %H:%M:%S'\" &gt;&gt; /etc/bashrcecho \"export HISTTIMEFORMAT='%F %T '\" &gt;&gt; /etc/profilesed -i \"s/^#UseDNS.*/UseDNS no/g\" /etc/ssh/sshd_config sed -i \"s/SELINUX=.*/SELINUX=disabled/g\" /etc/selinux/configsed -i \"s/pool 2.centos.pool.ntp.org iburst/#pool 2.centos.pool.ntp.org iburst/g\" /etc/chrony.confsed -i '4a server ntp.aliyun.com iburst' /etc/chrony.confsystemctl restart chronyd.servicesystemctl enable chronyd.servicechronyc sources -vtimedatectl set-timezone Asia/Shanghaisystemctl stop firewalld &amp;&amp; systemctl disable firewalld &amp;&amp; rpm -e --nodeps firewalldyum -y install iptables-servicessystemctl start iptables &amp;&amp; iptables -F &amp;&amp; service iptables saveyum -y install lrzsz net-tools vim psmisc bash-completion kernel-tools tree wget dos2unix unzip tcpdump cat &gt;&gt; ~/.vimrc &lt;&lt;EOFset ts=4set expandtabset pasteEOF 内核优化Linux服务器内核参数优化,主要是指在Linux系统中针对业务服务应用而进行的系统内核参数调整,优化并无一定的标准.下面是生产环境下Linux常见的内核优化: vim /etc/sysctl.conf 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596# 关闭ipv6net.ipv6.conf.all.disable_ipv6 = 1net.ipv6.conf.default.disable_ipv6 = 1# 避免放大攻击net.ipv4.icmp_echo_ignore_broadcasts = 1# 开启恶意icmp错误消息保护net.ipv4.icmp_ignore_bogus_error_responses = 1# 关闭路由转发net.ipv4.ip_forward = 0net.ipv4.conf.all.send_redirects = 0net.ipv4.conf.default.send_redirects = 0# 开启反向路径过滤net.ipv4.conf.all.rp_filter = 1net.ipv4.conf.default.rp_filter = 1# 处理无源路由的包net.ipv4.conf.all.accept_source_route = 0net.ipv4.conf.default.accept_source_route = 0# 关闭sysrq功能kernel.sysrq = 0# core文件名中添加pid作为扩展名kernel.core_uses_pid = 1# 开启SYN洪水攻击保护net.ipv4.tcp_syncookies = 1# 修改消息队列长度kernel.msgmnb = 65536kernel.msgmax = 65536# 设置最大内存共享段大小byteskernel.shmmax = 68719476736kernel.shmall = 4294967296# timewait的数量，默认180000net.ipv4.tcp_max_tw_buckets = 6000net.ipv4.tcp_sack = 1net.ipv4.tcp_window_scaling = 1net.ipv4.tcp_rmem = 4096 87380 4194304net.ipv4.tcp_wmem = 4096 16384 4194304net.core.wmem_default = 8388608net.core.rmem_default = 8388608net.core.rmem_max = 16777216net.core.wmem_max = 16777216# 每个网络接口接收数据包的速率比内核处理这些包的速率快时，允许送到队列的数据包的最大数目net.core.netdev_max_backlog = 262144# 限制仅仅是为了防止简单的DoS 攻击net.ipv4.tcp_max_orphans = 3276800# 未收到客户端确认信息的连接请求的最大值net.ipv4.tcp_max_syn_backlog = 262144net.ipv4.tcp_timestamps = 0# 内核放弃建立连接之前发送SYNACK 包的数量net.ipv4.tcp_synack_retries = 1# 内核放弃建立连接之前发送SYN 包的数量net.ipv4.tcp_syn_retries = 1# 启用timewait 快速回收net.ipv4.tcp_tw_recycle = 1# 开启重用。允许将TIME-WAIT sockets 重新用于新的TCP 连接net.ipv4.tcp_tw_reuse = 1net.ipv4.tcp_mem = 94500000 915000000 927000000net.ipv4.tcp_fin_timeout = 1# 当keepalive 起用的时候，TCP 发送keepalive 消息的频度。缺省是2 小时net.ipv4.tcp_keepalive_time = 30# 允许系统打开的端口范围net.ipv4.ip_local_port_range = 1024 65000# 修改防火墙表大小，默认65536net.netfilter.nf_conntrack_max=655350net.netfilter.nf_conntrack_tcp_timeout_established=1200# 确保无人能修改路由表net.ipv4.conf.all.accept_redirects = 0net.ipv4.conf.default.accept_redirects = 0net.ipv4.conf.all.secure_redirects = 0net.ipv4.conf.default.secure_redirects = 0# 系统最大进程设置kernel.pid_max = 32768# 系统最大文件数设置fs.file-max = 6553560 ulimit（进程占用资源优化）配置文件位置：vim /etc/security/limits.confcentos6：/etc/security/limits.d/90-nproc.confcentos7：/etc/security/limits.d/20-nproc.conf ulimit -a 12345678910111213141516core file size //限制内核文件的大小限制data seg size //最大数据大小限制scheduling priority //调度优先级，一般根据nice设置file size //最大文件大小限制pending signals //信号可以被挂起的最大数，这个值针对所有用户,表示可以被挂起/阻塞的最大信号数量。max locked memory //内存锁定值的限制max memory size //最大可以使用内存限制open files //进程打开文件数的限制pipe size //管道文件大小限制POSIX message queues //可以创建使用POSIX消息队列的最大值,单位为bytesreal-time priority //限制程序实时优先级的范围,只针对普通用户stack size //限制进程使用堆栈段的大小cpu time //程序占用CPU的时间,单位是秒max user processes //限制程序可以fork的进程数,只对普通用户有效virtual memory //限制进程使用虚拟内存的大小file locks //锁定文件大小限制 同时还有个要注意的值 file-max 是设置 系统所有进程一共可以打开的文件数量 ,可以通过如下方法进行修改echo 6553560 &gt; /proc/sys/fs/file-max或修改 /etc/sysctl.conf, 加入fs.file-max = 6553560 重启生效另外还有一个，/proc/sys/fs/file-nr，可以看到整个系统目前使用的文件句柄数量","categories":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://hxqxiaoqi.gitee.io/tags/linux/"}],"keywords":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}]},{"title":"python3之数据库连接","slug":"python3之数据库连接","date":"2019-11-02T14:43:00.000Z","updated":"2020-07-24T04:06:47.665Z","comments":true,"path":"2019/11/02/python3之数据库连接/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2019/11/02/python3之数据库连接/","excerpt":"","text":"介绍PyMySQL 是在 Python3.x 版本中用于连接 MySQL 服务器的一个库，Python2中则使用mysqldb。 PyMySQL 遵循 Python 数据库 API v2.0 规范，并包含了 pure-Python MySQL 客户端库。 安装PyMySQL模块菜鸟教程","categories":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}],"tags":[{"name":"python","slug":"python","permalink":"https://hxqxiaoqi.gitee.io/tags/python/"}],"keywords":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}]},{"title":"python2之requests模块","slug":"python2之requests模块","date":"2019-11-02T13:17:00.000Z","updated":"2020-07-24T04:06:57.889Z","comments":true,"path":"2019/11/02/python2之requests模块/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2019/11/02/python2之requests模块/","excerpt":"","text":"介绍Requests 是使用 Apache2 Licensed 许可证的 基于Python开发的HTTP 库，其在Python内置模块的基础上进行了高度的封装，从而使得Pythoner进行网络请求时，变得美好了许多，使用Requests可以轻而易举的完成浏览器可有的任何操作。requests可以模拟浏览器的请求，比起之前用到的urllib，requests模块的api更加便捷（其本质就是封装了urllib3） 简单示例get示例获取网页内容 123import requestsresponse = requests.get('http://httpbin.org/')print response.text 获取状态码 123import requestsresponse = requests.get('http://httpbin.org/').status_codeprint response 打印json结果 123456789import requestsimport jsonresponse = requests.get(\"http://httpbin.org/get\")print(type(response.text))print(type(response.json()))print(json.loads(response.text))print(response.json()) 添加请求头 12345678910111213# -*- coding: UTF-8 -*-# 不加请求头，有些服务会直接报500的错误import requestsresponse = requests.get(\"https://www.zhihu.com/explore\")print(response.text)# 添加请求头import requestsheaders = &#123; 'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.36'&#125;response = requests.get(\"https://www.zhihu.com/explore\", headers=headers)print(response.text)","categories":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}],"tags":[{"name":"python","slug":"python","permalink":"https://hxqxiaoqi.gitee.io/tags/python/"}],"keywords":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}]},{"title":"python2之threading模块多线程","slug":"python2之threading模块多线程","date":"2019-11-02T12:11:11.000Z","updated":"2020-07-24T04:06:53.399Z","comments":true,"path":"2019/11/02/python2之threading模块多线程/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2019/11/02/python2之threading模块多线程/","excerpt":"","text":"介绍多线程类似于同时执行多个不同程序，多线程运行有如下优点： 1.使用线程可以把占据长时间的程序中的任务放到后台去处理。2.用户界面可以更加吸引人，这样比如用户点击了一个按钮去触发某些事件的处理，可以弹出一个进度条来显示处理的进度3.程序的运行速度可能加快4.在一些等待的任务实现上如用户输入、文件读写和网络收发数据等，线程就比较有用了。在这种情况下我们可以释放一些珍贵的资源如内存占用等等。 简单的示例示例一手动创建三个线程同时执行，打印和后，等待5秒结束。 123456789101112131415161718# -*- coding: UTF-8 -*-import timeimport threadingdef f1(a1, a2): print a1 + a2 time.sleep(5)# 创建线程t = threading.Thread(target=f1, args=(111, 111)) # 开启线程t.start() t = threading.Thread(target=f1, args=(222, 222))t.start()t = threading.Thread(target=f1, args=(333, 333))t.start() 示例二这段代码执行的效果是2秒内全部执行完成，而不是每执行一次函数等待两秒，打开了三个线程同时执行函数，打印三次时间。 12345678910111213141516171819202122232425# -*- coding: UTF-8 -*-import threadingimport time# 创建一个函数交给多线程执行def test(x): date = time.time() print x print date time.sleep(2)threads = []# target=执行的函数，args=传给函数的值，range代表打开几个线程执行，变量i传给函数test的xfor i in range(3): t = threading.Thread(target=test, args=(i,)) threads.append(t)# 打开线程活动for thr in threads: thr.start()# 等待至线程中止for thr in threads: thr.join()","categories":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}],"tags":[{"name":"python","slug":"python","permalink":"https://hxqxiaoqi.gitee.io/tags/python/"}],"keywords":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}]},{"title":"svn安装使用","slug":"svn安装使用","date":"2019-11-01T12:45:00.000Z","updated":"2020-07-24T04:00:18.208Z","comments":true,"path":"2019/11/01/svn安装使用/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2019/11/01/svn安装使用/","excerpt":"","text":"介绍Subversion(SVN): 是一个开源的版本控制系統, 也就是说 Subversion 管理着随时间改变的数据。 这些数据放置在一个中央资料档案库(repository) 中。 这个档案库很像一个普通的文件服务器, 不过它会记住每一次文件的变动。 这样你就可以把档案恢复到旧的版本, 或是浏览文件的变动历史。 安装12345# 安装yum -y install subversion# 查看版本svn --version 创建版本库 123456789# 手动新建版本库目录mkdir /data/svn# 利用svn命令创建版本库svnadmin create /opt/svn/test# 查看创建生成的文件，其中conf目录下：authz：给用户或组设置权限，passwd：给用户设置密码，svnserve.conf：svn配置文件。# 数据主要存在db下，格式为fsfs。ls /opt/svn/test 配置用户 123456789101112131415161718192021222324cd /opt/svn/test/conf# 创建用户vim passwd huang = 123456 xiao = 123123# 给用户授权，[/]：代表/opt/svn/目录vim authz [/] huang = rw xiao = r # 配置版本库，取消以下注释。# anon-access: 匿名用户权限# auth-access: 登录用户权限# password-db：密码文件位置# authz-db: 指定权限配置文件名# realm: 指定版本库的认证域，即在登录时提示的认证域名称。若两个版本库的 认证域相同，建议使用相同的用户名口令数据文件。 默认值：一个UUID(Universal Unique IDentifier，全局唯一标示)。vim svnserve.conf anon-access = read auth-access = write password-db = passwd realm = My First Repository 启动 123# 使用命令svnserve启动服务，-d：后台运行，-r：指定版本库目录如果不指定端口，默认为3690# svnserve -d -r 目录 --listen-port 端口号svnserve -d -r /opt/svn/ 使用下载svn客户端：TortoiseSVN 下载window版，安装客户端。 随便创建一个目录，右击该目录，可查看到svn选项，即安装完成。 拉去svn版本库test 1.选择创建的目录，右击-选择SVN Checkout 2.在跳出的任务框中输入：svn://10.10.10.10/test 拉取代码 提交代码在已经拉取的目录中，创建一些文件，右击-选择SVN commit，可以输入提交说明和文件 更新代码在已经拉取的目录中，右击-选择SVN UPdate 备份恢复备份 1svnadmin dump /opt/svn/test &gt; test.svn.bak 恢复 12345# #创建一个新的版本库,用户需要重新配置svnadmin create /opt/svn/test # 现还原完全备份svnadmin load /opt/svn/test &lt; test.svn.bak","categories":[{"name":"中间件","slug":"中间件","permalink":"https://hxqxiaoqi.gitee.io/categories/中间件/"}],"tags":[{"name":"svn","slug":"svn","permalink":"https://hxqxiaoqi.gitee.io/tags/svn/"}],"keywords":[{"name":"中间件","slug":"中间件","permalink":"https://hxqxiaoqi.gitee.io/categories/中间件/"}]},{"title":"dockerfile几个实例","slug":"dockerfile几个实例","date":"2019-10-30T07:25:13.830Z","updated":"2020-07-24T03:51:05.106Z","comments":true,"path":"2019/10/30/dockerfile几个实例/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2019/10/30/dockerfile几个实例/","excerpt":"","text":"实例说明本章会写两个dockerfile实例和一个shell脚本调用dockerfile实例，重点在于shell和dockerfile中环境变量的调用以及调用系统变量，这里有些坑会重点说明。 dockerfile封装jdk以下代码存为名为Dockerfile的文件，把下载好的jdk包放在Dockerfile同一目录中，运行dockerfile，即可生成拥有jdk环境的系统镜像，我把镜像上传到阿里云仓库中，方便可以随时使用。 1234567891011121314151617181920#依赖镜像名称和IDFROM centos#切换工作目录WORKDIR /usrRUN mkdir /usr/local/java#ADD 是相对路径jar,把java添加到容器中ADD jdk-8u191-linux-x64.tar.gz /usr/local/java/#配置java环境变量ENV JAVA_HOME /usr/local/java/jdk1.8.0_191ENV JRE_HOME $JAVA_HOME/jreENV CLASSPATH $JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib:$CLASSPATHENV PATH $JAVA_HOME/bin:$PATH#配置系统语言ENV LANG en_US.UTF-8#运行ENTRYPOINT tail -f /anaconda-post.log dockerfile封装jar包服务以下代码存为名为Dockerfile的文件，跟下面shell脚本配合使用，注意：dockerfile中的变量只是容器中的变量，系统变量无法在dockerfile中生效，只有通过ARG向dockerfile中传入系统变量，ARG指令需要在docker build时指定其变量。 12345678910111213141516171819#依赖镜像名称和ID#阿里云内网FROM registry-vpc.cn-hangzhou.aliyuncs.com/znknow/page:1.8#阿里云外网#FROM registry.cn-hangzhou.aliyuncs.com/znknow/page:1.8#系统环境变量ARG pagejARG pagep#dockerfile环境变量ENV jar $pagejENV port $pagepENV LANG en_US.UTF-8COPY ./$jar /usr/local/EXPOSE $portENTRYPOINT java -Xdebug -Xnoagent -Djava.compiler=NONE -Xrunjdwp:transport=dt_socket,address=12000,server=y,suspend=n -jar /usr/local/$jar -Djava.io.tmpdir=/data/tmp &amp;&gt; /var/log/$jar.log shell启动dockerfile该shell脚本为运行dockerfile并向dockerfile中传入相应变量。 1234567891011121314151617181920#!/bin/bash#定义shell环境变量export pagedir=`pwd`export pagejar=$1export pageport=$2export pageport3=$3export pagetag=\"1.0\"export pageago=`docker ps -a | grep $pagejar | cut -d \" \" -f1`export pageagoim=`docker images | grep $pagejar |awk -F \" \" '&#123;print $3&#125;'`#删除原镜像和容器，这里不像生成多个相同镜像，也可以使用标签生成多个镜像/usr/bin/docker rm -f $pageago/usr/bin/docker rmi -f $pageagoim#运行dockerfile指令，--build-arg为传入dockerfile中的环境变量/usr/bin/docker build --build-arg pagej=$pagejar --build-arg pagep=$pageport3 -t $pagejar:$pagetag .#启动容器/usr/bin/docker run --restart always -v $pagedir:/var/log/ -v /etc/localtime:/etc/localtime -v /etc/timezone:/etc/timezone -p $pageport:$pageport3 --name $pagejar-$pagetag -d $pagejar:$pagetag docker-zkui1234567891011121314FROM registry.cn-hangzhou.aliyuncs.com/mmh/jdk:1.8.0ENV LANG en_US.UTF-8ENV JAVA_HOME /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.232.b09-0.el7_7.x86_64ENV CLASSPATH .:/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.232.b09-0.el7_7.x86_64/dt.jar:/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.232.b09-0.el7_7.x86_64/lib/tools.jarADD ./zkui-2.0-SNAPSHOT-jar-with-dependencies.jar /opt/zkui/zkui-2.0-SNAPSHOT-jar-with-dependencies.jarADD ./config.cfg /opt/zkui/config.cfgRUN cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtimeRUN yum -y install vim net-tools telnet# $zkcluster变量可以在启动镜像时指定ENTRYPOINT sed -i 's/zkServer=.*/zkServer='$zkcluster'/' /opt/zkui/config.cfg &amp;&amp; cd /opt/zkui/ &amp;&amp; java -Xms512m -Xmx512m -XX:PermSize=128m -jar /opt/zkui/zkui-2.0-SNAPSHOT-jar-with-dependencies.jar docker-zipkin123456789101112FROM registry.cn-hangzhou.aliyuncs.com/mmh/jdk:1.8.0ENV LANG en_US.UTF-8ENV JAVA_HOME /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.232.b09-0.el7_7.x86_64ENV CLASSPATH .:/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.232.b09-0.el7_7.x86_64/dt.jar:/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.232.b09-0.el7_7.x86_64/lib/tools.jarADD ./zipkin.tar.gz /data/RUN cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtimeRUN yum -y install vim net-toolsENTRYPOINT cd /data/zipkin &amp;&amp; java -Xms512m -Xmx512m -XX:PermSize=128m -jar /data/zipkin/zipkin.jar docker-disconf12345678910111213141516171819202122232425262728293031323334FROM centos:7.4.1708ENV LANG en_US.UTF-8ENV JAVA_HOME /opt/jdk1.8.0_221ENV JRE_HOME $&#123;JAVA_HOME&#125;/jreENV CLASSPATH .:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/libENV PATH $&#123;JAVA_HOME&#125;/bin:$PATHENV MAVEN_HOME /opt/apache-maven-3.3.9ENV PATH $PATH:$JAVA_HOME/bin:$MAVEN_HOME/binENV ONLINE_CONFIG_PATH /usr/local/disconf/resourceENV WAR_ROOT_PATH /usr/local/disconf/warADD ./jdk-8u221-linux-x64.tar.gz /opt/ADD ./apache-maven-3.3.9-bin.tar.gz /opt/ADD ./apache-tomcat-8.5.47.tar.gz /opt/ADD ./disconf.tar.gz /usr/local/ADD ./nginx.sh /opt/ADD ./redis.sh /opt/ADD ./redis-stable.tar.gz /opt/ADD ./nginx-1.14.2.tar.gz /opt/ADD ./start.sh /opt/ADD ./nginx.conf /opt/ADD ./server.xml /opt/ADD ./nginx.service /lib/systemd/system/RUN /bin/cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime &amp;&amp; echo 'Asia/Shanghai' &gt;/etc/timezoneRUN yum -y install gcc gcc-c++ pcre pcre-devel zlib zlib-devel openssl openssl-devel wget vim net-tools telnetRUN sh /opt/nginx.shRUN sh /opt/redis.shRUN \\mv /opt/nginx.conf /opt/nginx/conf/RUN \\mv /opt/server.xml /opt/apache-tomcat-8.5.47/conf/RUN cd /opt/ &amp;&amp; rm -rf nginx-1.14.2 nginx.sh redis.sh ENTRYPOINT cd /opt/redis-stable/ &amp;&amp; ./src/redis-server ./redis.conf &amp;&amp; bash /opt/apache-tomcat-8.5.47/bin/startup.sh &amp;&amp; /opt/nginx/sbin/nginx -g \"daemon off;\"","categories":[{"name":"kubernetes","slug":"kubernetes","permalink":"https://hxqxiaoqi.gitee.io/categories/kubernetes/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://hxqxiaoqi.gitee.io/tags/docker/"}],"keywords":[{"name":"kubernetes","slug":"kubernetes","permalink":"https://hxqxiaoqi.gitee.io/categories/kubernetes/"}]},{"title":"mongodb主从与仲裁搭建","slug":"mongodb主从与仲裁搭建","date":"2019-10-28T10:58:00.000Z","updated":"2020-07-24T03:48:33.586Z","comments":true,"path":"2019/10/28/mongodb主从与仲裁搭建/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2019/10/28/mongodb主从与仲裁搭建/","excerpt":"","text":"介绍中文翻译叫做副本集。其实简单来说就是集群当中包含了多份数据，保证主节点挂掉了，备节点能继续提供数据服务，提供的前提就是数据需要和主节点一致。 默认设置下，主节点提供所有增删查改服务，备节点不提供任何服务。但是可以通过设置使备节点提供查询服务，这样就可以减少主节点的压力，当客户端进行数据查询时，请求自动转到备节点上。 仲裁节点是一种特殊的节点，它本身并不存储数据，主要的作用是决定哪一个备节点在主节点挂掉之后提升为主节点，所以客户端不需要连接此节点。这里虽然只有一个备节点，但是仍然需要一个仲裁节点来提升备节点级别。 部署部署环境：以下每台安装mongodb 192.168.40.100 master 192.168.40.101 slave 192.168.40.102 arbiter 安装mongodb请看该文档：mongodb安装注：配置文件需要更改为以下配置启动。 配置文件 注：master，slave，arbiter配置都是一致的，配置中replSet=RS1为集群名称，之后根据该名称设置集群 1234567891011121314151617181920212223242526272829303132333435bind_ip=0.0.0.0port=27017# 持久化存储引擎storageEngine=wiredTiger# 内部缓存的大小wiredTigerCacheSizeGB=2# 是设置从内存同步到硬盘的时间间隔，默认为60秒，可以设置的少一些syncdelay=30# 设定压缩策略 snappy 是一种压缩速度非常快的压缩策略wiredTigerCollectionBlockCompressor=snappy# 集群名称replSet=RS1# 文件位置dbpath=/data/mongodb-linux-x86_64-3.6.14/datalogpath=/data/mongodb-linux-x86_64-3.6.14/logs/mongodb.log# mongodb操作日志文件的最大大小。单位为Mb，默认为硬盘剩余空间的5%oplogSize=6144# 追加方式写入日志logappend=true# 后台运行fork=true# 启用日志文件，默认启用journal=true# 为每一个数据库按照数据库名建立文件夹存放directoryperdb=true 启动全部启动 123./bin/monood -f mongodb.conf ./bin/mongod -f mongodb.conf ./bin/mongod -f mongodb.conf 配置主，备，仲裁节点 可以通过客户端连接mongodb，也可以直接在三个节点中选择一个连接mongodb。 1234567891011# 登录./bin/mongo# 切换库&gt;use admin;# 配置仲裁，根据实际IP地址配置&gt;cfg=&#123; _id:\"testrs\", members:[ &#123;_id:0,host:'192.168.40.100:27017',priority:2&#125;, &#123;_id:1,host:'192.168.40.101:27017',priority:1&#125;, &#123;_id:2,host:'192.168.40.102:27017',arbiterOnly:true&#125;] &#125;;# 查看状态：PRIMARY为主，SECONDARY为从，ARBITER为仲裁rs.status() cfg是可以任意的名字，当然最好不要是mongodb的关键字，conf，config都可以。最外层的_id表示replica set的名字，members里包含的是所有节点的地址以及优先级。优先级最高的即成为主节点，即这里的10.10.148.130:27017。特别注意的是，对于仲裁节点，需要有个特别的配置——arbiterOnly:true。这个千万不能少了，不然主备模式就不能生效。 实验 杀死主（db.shutdownServer();） 查看仲裁日志 查看从状态 添加节点12345678# 添加节点&gt; rs.add(\"192.168.40.101:27017\");# 添加仲裁节点&gt; rs.addArb(\"192.168.40.102:27017\");# 移除节点&gt; rs.remove(\"192.168.40.101:27020\");","categories":[{"name":"数据库","slug":"数据库","permalink":"https://hxqxiaoqi.gitee.io/categories/数据库/"}],"tags":[{"name":"mongodb","slug":"mongodb","permalink":"https://hxqxiaoqi.gitee.io/tags/mongodb/"}],"keywords":[{"name":"数据库","slug":"数据库","permalink":"https://hxqxiaoqi.gitee.io/categories/数据库/"}]},{"title":"mongodb搭建","slug":"mongodb搭建","date":"2019-10-28T08:20:00.000Z","updated":"2020-07-24T03:48:22.812Z","comments":true,"path":"2019/10/28/mongodb搭建/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2019/10/28/mongodb搭建/","excerpt":"","text":"介绍MongoDB： 是由C++语言编写的一个基于分布式文件存储的开源数据库系统，它的目的在于为WEB应用提供可扩展的高性能数据存储解决方案。是一个介于关系型数据库和非关系型数据库之间的产品，是非关系型数据库当中功能最丰富，最像关系型数据库的。它支持的数据结构非常松散，会将数据存储为一个文档，数据结构由键值对(key=&gt;value)组成，是类似于json的bson格式，字段值可以包含其它文档、数组和文档数组，因此可以存储比较复杂的数据类型。 安装官网下载以下为自动安装脚本 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#!/bin/bash# 自动安装mongodbworkdir=/datamongodb_version=mongodb-linux-x86_64-3.6.14[ -e $workdir ] || mkdir $workdir mongodb_dir=$workdir/$mongodb_versionyum -y install wgetwget https://fastdl.mongodb.org/linux/$mongodb_version.tgztar xf $mongodb_version.tgz -C /datacd $mongodb_dirmkdir &#123;data,logs&#125;cat &gt; mongodb.conf &lt;&lt;EOF# 数据库路径dbpath=$mongodb_dir/data# 日志输出文件路径logpath=$mongodb_dir/logs/mongodb.log# 错误日志采用追加模式logappend=true# 启用日志文件，默认启用journal=true# 这个选项可以过滤掉一些无用的日志信息，若需要调试使用请设置为falsequiet=true# 端口号 默认为27017port=27017# 允许远程访问bind_ip=0.0.0.0# 开启子进程fork=true# 为每一个数据库按照数据库名建立文件夹存放directoryperdb=true#开启认证，必选先添加用户#auth=trueEOF$mongodb_dir/bin/mongod -f $mongodb_dir/mongodb.conf 启动脚本1234567891011121314151617181920212223242526#!/bin/bash# mongodb启动脚本# chkconfig: 2345 10 90dir=/data/mongodb-linux-x86_64-3.6.14start() &#123;$dir/bin/mongod --config $dir/mongodb.conf&#125;stop() &#123;$dir/bin/mongod --config $dir/mongodb.conf --shutdown&#125;case \"$1\" instart) start ;;stop) stop ;;restart) stop start ;;*) echo $\"Usage: $0 &#123;start|stop|restart&#125;\" exit 1esac 开机自启动把以上启动脚本存为mongodb 12345mv mongodb /etc/rc.d/init.d/chmod +x /etc/rc.d/init.d/mongodbchkconfig --add mongodbchkconfig mongodb onchkconfig --list 备份和恢复备份整个库 1234567891011例如： mongodump -h localhost -d users -o /root/mongdbbak/-h：MongDB所在服务器地址，例如：127.0.0.1或localhost，当然也可以指定端口号：127.0.0.1:27017-d：需要备份的数据库实例名，例如：users-o：指定备份的数据存放的目录位置，例如：/root/mongdbbak/，当然该目录需要提前建立，在备份完成后，系统自动在/root/mongdbbak/目录下建立一个users目录，这个目录里面存放该数据库实例的备份数据。数据形式是以JSON的格式文件存储。 恢复整个库 1234567891011例如：mongorestore -h localhost -d users --dir /root/mongdbbak/users--host &lt;:port&gt;, -h &lt;:port&gt;：MongoDB所在服务器地址，默认为:localhost:27017-d ：需要恢复的数据库实例名，例如：users，当然这个名称也可以和备份时候的不一样，比如user2--dir：指定备份的目录。 导出集合 12345678910例如：mongoexport -d mydb -c promotionConfiguration -o promotionConfiguration.json-h ：数据库地址，MongoDB 服务器所在的 IP 与 端口，如 localhost:27017-d ：指明使用的数据库实例，如 test-c 指明要导出的集合，如 demo-o 指明要导出的文件名，demo.json，文件类型支持txt、xls、docs 等等 导入集合 12345678例如：mongoimport -d mydb -c u_vip_card_item --type=json --file u_vip_card_item.json-h ： 数据库地址，MongoDB 服务器所在的 IP 与 端口，如 localhost:27017-d ：指明使用的库，指明使用的数据库实例，如 test-c ：指明要导入的集合，如 demo可以和导出时不一致，自定义即可，不存在时会直接创建。 常用命令关闭mongodbmongod –shutdown –dbpath /database/mongodb/data/或 use admin;db.shutdownServer(); 查看库大小单位B查看db.stats(); 单位M查看db.stats(1048576); 单位G查看db.stats(1073741824); 查看表大小(单位字节)db.tables.stats() 查看全部数据库show dbs; 显示当前数据库中的集合（类似关系数据库中的表）show collections; 查看当前数据库的用户信息show users; 切换数据库跟mysql一样 （如果没用库，则创建，需要有数据才能生成库）use ; 查看当前所在数据库db;db.getName(); 对于当前数据库中的foo集合进行数据查找（由于没有条件，会列出所有数据）db.foo.find(); 对于当前数据库中的foo集合进行查找 （条件是数据中有一个属性叫a，且a的值为1）db.foo.find( { a : 1 } ); 创建表db.test.insert({“_id”:”520”,”name”:”xiaoming”}) 创建用户use admindb.createUser({user:”xiaoming”,pwd:”123456”,roles:[{role:”userAdmin”,db:”test”}]}) 删除用户db.removeUser(“userName”); 显示当前所有用户show users; 删除当前所在库db.dropDatabase(); 查看当前库状态db.stats(); 查看当前连接数和最大连接数db.serverStatus().connections 实时查运行状态mongostat 查看压力mongotop","categories":[{"name":"数据库","slug":"数据库","permalink":"https://hxqxiaoqi.gitee.io/categories/数据库/"}],"tags":[{"name":"mongodb","slug":"mongodb","permalink":"https://hxqxiaoqi.gitee.io/tags/mongodb/"}],"keywords":[{"name":"数据库","slug":"数据库","permalink":"https://hxqxiaoqi.gitee.io/categories/数据库/"}]},{"title":"ssh端口转发","slug":"ssh端口转发","date":"2019-10-27T13:49:00.000Z","updated":"2020-07-24T04:06:00.584Z","comments":true,"path":"2019/10/27/ssh端口转发/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2019/10/27/ssh端口转发/","excerpt":"","text":"介绍ssh端口转发作用： 转发对应的端口请求到目标服务器的对应端口服务（在本地生成监听端口） 转发对应的端口请求到目标服务器的对应端口服务（在跳板机生成监听端口） 使用ssh参数说明： -L # 本地转发 -R # 远程转发 -N # 不打开远程shell，处于等待状态（不加-N则直接登录进去 -f # 后台启用 实验环境： 192.168.40.100（发起请求） 192.168.40.101（跳板机） 192.168.40.102（被请求） 在本地生成监听端口执行该命令，在192.168.40.100上会生成3000端口的监听，访问该端口等于访问192.168.40.102上的22端口服务，使用ssh连接192.168.40.100并指定端口为3000，最终需要输入的是192.168.40.102服务器的密码。 192.168.40.100实际是通过访问192.168.40.102上的22端口服务。 192.168.40.101类似与跳板机作用。 实际环境，192.168.40.101应该是公网IP，并可以被192.168.40.101访问，且能访问192.168.40.102。 12# 在192.168.40.100上执行，并要求输入101的密码ssh -L 192.168.40.100:3000:192.168.40.102:22 -N 192.168.40.101 在跳板机生成监听端口执行该命令，在192.168.40.101上会生成3000端口的监听，访问该端口等于访问192.168.40.102上的22端口服务，使用ssh连接192.168.40.100并指定端口为3000，最终需要输入的是192.168.40.102服务器的密码。注：192.168.40.101会以127.0.0.1监听，所以只能登录到该服务器访问。 12# 在192.168.40.100上执行，并要求输入101的密码ssh -R 192.168.40.100:3000:192.168.40.102:22 -N 192.168.40.101","categories":[{"name":"脚本","slug":"脚本","permalink":"https://hxqxiaoqi.gitee.io/categories/脚本/"}],"tags":[{"name":"ssh","slug":"ssh","permalink":"https://hxqxiaoqi.gitee.io/tags/ssh/"}],"keywords":[{"name":"脚本","slug":"脚本","permalink":"https://hxqxiaoqi.gitee.io/categories/脚本/"}]},{"title":"node.js和PM2安装和使用","slug":"node.js和PM2安装和使用","date":"2019-10-26T07:41:00.000Z","updated":"2020-07-24T04:07:37.412Z","comments":true,"path":"2019/10/26/node.js和PM2安装和使用/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2019/10/26/node.js和PM2安装和使用/","excerpt":"","text":"介绍Node.js： 就是运行在服务端的 JavaScript。Node.js 是一个基于Chrome JavaScript 运行时建立的一个平台。Node.js是一个事件驱动I/O服务端JavaScript环境，基于Google的V8引擎，V8引擎执行Javascript的速度非常快，性能非常好。 NPM： 是随同NodeJS一起安装的包管理工具，能解决NodeJS代码部署上的很多问题，常见的使用场景有以下几种： 允许用户从NPM服务器下载别人编写的第三方包到本地使用。 允许用户从NPM服务器下载并安装别人编写的命令行程序到本地使用。 允许用户将自己编写的包或命令行程序上传到NPM服务器供别人使用。 PM2： 是node进程管理工具，可以利用它来简化很多node应用管理的繁琐任务，如性能监控、自动重启、负载均衡等，而且使用非常简单。 下面就对PM2进行入门性的介绍，基本涵盖了PM2的常用的功能和配置。 node.js安装12345678910wget https://cdn.npm.taobao.org/dist/node/v12.13.0/node-v12.13.0-linux-x64.tar.xztar xf node-v12.13.0-linux-x64.tar.xz -C /opt/cd /optmv node-v12.13.0-linux-x64 nodeln -s /opt/node/bin/npm /usr/local/bin/ln -s /opt/node/bin/node /usr/local/bin/node -vnpm -v npm常用命令 查看node版本node –version 查看npm 版本npm -v 安装cnpm (国内淘宝镜像源)npm install cnpm -g –registry=https://registry.npm.taobao.org 安装express模块npm install express 全局安装express模块npm install -g express 列出已安装模块npm list 显示模块详情npm show express 升级当前目录下的项目的所有模块npm update 升级当前目录下的项目的指定模块npm update express 升级全局安装的express模块npm update -g express 删除指定的模块npm uninstall express 更新node 版本首先需要确保是否安装 n 模块，这个是node升级需要没有安装执行：npm i n -g -f检测使用: n –version更新node命令：n stable pm2常用命令 启动app.js应用程序pm2 start app.js cluster mode 模式启动4个app.js的应用实例pm2 start app.js -i 4 启动应用程序并命名为 “api”pm2 start app.js –name=”api” 当文件变化时自动重启应用pm2 start app.js –watch 启动 bash 脚本pm2 start script.sh 列表 PM2 启动的所有的应用程序pm2 list 显示每个应用程序的CPU和内存占用情况pm2 monit 显示应用程序的所有信息pm2 show app 显示所有应用程序的日志pm2 logs 显示指定应用程序的日志pm2 logs app 清空所有日志文件pm2 flush 停止所有的应用程序pm2 stop all 停止 id为 0的指定应用程序pm2 stop 0 重启所有应用pm2 restart all 重启 cluster mode下的所有应用pm2 reload all 重启集群所有应用pm2 gracefulReload all 关闭并删除所有应用pm2 delete all 删除指定应用 id 0pm2 delete 0 把名字叫api的应用扩展到10个实例pm2 scale api 10 重置重启数量pm2 reset app 创建开机自启动命令pm2 startup 保存当前应用列表pm2 save 重新加载保存的应用列表pm2 resurrect","categories":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}],"tags":[{"name":"node","slug":"node","permalink":"https://hxqxiaoqi.gitee.io/tags/node/"}],"keywords":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}]},{"title":"kvm安装与使用","slug":"kvm安装与使用","date":"2019-10-26T06:07:00.000Z","updated":"2020-07-24T04:10:42.224Z","comments":true,"path":"2019/10/26/kvm安装与使用/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2019/10/26/kvm安装与使用/","excerpt":"","text":"介绍kvm： 全称“基于内核的虚拟机”，是一个开源的软件，基于内核的虚拟化技术，实际是嵌入系统的一个虚拟化模块，通过优化内核来使用虚拟技术，该内核模块使得Linux变成一个hypervisor，虚拟机使用Linux自身的调度器进行管理。（就是说Linux要部署一个kvm模块，他才能变成hypervisor层）。 kvm是基于CPU的类型进行管理。 用户空间：指的是用户得到一个虚拟机。 内核空间：指的是你的kvm宿主机里面它部署的虚拟化的软件，是通过驱动内核来实现的。 组件说明： 虚机：指的是用户的得到一个虚拟机层。 Guest：指的我们虚拟机，也称VM。 kvm：运行在内核空间，提供CPU和内存的虚拟。 QEMU（扩展软件）：帮我们提供了虚拟机的I/O设备（CPU 内存 显示器），其他的硬件虚拟化。 kvm有一个内核模块叫kvm.ko，它来提供我们CPU和内存。 Libvirt：kvm的管理工具。 virt-viewer：轻量级桌面工具。 bridge-utils ：网桥工具。 virt-install：KVM虚拟机的管理主要是通过virsh命令对虚拟机进行管理。 环境要求： KVM需要硬件⽀持, 所以需要开启虚拟化⽀持。 硬件设备直接在BIOS设置开启CPU虚拟化。 个⼈电脑同样进⼊BIOS开启虚拟化⽀持。 VM需要找到对应虚拟机开启对应的VT-EPT虚拟化技术。 部署kvm安装 12345678yum install -y qemu-kvm libvirt virt-install bridge-utils virt-viewer# 查看是否开启虚拟化lsmod |grep kvm# 启动管理工具systemctl start libvirtdsystemctl enable libvirtd 修改网卡 vim /etc/sysconfig/network-scripts/ifcfg-ens33 123456NAME=ens33DEVICE=ens33BOOTPROTO=noneNM_CONTROLLED=noONBOOT=yesBRIDGE=br0 vim ifcfg-br0设置为本机IP，当作网桥 123456789101112NAME=br0DEVICE=br0ONBOOT=yesNETBOOT=yesIPV6INIT=noBOOTPROTO=staticNM_CONTROLLED=noTYPE=BridgeIPADDR=192.168.0.127NETMASK=255.255.255.0GATEWAY=192.168.0.1DNS1=8.8.8.8 重启网卡 1systemctl restart network 查看网桥 1brctl show 创建虚拟机 123456789101112131415161718# 创建目录，iso用于存放系统镜像，kvm用于存放创建的虚拟机磁盘文件，保证空间mkdir -p /data/&#123;iso,kvm&#125;# 导入镜像到iso目录下# 创建虚拟磁盘cd /data/kvm/; qemu-img create -f qcow2 /data/kvm/disk/flink02.qcow2 200G# 创建虚拟机# --arch=x86_64 为虚拟机请求一个非本地CPU架构，这个选项当前只对qemu客户机有效，但是不能够使用加速机制。如果忽略，在虚拟机中将使用主机CPU架构。# --vcpus=1 cpu数# --disk 指定磁盘类型，bus：磁盘总结类型，其值可以为ide、scsi、usb、virtio或xen；cache：缓存模型，其值有none、writethrouth（缓存读）及writeback（缓存读写）。# --os-type 针对一类操作系统优化虚拟机配置# --vnc vnc监听端口virt-install -n flink02 --arch=x86_64 --vcpus=4 -r 16384 --disk path=/data/kvm/disk/flink02.qcow2,io=native,bus=virtio,cache=none --network bridge=br0,model=virtio --os-type=linux --os-variant=rhel7 --cdrom /data/ISO/CentOS-7-x86_64-DVD-1611.iso --vnc --vncport=7001 --vnclisten=0.0.0.0 --video=vga# 另开一个终端，查看虚拟机列表virsh list 安装vnclinux下载vnc服务端 1234yum install -y tigervnc-server tigervnc-server-module# 启动vnc，进入交互式界面，设置vnc连接密码vncserver 在windows： 下载vncviewer客户端 打开vncviewer，连接虚拟机，端口为创建系统时指定的7000，可以看到图形化安装显示，安装系统。注：配置ip，需要同一局域网，如果不同，需要设置路由记录，之后就可以使用ssh工具连接虚拟机了。 查看vnc密码 12cd /etc/libvirt/qemuvim 虚拟机配置文件 修改虚拟机root密码12345678910111213# 安装编辑工具yum -y install libguestfs-tools# 在你的另外的机器上面，查看root的shadow文件，复制root的密码文件# 关掉虚拟机virsh xxxx shutdown # 编辑虚拟机shadow文件virt-edit xxx /etc/shadow# 启动虚拟机 virsh xxxx start 扩大虚拟机内存和cpu方法一： 1234567891011121314151617# 查看虚拟机信息virsh dominfo etc01# 关闭虚拟机virsh shutdown etc01# 设置虚拟机最大内存virsh setmaxmem etc01 8388608# 开启虚拟机virsh start etc01# 设置虚拟机可以内存# 临时修改virsh setmem etc01 8388608# 永久修改，编辑配置文件virsh edit etc01 方法二： 12# 永久修改，编辑配置文件virsh edit etc01 磁盘扩容12345678910111213141516171819202122232425# 关闭虚拟机virsh destroy test1# 添加容量qemu-img resize /data/kvm/disk/test1.qcow2 +100G# 查看容量qemu-img info /data/kvm/disk/test1.qcow2# 启动虚拟机virsh start test1# 使用vnc登录# 查看磁盘分区fdisk -l# 给多余容量分区，按n添加分区，按p添加主分区，按w保存推出，按t修改分区格式为8efdisk /dev/vda3# 重新加载分区partprobe# 创建pvpvcreate /dev/vda3# 查看并添加pv搭配vg中vgdisplayvgextend centos /dev/vda3# 查看并扩容已有分区lvdisplaylvresize -L +50G /dev/mapper/centos-root# 扩充文件系统resize2fs /dev/mapper/centos-root kvm常用命令命令帮助 1virsh --help 查看虚拟机状态 1virsh list --all 关机 1virsh shutdown win2k8r2 强制关闭电源 1virsh destroy win2k8r2 通过配置文件创建虚拟机 1virsh create /etc/libvirt/qemu/win2k8r2.xml 设置虚拟机开机自启 12345678# 开机启动virsh autostart win2k8r2# 取消开机启动virsh autostart --disable win2k8r2# 查看虚拟机是否自启ll /etc/libvirt/qemu/autostart/ 删除虚拟机 12# 该命令只删除配置文件，并不删除磁盘文件virsh undefine win2k8r2 导出虚拟机配置文件 1virsh dumpxml win2k8r2 &gt; /etc/libvirt/qemu/win2k8r2_bak.xml 通过配置文件恢复原KVM虚拟机 12mv /etc/libvirt/qemu/win2k8r2_bak.xml /etc/libvirt/qemu/win2k8r2.xmlvirsh define /etc/libvirt/qemu/win2k8r2.xml 编辑配置文件 1virsh edit win2k8r2 挂起 1virsh suspend win2k8r2 恢复 1virsh resume win2k8r2","categories":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}],"tags":[{"name":"kvm","slug":"kvm","permalink":"https://hxqxiaoqi.gitee.io/tags/kvm/"}],"keywords":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}]},{"title":"centos7安装mariadb","slug":"centos7安装mariadb","date":"2019-10-23T03:11:11.000Z","updated":"2020-07-24T04:03:32.273Z","comments":true,"path":"2019/10/23/centos7安装mariadb/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2019/10/23/centos7安装mariadb/","excerpt":"","text":"介绍使用yum安装mariadb，方便快捷。 安装安装并启动 12345yum install mariadb-serversystemctl start mariadb systemctl enable mariadb 初始化 12345678910111213141516171819202122232425# 初始化命令，进入交互式界面mysql_secure_installation# 输入数据库超级管理员root的密码(注意不是系统root的密码)，第一次进入还没有设置密码则直接回车Enter current password for root (enter for none): # 设置密码，ySet root password? [Y/n] # 新密码New password: # 再次输入密码Re-enter new password: # 移除匿名用户， yRemove anonymous users? [Y/n] # 拒绝root远程登录，n，不管y/n，都会拒绝root远程登录Disallow root login remotely? [Y/n] # 删除test数据库，y：删除。n：不删除，数据库中会有一个test数据库，一般不需要Remove test database and access to it? [Y/n] # 重新加载权限表，y。或者重启服务也许Reload privilege tables now? [Y/n] 登录 1mysql -u root -p 修改字符集vim /etc/my.cnf在 [mysqld] 标签下添加 12345init_connect='SET collation_connection = utf8_unicode_ci'init_connect='SET NAMES utf8'character-set-server=utf8collation-server=utf8_unicode_ciskip-character-set-client-handshake vim /etc/my.cnf.d/client.cnf在 [client] 标签下添加 1default-character-set=utf8 vim /etc/my.cnf.d/mysql-clients.cnf在 [mysql] 标签下添加 1default-character-set=utf8 重启 1systemctl restart mariadb 修改远程登录权限 123MariaDB [(none)]&gt; grant all privileges on *.* to 'root'@'%' identified by '123456Aa';MariaDB [(none)]&gt; flush privileges;","categories":[{"name":"数据库","slug":"数据库","permalink":"https://hxqxiaoqi.gitee.io/categories/数据库/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://hxqxiaoqi.gitee.io/tags/mysql/"}],"keywords":[{"name":"数据库","slug":"数据库","permalink":"https://hxqxiaoqi.gitee.io/categories/数据库/"}]},{"title":"redis常用命令","slug":"redis常用命令","date":"2019-10-19T07:29:00.000Z","updated":"2020-07-24T03:49:11.871Z","comments":true,"path":"2019/10/19/redis常用命令/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2019/10/19/redis常用命令/","excerpt":"","text":"介绍方便自己查询使用 常用命令登录查询命令1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859# 登录redis./redis-cli -h 主机IP -a 密码 -p 端口 [可执行命令]# 查看redis信息info# 查看集群身份info Replication# 清除当前数据库的所有keysflush db # 清除所有数据库的所有keysflush all # 查看所有keyskeys * # 查看前缀为\"prefix_\"的所有keyskeys prefix_* # 确认一个key是否存在exists key # 设置key和valueset key value # 获取key的valueget key # 删除一个keydel key # 返回值的类型type key # 返回满足给定pattern的所有keykeys pattern # 随机返回key空间的一个random key # 重命名keykey rename oldname newname # 返回当前数据库中key的数目db size # 选择第0~15中的库select index # 移动当前数据库中的key到dbindex数据库move key dbindex # 设置key过期时间为120秒set key value ex 120# 批量删除键redis-cli -h 192.168.10.71 -p 6379 keys \"Mpos:base:user:info:key:*\" | xargs redis-cli -h 192.168.10.71 -p 6379 del 持久化存储命令12345678# SAVE命令会占用当前的redis服务进程进行重写127.0.0.1:6379&gt; SAVE# BGSAVE命令会以redis服务进程启动一个名为redis-rdb-bgsave的子进程,因此temp-PID.rdb中的PID即是该子进程redis-rdb-bgsave的PID,因此不会阻塞redis服务进程，redis正常对外服务127.0.0.1:6379&gt; BGSAVE# 该命令会以redis服务进程打开一个名为redis-aof-rewrite的子程序127.0.0.1:6379&gt; BGREWRITEAOF 客户端连接命令12345# 查看当前连接到redis的会话：redis-cli -h 192.168.77.100 -p 7000 client list# 使用awk格式化输出，生成简易报表：redis-cli client list|sed 's/\\r//'|awk -F' |:' '&#123;print $1,$2,$5,$6,$9,$19&#125;'|column -t 参数命令123456789101112131415161718192021222324252627282930313233343536# 批量删除keycat token.txt |awk '&#123;print \"redis-cli del\"\"\\t\"$1 &#125;'| sh# 获取所有的参数redis-cli -h 192.168.77.100 -p 7000 CONFIG GET \"*\"# 获取最大内存参数redis-cli -h 192.168.77.100 -p 7000 CONFIG GET maxmemory# 返回值 6871947673# 设置参数，当前生效，无需重启redis-cli -h 192.168.77.100 -p 7000 CONFIG SET maxmemory 7000000000redis-cli -h 192.168.77.100 -p 7000 CONFIG GET maxmemory# 返回值 7000000000cat redis_7000.conf |grep ^maxmemory# maxmemory 6871947673# 配置文件并没有被修改，redis重启参数设置回滚# 将当前参数刷入配置文件redis-cli -h 192.168.77.100 -p 7000 CONFIG REWRITEcat redis_7000.conf |grep ^maxmemory# maxmemory 7000000000# 配置文件更新，参数永久设置# 重置 INFO 命令中的某些统计数据# 被重置的数据包括：# Keyspace hits (键空间命中次数)# Keyspace misses (键空间不命中次数)# Number of commands processed (执行命令的次数)# Number of connections received (连接服务器的次数)# Number of expired keys (过期key的数量)# Number of rejected connections (被拒绝的连接数量)# Latest fork(2) time(最后执行 fork(2) 的时间)# The aof_delayed_fsync counter(aof_delayed_fsync 计数器的值)redis-cli -h 192.168.77.100 -p 7000 CONFIG RESETSTAT 底层命令12345678910111213141516# 获取全部的命令列表redis-cli -h 192.168.77.100 -p 7000 COMMAND# 获取这些命令的总数redis-cli -h 192.168.77.100 -p 7000 COMMAND COUNT# 获取给定命令的所有键redis-cli -h 192.168.77.100 -p 7000 COMMAND GETKEYS SET key valueredis-cli -h 192.168.77.100 -p 7000 COMMAND GETKEYS MSET k1 v1 k2 v2 k3 v3# 获取Redis相应命令描述的数组redis-cli -h 192.168.77.100 -p 7000 COMMAND INFO del set# 不负责任的猜测：# 是命令实现的简单描述# 如set需要先调用write写# 然后调用denyoom拒绝被oom 清楚库命令1234567891011121314# 需要将命令流转化成dos格式，然后使用--pipe参数装入到redis实例echo -e \"select 2\\nflushdb\"|sed 's/$/\\r/'|redis-cli -h 192.168.77.100 -p 7000 --pipe# 删除所有数据库的所有key，全部库的key都会被清空redis-cli -h 192.168.77.100 -p 7000 FLUSHALL# 关闭redis服务redis-cli -h 192.168.77.100 -p 7000 SHUTDOWN# 默认使用SAVE命令，阻塞服务请求，生成新的RDB，然后关闭redis服务redis-cli -h 192.168.77.100 -p 7000 SHUTDOWN SAVE# 服务崩溃命令redis-cli -h 192.168.77.100 -p 7000 DEBUG SEGFAULT 服务状态命令12345678910111213141516171819202122232425262728293031323334353637383940TIME # 返回当前服务器时间UNIX时间戳，到'1970-01-01 00:00:00'+时区 的间隔秒和微秒DBSIZE # 返回当前数据库的 key 的数量LASTSAVE # 返回上一次成功保存RDB的时间戳，UNIX时间戳，到'1970-01-01 00:00:00'+时区的间隔秒DEBUG OBJECT key # 获取 key 的调试信息# Value at:0x7f2167c72528 refcount:1# encoding:embstr serializedlength:17 lru:13993658 lru_seconds_idle:1424# 返回的信息包括value内存地址、编码方式、序列化长度、lru空闲秒数 等# 慢日志相关redis-cli -c -h 192.168.21.101 -p 7000 SLOWLOG LEN# 查看当前有多少条慢日志redis-cli -c -h 192.168.21.101 -p 7000 SLOWLOG GET 1# 获取最后一条慢日志# 1) 1) (integer) 95 慢日志的ID# 2) (integer) 1523857790 慢日志UNIX时间戳# 3) (integer) 13730 慢日志的耗时/微秒# 4) 1) \"ZADD\" 慢日志具体操作内容# 2) \"&#123;OPREATE_RECORD...# 3) \"5.6704707E7\"# 4) \"&#123;\\\"aaCreateTime...# 5) \"192.168.1.117:55165\" 会话来源redis-cli -c -h 192.168.21.101 -p 7000 SLOWLOG GET# 获取全部慢日志redis-cli -c -h 192.168.21.101 -p 7000 SLOWLOG RESET# 清空慢日志# 监控 MONITORredis-cli -c -h 192.168.77.100 -p 7000 MONITOR# 相当于tailf log，将所有到该redis服务器的会话连接全部监控起来# 1523933983.091873 [0 192.168.77.100:43468] \"dbsize\"# 时间戳 [数据库 IP:PORT] \"命令\"date -d@1523933983.091873 +%F_%T_%N# 2018-04-17_10:59:43_091873000","categories":[{"name":"数据库","slug":"数据库","permalink":"https://hxqxiaoqi.gitee.io/categories/数据库/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://hxqxiaoqi.gitee.io/tags/redis/"}],"keywords":[{"name":"数据库","slug":"数据库","permalink":"https://hxqxiaoqi.gitee.io/categories/数据库/"}]},{"title":"redis配置文件详解","slug":"redis配置文件详解","date":"2019-10-19T04:00:00.000Z","updated":"2020-07-24T03:49:17.930Z","comments":true,"path":"2019/10/19/redis配置文件详解/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2019/10/19/redis配置文件详解/","excerpt":"","text":"介绍源码包安装的redis中redis.conf和sentinel.conf的配置文件详解 redis.conf配置详解123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169# 后台运行daemonize yes# 关闭保护，无密码连接protected-mode nopidfile \"/var/run/redis.pid\"port 6379# 此参数确定了TCP连接中已完成队列(完成三次握手之后)的长度， 当然此值必须不大于Linux系统定义的/proc/sys/net/core/somaxconn值，默认是511，而Linux的默认参数值是128。当系统并发量大并且客户端速度缓慢的时候，可以将这二个参数一起参考设定。该内核参数默认值一般是128，对于负载很大的服务程序来说大大的不够。一般会将它修改为2048或者更大。在/etc/sysctl.conf中添加:net.core.somaxconn = 2048，然后在终端中执行sysctl -ptcp-backlog 511# 此参数为设置客户端空闲超过timeout，服务端会断开连接，为0则服务端不会主动断开连接，不能小于0timeout 0# tcp keepalive参数。如果设置不为0，就使用配置tcp的SO_KEEPALIVE值，使用keepalive有两个好处:检测挂掉的对端。降低中间设备出问题而导致网络看似连接却已经与对端端口的问题。在Linux内核中，设置了keepalive，redis会定时给对端发送ack。检测到对端关闭需要两倍的设置值tcp-keepalive 0# 指定了服务端日志的级别。级别包括：debug（很多信息，方便开发、测试），verbose（许多有用的信息，但是没有debug级别信息多），notice（适当的日志级别，适合生产环境），warn（只有非常重要的信息）loglevel noticelogfile \"/data/redis-stable/redis_master_6379.log\"# 数据库的数量，默认使用的数据库是0。可以通过”SELECT 【数据库序号】“命令选择一个数据库，序号从0开始databases 16# RDB核心规则配置 save &lt;指定时间间隔&gt; &lt;执行指定次数更新操作&gt;，满足条件就将内存中的数据同步到硬盘中。官方出厂配置默认是 900秒内有1个更改，300秒内有10个更改以及60秒内有10000个更改，则将内存中的数据快照写入磁盘。若不想用RDB方案，可以把 save \"\" 的注释打开，下面三个注释save 900 1save 300 10save 60 10000# 当RDB持久化出现错误后，是否依然进行继续进行工作，yes：不能进行工作，no：可以继续进行工作，可以通过info中的rdb_last_bgsave_status了解RDB持久化是否有错误stop-writes-on-bgsave-error no# 配置存储至本地数据库时是否压缩数据，默认为yes。Redis采用LZF压缩方式，但占用了一点CPU的时间。若关闭该选项，但会导致数据库文件变的巨大。建议开启。rdbcompression no# 是否校验rdb文件;从rdb格式的第五个版本开始，在rdb文件的末尾会带上CRC64的校验和。这跟有利于文件的容错性，但是在保存rdb文件的时候，会有大概10%的性能损耗，所以如果你追求高性能，可以关闭该配置rdbchecksum yes# 指定本地数据库文件名，一般采用默认的 dump.rdbdbfilename \"dump.rdb\"# 数据目录，数据库的写入会在这个目录。rdb、aof文件也会写在这个目录dir \"/data/redis-stable/data\"# 当从库同主机失去连接或者复制正在进行，从机库有两种运行方式：1) 如果slave-serve-stale-data设置为yes(默认设置)，从库会继续响应客户端的请求。2) 如果slave-serve-stale-data设置为no，INFO,replicaOF, AUTH, PING, SHUTDOWN, REPLCONF, ROLE, CONFIG,SUBSCRIBE, UNSUBSCRIBE,PSUBSCRIBE, PUNSUBSCRIBE, PUBLISH, PUBSUB,COMMAND, POST, HOST: and LATENCY命令之外的任何请求都会返回一个错误”SYNC with master in progress”。slave-serve-stale-data yes# 从节点为只读slave-read-only yes# 是否使用socket方式复制数据。目前redis复制提供两种方式，disk和socket。如果新的slave连上来或者重连的slave无法部分同步，就会执行全量同步，master会生成rdb文件。有2种方式：disk方式是master创建一个新的进程把rdb文件保存到磁盘，再把磁盘上的rdb文件传递给slave。socket是master创建一个新的进程，直接把rdb文件以socket的方式发给slave。disk方式的时候，当一个rdb保存的过程中，多个slave都能共享这个rdb文件。socket的方式就的一个个slave顺序复制。在磁盘速度缓慢，网速快的情况下推荐用socket方式。repl-diskless-sync no# diskless复制的延迟时间，防止设置为0。一旦复制开始，节点不会再接收新slave的复制请求直到下一个rdb传输。所以最好等待一段时间，等更多的slave连上来repl-diskless-sync-delay 5# 是否禁止复制tcp链接的tcp nodelay参数，可传递yes或者no。默认是no，即使用tcp nodelay。如果master设置了yes来禁止tcp nodelay设置，在把数据复制给slave的时候，会减少包的数量和更小的网络带宽。但是这也可能带来数据的延迟。默认我们推荐更小的延迟，但是在数据量传输很大的场景下，建议选择yesrepl-disable-tcp-nodelay no# 适用Sentinel模块(unstable,M-S集群管理和监控),需要额外的配置文件支持。slave的权重值,默认100.当master失效后,Sentinel将会从slave列表中找到权重值最低(&gt;0)的slave,并提升为master。如果权重值为0,表示此slave为\"观察者\",不参与master选举slave-priority 100# 默认情况下，redis 会在后台异步的把数据库镜像备份到磁盘，但是该备份是非常耗时的，而且备份也不能很频繁。所以redis 提供了另外一种更加高效的数据库备份及灾难恢复方式。开启append only 模式之后，redis 会把所接收到的每一次写操作请求都追加到appendonly.aof 文件中，当redis 重新启动时，会从该文件恢复出之前的状态。但是这样会造成appendonly.aof 文件过大，所以redis 还支持了BGREWRITEAOF 指令，对appendonly.aof 进行重新整理。如果不经常进行数据迁移操作，推荐生产环境下的做法为关闭镜像，开启appendonly.aof，同时可以选择在访问较少的时间每天对appendonly.aof 进行重写一次。appendonly no# 指定本地数据库文件名，默认值为 appendonly.aofappendfilename \"appendonly.aof\"# aof持久化策略的配置# no表示不执行fsync，由操作系统保证数据同步到磁盘，速度最快# always表示每次写入都执行fsync，以保证数据同步到磁盘# everysec表示每秒执行一次fsync，可能会导致丢失这1s数据appendfsync everysec# 在aof重写或者写入rdb文件的时候，会执行大量IO，此时对于everysec和always的aof模式来说，执行fsync会造成阻塞过长时间，no-appendfsync-on-rewrite字段设置为默认设置为no。如果对延迟要求很高的应用，这个字段可以设置为yes，否则还是设置为no，这样对持久化特性来说这是更安全的选择。设置为yes表示rewrite期间对新写操作不fsync,暂时存在内存中,等rewrite完成后再写入，默认为no，建议yes。Linux的默认fsync策略是30秒。可能丢失30秒数据no-appendfsync-on-rewrite no# aof自动重写配置。当目前aof文件大小超过上一次重写的aof文件大小的百分之多少进行重写，即当aof文件增长到一定大小的时候Redis能够调用bgrewriteaof对日志文件进行重写。当前AOF文件大小是上次日志重写得到AOF文件大小的二倍（设置为100）时，自动启动新的日志重写过程auto-aof-rewrite-percentage 100# 设置允许重写的最小aof文件大小，避免了达到约定百分比但尺寸仍然很小的情况还要重写auto-aof-rewrite-min-size 64mb# aof文件可能在尾部是不完整的，当redis启动的时候，aof文件的数据被载入内存。重启可能发生在redis所在的主机操作系统宕机后，尤其在ext4文件系统没有加上data=ordered选项（redis宕机或者异常终止不会造成尾部不完整现象。）出现这种现象，可以选择让redis退出，或者导入尽可能多的数据。如果选择的是yes，当截的aof文件被导入的时候，会自动发布一个log给客户端然后load。如果是no，用户必须手动redis-check-aof修复AOF文件才可以aof-load-truncated yes# 在aof重写的时候，如果打开了aof-rewrite-incremental-fsync开关，系统会每32MB执行一次fsync。这对于把文件写入磁盘是有帮助的，可以避免过大的延迟峰值aof-rewrite-incremental-fsync yes# 如果达到最大时间限制（毫秒），redis会记个log，然后返回error。当一个脚本超过了最大时限。只有SCRIPT KILL和SHUTDOWN NOSAVE可以用。第一个可以杀没有调write命令的东西。要是已经调用了write，只能用第二个命令杀lua-time-limit 5000# slog log是用来记录redis运行中执行比较慢的命令耗时。当命令的执行超过了指定时间，就记录在slow log中，slog log保存在内存中，所以没有IO操作。# 执行时间比slowlog-log-slower-than大的请求记录到slowlog里面，单位是微秒，所以1000000就是1秒。注意，负数时间会禁用慢查询日志，而0则会强制记录所有命令。slowlog-log-slower-than 50000# 慢查询日志长度。当一个新的命令被写进日志的时候，最老的那个记录会被删掉。这个长度没有限制。只要有足够的内存就行。你可以通过 SLOWLOG RESET 来释放内存slowlog-max-len 128# 延迟监控功能是用来监控redis中执行比较缓慢的一些操作，用LATENCY打印redis实例在跑命令时的耗时图表。只记录大于等于下边设置的值的操作。0的话，就是关闭监视。默认延迟监控功能是关闭的，如果你需要打开，也可以通过CONFIG SET命令动态设置latency-monitor-threshold 0#键空间通知使得客户端可以通过订阅频道或模式，来接收那些以某种方式改动了 Redis 数据集的事件。因为开启键空间通知功能需要消耗一些 CPU ，所以在默认配置下，该功能处于关闭状态。#notify-keyspace-events 的参数可以是以下字符的任意组合，它指定了服务器该发送哪些类型的通知：##K 键空间通知，所有通知以 __keyspace@__ 为前缀##E 键事件通知，所有通知以 __keyevent@__ 为前缀##g DEL 、 EXPIRE 、 RENAME 等类型无关的通用命令的通知##$ 字符串命令的通知##l 列表命令的通知##s 集合命令的通知##h 哈希命令的通知##z 有序集合命令的通知##x 过期事件：每当有过期键被删除时发送##e 驱逐(evict)事件：每当有键因为 maxmemory 政策而被删除时发送##A 参数 g$lshzxe 的别名#输入的参数中至少要有一个 K 或者 E，否则的话，不管其余的参数是什么，都不会有任何 通知被分发。详细使用可以参考http://redis.io/topics/notificationsnotify-keyspace-events \"\"# hash类型的数据结构在编码上可以使用ziplist和hashtable。ziplist的特点就是文件存储(以及内存存储)所需的空间较小,在内容较小时,性能和hashtable几乎一样.因此redis对hash类型默认采取ziplist。如果hash中条目的条目个数或者value长度达到阀值,将会被重构为hashtable。# 这个参数指的是ziplist中允许存储的最大条目个数，，默认为512，建议为128hash-max-ziplist-entries 512# ziplist中允许条目value值最大字节数，默认为64，建议为1024hash-max-ziplist-value 64# 对于list类型,将会采取ziplist,linkedlist两种编码类型。解释同上。list-max-ziplist-entries 512list-max-ziplist-value 64# intset中允许保存的最大条目个数,如果达到阀值,intset将会被重构为hashtableset-max-intset-entries 512# zset为有序集合,有2中编码类型:ziplist,skiplist。因为\"排序\"将会消耗额外的性能,当zset中数据较多时,将会被重构为skiplist。zset-max-ziplist-entries 128zset-max-ziplist-value 64# value大小小于等于hll-sparse-max-bytes使用稀疏数据结构（sparse），大于hll-sparse-max-bytes使用稠密的数据结构（dense）。一个比16000大的value是几乎没用的，建议的value大概为3000。如果对CPU要求不高，对空间要求较高的，建议设置到10000左右hll-sparse-max-bytes 3000# Redis将在每100毫秒时使用1毫秒的CPU时间来对redis的hash表进行重新hash，可以降低内存的使用。当你的使用场景中，有非常严格的实时性需要，不能够接受Redis时不时的对请求有2毫秒的延迟的话，把这项配置为no。如果没有这么严格的实时性要求，可以设置为yes，以便能够尽可能快的释放内存activerehashing yes# 客户端buffer控制。在客户端与server进行的交互中,每个连接都会与一个buffer关联,此buffer用来队列化等待被client接受的响应信息。如果client不能及时的消费响应信息,那么buffer将会被不断积压而给server带来内存压力.如果buffer中积压的数据达到阀值,将会导致连接被关闭,buffer被移除。# buffer控制类型包括:normal -&gt; 普通连接；slave -&gt;与slave之间的连接；pubsub -&gt;pub/sub类型连接，此类型的连接，往往会产生此种问题;因为pub端会密集的发布消息,但是sub端可能消费不足.# 指令格式:client-output-buffer-limit &lt;class&gt; &lt;hard&gt; &lt;soft&gt; &lt;seconds&gt;,其中hard表示buffer最大值,一旦达到阀值将立即关闭连接;soft表示\"容忍值\",它和seconds配合,如果buffer值超过soft且持续时间达到了seconds,也将立即关闭连接,如果超过了soft但是在seconds之后，buffer数据小于了soft,连接将会被保留.其中hard和soft都设置为0,则表示禁用buffer控制.通常hard值大于soft.client-output-buffer-limit normal 0 0 0client-output-buffer-limit slave 256mb 64mb 60client-output-buffer-limit pubsub 32mb 8mb 60#Redis server执行后台任务的频率,默认为10,此值越大表示redis对\"间歇性task\"的执行次数越频繁(次数/秒)。\"间歇性task\"包括\"过期集合\"检测、关闭\"空闲超时\"的连接等,此值必须大于0且小于500。此值过小就意味着更多的cpu周期消耗,后台task被轮询的次数更频繁。此值过大意味着\"内存敏感\"性较差。建议采用默认值。hz 10# 配置密码# requirepass 123456# 用于连接认证# masterauth \"123456\" sentinel.conf配置详解12345678910111213141516171819202122232425262728293031port 8001# 守护进程模式daemonize yes# 指明日志文件名logfile \"./sentinel1.log\"# 工作路径，sentinel一般指定/tmp比较简单dir ./# 配置监听的主服务器，这里sentinel monitor代表监控，redis01代表服务器的名称，可以自定义，192.168.40.100代表监控的主服务器，6379代表端口，1代表只有1个或1个以上的哨兵认为主服务器不可用的时候，才会进行failover操作sentinel monitor mymaster 192.168.40.100 6379 1# master或slave多长时间（默认30秒）不能使用后标记为s_down状态。sentinel down-after-milliseconds mymaster 1500# 若sentinel在该配置值内未能完成failover操作（即故障时master/slave自动切换），则认为本次failover失败。sentinel failover-timeout mymaster 10000# 设置master和slaves验证密码sentinel auth-pass mymaster testmaster123# 指定最大同时同步新maser配置的salve数量sentinel parallel-syncs mymaster 1# 确认mymater SDOWN时长sentinel config-epoch mymaster 0 # 同时一时间最多2个slave可同时更新配置.sentinel leader-epoch mymaster 2","categories":[{"name":"数据库","slug":"数据库","permalink":"https://hxqxiaoqi.gitee.io/categories/数据库/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://hxqxiaoqi.gitee.io/tags/redis/"}],"keywords":[{"name":"数据库","slug":"数据库","permalink":"https://hxqxiaoqi.gitee.io/categories/数据库/"}]},{"title":"redis主从与哨兵模式搭建","slug":"redis主从与哨兵模式搭建","date":"2019-10-18T07:47:00.000Z","updated":"2020-07-24T03:49:24.722Z","comments":true,"path":"2019/10/18/redis主从与哨兵模式搭建/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2019/10/18/redis主从与哨兵模式搭建/","excerpt":"","text":"主从介绍主从：主节点负责写数据，从节点负责读数据，主节点定期把数据同步到从节点保证数据的一致性 哨兵机制介绍主要功能如下 集群监控：负责监控redis master和slave进程是否正常工作 消息通知：如果某个redis实例有故障，那么哨兵负责发送消息作为报警通知给管理员 故障转移：如果master node挂掉了，会自动转移到slave node上 配置中心：如果故障转移发生了，通知client客户端新的master地址 哨兵的核心知识 故障转移时，判断一个master node是宕机了，需要大部分的哨兵都同意才行，涉及到了分布式选举的问题 哨兵至少需要3个实例，来保证自己的健壮性 哨兵 + redis主从的部署架构，是不会保证数据零丢失的，只能保证redis集群的高可用性 部署主从环境说明： master安装：redis主 192.168.40.100:6739 node1安装：redis从 192.168.40.101:6739 node2安装：哨兵1和哨兵2 192.168.40.102:16739与192.168.40.101:26739 安装目录均在 /data 下 安装redis主： 1234567wget http://download.redis.io/redis-stable.tar.gztar xf redis-stable.tar.gz -C /datacd /data/redis-stable/make &amp;&amp; make install 配置文件 redis配置文件详解 1234567891011daemonize yesprotected-mode noport 6379pidfile \"/var/run/redis.pid\"logfile \"/var/log/redis.log\"dbfilename \"dump.rdb\"dir \"./data\"save 900 1save 300 10save 60 10000 启动 12cd /data/redis-stable/./src/redis-server ./redis.conf 安装redis从全部与安装redis主一致，只是配置文件中多一条配置，之后启动从，日志中可以看出已经连接master，并同步数据 12# 从服务指定主服务的IP和portslaveof 192.168.40.100 6379 部署哨兵安装哨兵1安装redis与上面步骤一致 12cd /data/redis-stable/vim sentinel.conf sentinel.conf配置文件redis配置文件详解 1234567891011# 设置成：protected-mode no；保护模式关闭，如果你不关闭保护模式，启动哨兵的时候，无法正常运行。还有个解决办法就是你设置密码，但是一般都不设置redis的密码。麻烦，我每次连接还得输入密码。protected-mode nodaemonize yesport 16379dir \"/tmp\"logfile \"/var/log/redis_sen1.log\"sentinel monitor redis01 192.168.40.100 6379 2sentinel down-after-milliseconds redis01 10000sentinel failover-timeout redis01 100000sentinel parallel-syncs redis01 1sentinel config-epoch redis01 5 启动 12cd /data/redis-stable/./src/redis-sentinel ./sentinel.conf 安装哨兵2安装步骤与哨兵1一致，注意区分端口和日志文件位置查看日志，如果有主从服务的相关信息，则哨兵模式部署完成 测试主从与哨兵验证主从登录主服务器，主从模式，只有主可写入数据，从不可写 123456789101112# 登录主cd /data/redis-stable/./src/redis-cli# 查看主从状态127.0.0.1:6379&gt; info Replication# 写入数据127.0.0.1:6379&gt; set test 12312312# 获取数据127.0.0.1:6379&gt; get test 登录从服务器 12345678# 查看主从状态127.0.0.1:6379&gt; info Replication# 查看主写入的数据是否同步到从127.0.0.1:6379&gt; get test# 写入数据，会提示无法写入，即是从127.0.0.1:6379&gt; set test1 343434 测试哨兵模式 1.实时查看哨兵1和哨兵2日志 2.关闭redis主服务，等待10s，哨兵日志提示，主服务下线，从服务切换为主 3.登录原从服务器，查看身份状态，身份改为主 4.测试是否可以写入 数据备份备份 12345# 该命令将在 redis 安装目录中创建dump.rdb文件redis 127.0.0.1:6379&gt; SAVE # 创建 redis 备份文件也可以使用命令 BGSAVE，该命令在后台执行。（推荐）redis 127.0.0.1:6379&gt; BGSAVE 恢复 如果需要恢复数据，只需将备份文件 (dump.rdb) 移动到 redis 安装目录并启动服务即可。获取 redis 目录可以使用 CONFIG 命令，如下所示： 1redis 127.0.0.1:6379&gt; CONFIG GET dir 启动警告警告一： 1WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128. 解决方法： 12echo \"net.core.somaxconn = 1024\" &gt;&gt; /etc/sysctl.confsysctl -p 警告二： 1WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect 解决方法： 12echo \"vm.overcommit_memory = 1\" &gt;&gt; /etc/sysctl.confsysctl -p 警告三： 1WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled. 解决方法： 1234# 临时echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled# 永久echo \"echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled\" &gt;&gt; /etc/rc.local","categories":[{"name":"数据库","slug":"数据库","permalink":"https://hxqxiaoqi.gitee.io/categories/数据库/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://hxqxiaoqi.gitee.io/tags/redis/"}],"keywords":[{"name":"数据库","slug":"数据库","permalink":"https://hxqxiaoqi.gitee.io/categories/数据库/"}]},{"title":"nginx配置大全","slug":"nginx配置大全","date":"2019-09-18T11:00:00.000Z","updated":"2020-07-24T04:08:24.203Z","comments":true,"path":"2019/09/18/nginx配置大全/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2019/09/18/nginx配置大全/","excerpt":"","text":"全局配置12345678910111213141516171819# nginx启动的进程数worker_processes 2; # 让不同的进程使用不同的cpuworker_cpu_affinity 01 10; # 一个进程打开的最多文件描述符，不大于ulimit的限制worker_rlimit_nofile 65535;events &#123; #epoll事件模型,处理效率高 use epoll; #nginx单个进程可连接的线程数 worker_connections 1024; #on:worker以串行方式处理连接,off:以并行方式,吞吐量大时建议关闭 multi_accept on; &#125; http区域设置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106http &#123; # 调用mime.types，定义资源的媒体类型,#文件扩展名与类型映射表 include mime.types; # 定义默认资源的媒体类型 default_type application/octet-stream; # 立即将数据从磁盘读到缓存,注意：如果图片显示不正常把这个改成off.所以当 Nginx 是一个静态文件服务器的时候，开启SENDFILE 配置项能大大提高 Nginx 的性能,但是当 Nginx 是作为一个反向代理来使用的时候，SENDFILE 则没什么用了，因为 Nginx 是反向代理的时候。 in_fd 就不是文件句柄而是 socket，此时就不符合 sendfile 函数的参数要求了。 sendfile on; # 防止网络阻塞，必须在sendfile开启模式才有效，与tcp_nodelay on;相反，使用数据量大的时候使用 tcp_nopush on; # 可以指定一条tcp连接上最多能发送的请求数量，超过keepalive_requests数量时server端会关闭tcp连接，默认是100 keepalive_requests 1000; # 给客户端分配keep-alive链接超时时间 keepalive_timeout 30; # 要包涵在keepalived参数才有效,禁用了Nagle 算法，适合数据少的时候使用 tcp_nodelay on; # nginx是支持读取非nginx标准的用户自定义header的，但是需要在http或者server下开启header的下划线支持: underscores_in_headers on; # 这个将为打开文件指定缓存，默认是没有启用的，max指定缓存数量，建议和打开文件inactive 是指经过多长时间文件没被请求后删除缓存。 open_file_cache max=102400 inactive=20s; # 这个是指多长时间检查一次缓存的有效信息。 open_file_cache_valid 30s; # open_file_cache指令中的inactive 参数时间内文件的最少使用次数，如果超过这个数字，文件描述符一直是在缓存中打开的，如上例，如果有一个文件在inactive 时间内一次没被使用，它将被移除。 # max=64 表示设置缓存文件的最大数目为 64, 超过此数字后 Nginx 将按照 LRU 原则丢弃冷数据。 # inactive=30d 与 open_file_cache_min_uses 8 表示如果在 30 天内某文件被访问的次数低于 8 次，那就将它从缓存中删除。 # open_file_cache_valid 3m 表示每 3 分钟检查一次缓存中的文件元信息是否是最新的，如果不是则更新之。 open_file_cache_min_uses 1; # 客户端请求头部的缓冲区大小，这个可以根据你的系统分页大小来设置，一般一个请求头的大小不会超过 1k，不过由于一&gt;般系统分页都要大于1k，所以这里设置为分页大小。分页大小可以用命令getconf PAGESIZE取得。 client_header_buffer_size 4k; # 设置读取客户端请求头超时时间，默认为60s，如果在此超时时间内客户端没有发送完请求头，则响应408（RequestTime-out）状态码给客户端 client_header_timeout 15; # 设置读取客户端内容体超时时间，默认为60s，此超时时间指的是两次成功读操作间隔时间，而不是发送整个请求体的超时时间，如果在此超时时间内客户端没有发送任何请求体，则响应408（RequestTime-out）状态码给客户端 client_body_timeout 15; # 上传文件大小限制，默认1M client_max_body_size 10m; # 告诉nginx关闭不响应的客户端连接。这将会释放那个客户端所占有的内存空间。 reset_timedout_connection on; # 设置发送响应到客户端的超时时间，默认为60s，此超时时间指的也是两次成功写操作间隔时间，而不是发送整个响应的超时时间。如果在此超时时间内客户端没有接收任何响应，则Nginx关闭此连接。 send_timeout 15; # 并不会让nginx执行的速度更快，但它可以关闭在错误页面中的nginx版本数字，这样对于安全性是有好处的。 server_tokens off; # limit模块，可防范一定量的DDOS攻击 # 用来存储session会话的状态，如下是为session分配一个名为one的10M的内存存储区，限制了每秒只接受一个ip的一次请求 1r/s limit_req_zone $binary_remote_addr zone=one:10m rate=1r/s; limit_conn_zone $binary_remote_addr zone=addr:10m; # 如果nginx是代理，因设置在代理上 gzip on; # 默认值: 0 ，不管页面多大都压缩# 设置允许压缩的页面最小字节数，页面字节数从header头中的Content-Length中进行获取。# 建议设置成大于1k的字节数，小于1k可能会越压越大。 即: gzip_min_length 1024 gzip_min_length 10k; # 设置系统获取几个单位的缓存用于存储gzip的压缩结果数据流。 例如 4 4k 代表以4k为单位，按照原始数据大小以4k为单位的4倍申请内存。 4 8k 代表以8k为单位，按照原始数据大小以8k为单位的4倍申请内存。# 如果没有设置，默认值是申请跟原始数据相同大小的内存空间去存储gzip压缩结果。 gzip_buffers 4 16k; gzip_http_version 1.1; # 默认值：1(建议选择为4)# gzip压缩比/压缩级别，压缩级别 1-9，级别越高压缩率越大，当然压缩时间也就越长（传输快但比较消耗cpu）。 gzip_comp_level 6; # 默认值: gzip_types text/html (默认不对js/css文件进行压缩)# 压缩类型，匹配MIME类型进行压缩# 不能用通配符 text/*# (无论是否指定)text/html默认已经压缩 # 设置哪压缩种文本文件可参考 conf/mime.types gzip_types text/plain application/x-javascript text/css application/xml text/javascript application/x-httpd-php image/jpeg image/gif application/javascript application/json; # 选择支持vary header；改选项可以让前端的缓存服务器缓存经过gzip压缩的页面; 这个可以不写，表示在传送数据时，给客户端说明我使用了gzip压缩。 gzip_vary on; gzip_proxied [off|expired|no-cache|no-store|private|no_last_modified|no_etag|auth|any] ... # 默认值：off # Nginx作为反向代理的时候启用，开启或者关闭后端服务器返回的结果，匹配的前提是后端服务器必须要返回包含\"Via\"的 header头。 #off - 关闭所有的代理结果数据的压缩 #expired - 启用压缩，如果header头中包含 \"Expires\" 头信息 #no-cache - 启用压缩，如果header头中包含 \"Cache-Control:no-cache\" 头信息 #no-store - 启用压缩，如果header头中包含 \"Cache-Control:no-store\" 头信息 #private - 启用压缩，如果header头中包含 \"Cache-Control:private\" 头信息 #no_last_modified - 启用压缩,如果header头中不包含 \"Last-Modified\" 头信息 #no_etag - 启用压缩 ,如果header头中不包含 \"ETag\" 头信息 #auth - 启用压缩 , 如果header头中包含 \"Authorization\" 头信息 #any - 无条件启用压缩 gzip_disable \"MSIE [1-5]\\.\"; # 禁用IE6的gzip压缩，又是因为杯具的IE6。当然，IE6目前依然广泛的存在，所以这里你也可以设置为“MSIE [1-5].” # IE6的某些版本对gzip的压缩支持很不好，会造成页面的假死，今天产品的同学就测试出了这个问题 #后来调试后，发现是对img进行gzip后造成IE6的假死，把对img的gzip压缩去掉后就正常了 #为了确保其它的IE6版本不出问题，所以建议加上gzip_disable的设置 #定义日子格式 log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"'; access_log logs/access.log main; proxy_pass反向代理配置详解123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346 location / &#123; proxy_pass http://apachephp; proxy_redirect default; #重写后端返回的域名格式 proxy_set_header Host $host; #$host变量赋予Hsot，$host：客户端请求主机地址，$proxy_host：代理服务器请求的主机地址 proxy_set_header X-Real-IP $remote_addr; #$remote_addr：为客户端IP，把真实客户端IP写入到请求头X-Real-IP proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; #把请求头中的X-Forwarded-For与$remote_addr用逗号合起来，如果请求头中没有X-Forwarded-For则$proxy_add_x_forwarded_for为$remote_addr #X-Forwarded-For代表了客户端IP，反向代理如Nginx通过$proxy_add_x_forwarded_for添加此项，X-Forwarded-For的格式为X-Forwarded-For:real client ip, proxy ip 1, proxy ip N，每经过一个反向代理就在请求头X-Forwarded-For后追加反向代理IP proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504; #注：支付功能服务最好关闭 #error 和后端服务器建立连接时，或者向后端服务器发送请求时，或者从后端服务器接收响应头时，出现错误 #timeout 和后端服务器建立连接时，或者向后端服务器发送请求时，或者从后端服务器接收响应头时，出现超时 #invalid_header 后端服务器返回空响应或者非法响应头 #http_500 后端服务器返回的响应状态码为500 #http_502 # 后端服务器返回的响应状态码为502 #http_503 # 后端服务器返回的响应状态码为503 #http_504 # 后端服务器返回的响应状态码为504 #http_404 # 后端服务器返回的响应状态码为404 #off # 停止将请求发送给下一台后端服务器#proxy_buffers代理缓冲配置 proxy_temp_file_write_size 64k; proxy_max_temp_file_size 0; #临时文件由proxy_max_temp_file_size和proxy_temp_file_write_size这两个指令决定。 proxy_temp_file_write_size是一次访问能写入的临时文件的大小，默认是proxy_buffer_size和proxy_buffers中设置的缓冲区大小的2倍，Linux下一般是8k。proxy_max_temp_file_size指定当响应内容大于proxy_buffers指定的缓冲区时, 写入硬盘的临时文件的大小. 如果超过了这个值, Nginx将与Proxy服务器同步的传递内容, 而不再缓冲到硬盘. 设置为0时, 则直接关闭硬盘缓冲. proxy_connect_timeout 60; #与后端/上游服务器建立连接的超时时间，默认为60s，此时间不超过75s。 proxy_send_timeout 60; #设置往后端/上游服务器发送请求的超时时间，默认为60s，此超时时间指的是两次成功写操作间隔时间，而不是发送整个请求的超时时间，如果在此超时时间内上游服务器没有接收任何响应，则Nginx关闭此连接。 proxy_read_timeout 60; #设置从后端/上游服务器读取响应的超时时间，默认为60s，此超时时间指的是两次成功读操作间隔时间，而不是读取整个响应体的超时时间，如果在此超时时间内上游服务器没有发送任何响应，则Nginx关闭此连接 proxy_buffer_size 4k; #后端服务器的相应头会放到proxy_buffer_size当中，这个大小默认等于proxy_buffers当中的设置单个缓冲区的大小。 proxy_buffer_size只是响应头的缓冲区，没有必要也跟着设置太大。 proxy_buffer_size最好单独设置，一般设置个4k就够了 proxy_buffers 4 32k; #proxy_buffers的缓冲区大小一般会设置的比较大，以应付大网页。 proxy_buffers当中单个缓冲区的大小是由系统的内存页面大小决定的，Linux系统中一般为4k。 proxy_buffers由缓冲区数量和缓冲区大小组成的。总的大小为number*size。若某些请求的响应过大,则超过_buffers的部分将被缓冲到硬盘(缓冲目录由_temp_path指令指定), 当然这将会使读取响应的速度减慢, 影响用户体验. 可以使用proxy_max_temp_file_size指令关闭磁盘缓冲. proxy_busy_buffers_size 64k; #proxy_busy_buffers_size不是独立的空间，他是proxy_buffers和proxy_buffer_size的一部分。nginx会在没有完全读完后端响应的时候就开始向客户端传送数据，所以它会划出一部分缓冲区来专门向客户端传送数据(这部分的大小是由proxy_busy_buffers_size来控制的，建议为proxy_buffers中单个缓冲区大小的2倍)，然后它继续从后端取数据，缓冲区满了之后就写到磁盘的临时文件中。 proxy_buffering #这个参数用来控制是否打开后端响应内容的缓冲区，如果这个设置为off，那么proxy_buffers和proxy_busy_buffers_size这两个指令将会失效。 但是无论proxy_buffering是否开启，对proxy_buffer_size都是生效的#proxy_cache代理缓存设置 #nginx的web缓存功能的主要是由proxy_cache、fastcgi_cache指令集和相关指令集完成，proxy_cache指令负责反向代理缓存后端服务器的静态内容，fastcgi_cache主要用来处理FastCGI动态进程缓存 http块： proxy_cache_path /tmp/cache levels=1:2 keys_zone=nuget-cache:20m max_size=50g inactive=168h; #levels=1:2 #nginx会在上述配置的缓存文件路径下再创建两级目录，第一级目录命名为一个字符，第二级目录命名为2个字符 #keys_zone=nuget-cache:20m #定义缓存名称和共享内存大小，并mkdir创建nuget-cache缓存目录 #max_size=50g #最大缓存空间，如果缓存空间满，默认覆盖掉缓存时间最长的资源。 #inactive=168h #定义缓存时间 server/location块： proxy_cache nuget-cache; #开启nuget-cache缓存 proxy_cache_valid 200 304 1h; #状态码200|304的过期为12h proxy_cache_valid 404 1m; #状态码404的过期为1分钟 proxy_cache_valid any 1d; #其它的状态码过期为1天 proxy_ignore_headers X-Accel-Expires Expires Cache-Control Set-Cookie; #忽略后端头部缓存规则，这句代码很关键，尤其要忽略set-cookie proxy_hide_header Cache-Control; #隐藏响应头部信息 add_header Cache-Control no-store； #设置响应头部请求 proxy_cache_key $host$uri$is_args$args;#设置nginx服务器在内存中为缓存数据建立索引时使用的关键字#upstream负载均衡配置 Nginx的upstream支持5种分配方式，下面将会详细介绍，其中，前三种为Nginx原生支持的分配方式，后两种为第三方支持的分配方式： 1、轮询 轮询是upstream的默认分配方式，即每个请求按照时间顺序轮流分配到不同的后端服务器，如果某个后端服务器down掉后，能自动剔除。 upstream backend &#123; server 192.168.1.101:8888; server 192.168.1.102:8888; server 192.168.1.103:8888; &#125; 2、weight 轮询的加强版，即可以指定轮询比率，weight和访问几率成正比，主要应用于后端服务器异质的场景下。 upstream backend &#123; server 192.168.1.101 weight=1; server 192.168.1.102 weight=2; server 192.168.1.103 weight=3; &#125; 3、ip_hash 每个请求按照访问ip（即Nginx的前置服务器或者客户端IP）的hash结果分配，这样每个访客会固定访问一个后端服务器，可以解决session一致问题。 upstream backend &#123; ip_hash; server 192.168.1.101:7777; server 192.168.1.102:8888; server 192.168.1.103:9999; &#125; 4、fair fair顾名思义，公平地按照后端服务器的响应时间（rt）来分配请求，响应时间短即rt小的后端服务器优先分配请求。 upstream backend &#123; server 192.168.1.101; server 192.168.1.102; server 192.168.1.103; fair; &#125; 5、url_hash 与ip_hash类似，但是按照访问url的hash结果来分配请求，使得每个url定向到同一个后端服务器，主要应用于后端服务器为缓存时的场景下。 upstream backend &#123; server 192.168.1.101; server 192.168.1.102; server 192.168.1.103; hash $request_uri; hash_method crc32; &#125; 其中，hash_method为使用的hash算法，需要注意的是：此时，server语句中不能加weight等参数。 二、设备状态 down：表示当前server已停用 backup：表示当前server是备用服务器，只有其它非backup后端服务器都挂掉了或者很忙才会分配到请求。 weight：表示当前server负载权重，权重越大被请求几率越大。默认是1. max_fails和fail_timeout一般会关联使用，如果某台server在fail_timeout时间内出现了max_fails次连接失败，那么Nginx会认为其已经挂掉了，从而在fail_timeout时间内不再去请求它，fail_timeout默认是10s，max_fails默认是1，即默认情况是只要发生错误就认为服务器挂掉了，如果将max_fails设置为0，则表示取消这项检查。 举例说明如下： upstream backend &#123; server backend1.example.com weight=5; server 127.0.0.1:8080 max_fails=3 fail_timeout=30s; server unix:/tmp/backend3 down; &#125;#location配置 已=开头表示精确匹配 如 A 中只匹配根目录结尾的请求，后面不能带任何字符串。 ^~ 开头表示uri以某个常规字符串开头，不是正则匹配 ~ 开头表示区分大小写的正则匹配; ~* 开头表示不区分大小写的正则匹配 / 通用匹配, 如果没有其它匹配,任何请求都会匹配到 顺序 no优先级：(location =) &gt; (location 完整路径) &gt; (location ^~ 路径) &gt; (location ~,~* 正则顺序) &gt; (location 部分起始路径) &gt; (/) #将符合js,css文件的等设定expries缓存参数，要求浏览器缓存。 location ~* \\.(jpg|jpeg|gif|bmp|png)&#123; deny all; #location 标签，根目录下的.svn目录禁止访问 allow 219.237.222.30; ##允许访问的ip limit_rate_after 100k; #文件的大小限制 limit_rate 100k; #超过文件大小限制，限制速度为100k/s client_max_body_size 1000m; #请求数据大小限制的 log_not_found off;#是否在error_log中记录不存在的错误。默认是 access_log off; expires 1d;#缓存1天 &#125;#rewrite配置 #格式： rewrite regex replacement [flag] #正则：regex . ： 匹配除换行符以外的任意字符 ? ： 重复0次或1次 + ： 重复1次或更多次 * ： 重复0次或更多次 \\d ：匹配数字 ^ ： 匹配字符串的开始 $ ： 匹配字符串的介绍 &#123;n&#125; ： 重复n次 &#123;n,&#125; ： 重复n次或更多次 [c] ： 匹配单个字符c [a-z] ： 匹配a-z小写字母的任意一个 #变量赋值 set $hostx \"\"; set $addrs \"\"; #用作if判断的全局变量replacement $args ： 这个变量等于请求行中的参数，同$query_string $content_length ： 请求头中的Content-length字段。 $content_type ： 请求头中的Content-Type字段。 $document_root ： 当前请求在root指令中指定的值。 $host ： 请求主机头字段，否则为服务器名称。 $http_user_agent ： 客户端agent信息 $http_cookie ： 客户端cookie信息 $limit_rate ： 这个变量可以限制连接速率。 $request_method ： 客户端请求的动作，通常为GET或POST。 $remote_addr ： 客户端的IP地址。 $remote_port ： 客户端的端口。 $remote_user ： 已经经过Auth Basic Module验证的用户名。 $request_filename ：当前请求的文件路径，由root或alias指令与URI请求生成。 $scheme ： HTTP方法（如http，https）。 $server_protocol ： 请求使用的协议，通常是HTTP/1.0或HTTP/1.1。 $server_addr ： 服务器地址，在完成一次系统调用后可以确定这个值。 $server_name ： 服务器名称。 $server_port ： 请求到达服务器的端口号。 $request_uri ： 包含请求参数的原始URI，不包含主机名，如：”/foo/bar.php?arg=baz”。 $uri ： 不带请求参数的当前URI，$uri不包含主机名，如”/foo/bar.html”。 $document_uri ： 与$uri相同。 #标签flag last : 相当于Apache的[L]标记，表示完成rewrite break : 停止执行当前虚拟主机的后续rewrite指令集 redirect : 返回302临时重定向，地址栏会显示跳转后的地址 permanent : 返回301永久重定向，地址栏会显示跳转后的地址 因为301和302不能简单的只返回状态码，还必须有重定向的URL，这就是return指令无法返回301,302的原因了。这里 last 和 break 区别有点难以理解： #注 last一般写在server和if中，而break一般使用在location中 last不终止重写后的url匹配，即新的url会再从server走一遍匹配流程，而break终止重写后的匹配 break和last都能组织继续执行后面的rewrite指令 #https-ssl相关配置 方法一： server &#123; listen 80; server_name bjubi.com;#你的域名 rewrite ^(.*)$ https://$host$1 permanent;#把http的域名请求转成https &#125; server &#123; listen 443; #监听端口 server_name bjubi.com; root html； ssl on; #开启ssl ssl_certificate /ls/app/nginx/conf/mgmtxiangqiankeys/server.crt; #服务的证书 ssl_certificate_key /ls/app/nginx/conf/mgmtxiangqiankeys/server.key; #服务端key ssl_client_certificate /ls/app/nginx/conf/mgmtxiangqiankeys/ca.crt; #客户端证书 ssl_session_timeout 5m; #session超时时间 ssl_verify_client on; # 开户客户端证书验证 ssl_protocols SSLv2 SSLv3 TLSv1; #允许SSL协议 ssl_ciphers ALL:!ADH:!EXPORT56:RC4+RSA:+HIGH:+MEDIUM:+LOW:+SSLv2:+EXP; #加密算法 ssl_prefer_server_ciphers on; #启动加密算法 location / &#123; index index.html index.htm; &#125; &#125; 方法二： if ($scheme != https) &#123; # 强制 HTTP 跳转至 HTTPS # host 与 server_name 等价, redirect/permanent 分别为临时跳转/永久跳转 rewrite ^(.*)$ https://$host$1 permanent; &#125; #防盗链 #防止别人直接从你网站引用图片等链接，消耗了你的资源和网络流量，那么我们的解决办法由几种： 1：水印，品牌宣传，你的带宽，服务器足够 2：防火墙，直接控制，前提是你知道IP来源 3：防盗链策略下面的方法是直接给予404的错误提示 location ~* .*\\.(gif|jpg|png|jpeg)$ &#123; expires 30d; valid_referers *.hugao8.com www.hugao8.com m.hugao8.com *.baidu.com *.google.com; if ($invalid_referer) &#123; #rewrite ^/ http://ww4.sinaimg.cn/bmiddle/051bbed1gw1egjc4xl7srj20cm08aaa6.jpg; return 404; &#125; &#125; #第一行：其中“gif|jpg|jpeg|png|bmp|swf”设置防盗链文件类型，自行修改，每个后缀用“|”符号分开！ #第三行：就是白名单，允许文件链出的域名白名单，自行修改成您的域名！*.it300.com这个指的是子域名，域名与域名之间使用空格隔开！ #第五行：这个图片是盗链返回的图片，也就是替换盗链网站所有盗链的图片。这个图片要放在没有设置防盗链的网站上，因为防盗链的作用，这个图片如果也放在防盗链网站上就会被当作防盗链显示不出来了，盗链者的网站所盗链图片会显示X符号。 #第六行：直接返回404#后端服务器获取真实IP设置 nginx代理设置 proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; 后端服务器设置（在http或server设置，需要加载模块--with-http_realip_module） real_ip_header X-Forwarded-For; #X-Forwarded-For获取代理IP段的第一个IP为真实IP set_real_ip_from 192.168.0.0/16; #定义从哪台服务器获取代理IP段 real_ip_recursive on; #real_ip_recursive 是否递归地排除直至得到用户ip#跨域设置 #跨域其实就是访问不同网站的内容，可以直接使用rewrite重写实现 #以下是反向代理实现跨域 location /apis &#123; rewrite ^/apis/(.*)$ /$1 break; proxy_pass http://localhost:82; &#125; 实例：user www www;worker_processes 4;worker_cpu_affinity 0001 0010 0100 1000;error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;worker_rlimit_nofile 10240;pid logs/nginx.pid;events &#123; use epoll; worker_connections 4096;&#125;http &#123; include mime.types; default_type application/octet-stream; log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"' '\"$upstream_cache_status\"';access_log logs/access.log main;server_tokens off; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #Compression Settings gzip on; gzip_comp_level 6; gzip_http_version 1.1; gzip_proxied any; gzip_min_length 1k; gzip_buffers 16 8k; gzip_types text/plain text/css text/javascript application/json application/javascript application/x-javascript application/xml; gzip_vary on; #end gzip # http_proxy Settings client_max_body_size 10m; client_body_buffer_size 128k; proxy_connect_timeout 75; proxy_send_timeout 75; proxy_read_timeout 75; proxy_buffer_size 4k; proxy_buffers 4 32k; proxy_busy_buffers_size 64k; proxy_temp_file_write_size 64k; proxy_buffering on; proxy_temp_path /usr/local/nginx1.10/proxy_temp; proxy_cache_path /usr/local/nginx1.10/proxy_cache levels=1:2 keys_zone=my-cache:100m max_size=1000m inactive=600m max_size=2g; #load balance Settings upstream backend &#123; sticky; server 192.168.31.141:80 weight=1 max_fails=2 fail_timeout=10s; server 192.168.31.250:80 weight=1 max_fails=2 fail_timeout=10s; &#125; #virtual host Settings server &#123; listen 80; server_name localhost; charset utf-8; location ~/purge(/.*) &#123; allow 127.0.0.1; allow 192.168.31.0/24; deny all; proxy_cache_purge my-cache $host$1$is_args$args; &#125; location / &#123; index index.php index.html index.htm; proxy_pass http://backend; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_ignore_headers Set-Cookie;proxy_hide_header Set-Cookie; proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504; &#125; location ~ .*\\.(gif|jpg|png|html|htm|css|js|ico|swf|pdf)(.*) &#123; proxy_pass http://backend; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504; proxy_cache my-cache; add_header Nginx-Cache $upstream_cache_status; proxy_cache_valid 200 304 301 302 8h; proxy_cache_valid 404 1m; proxy_cache_valid any 1d; proxy_cache_key $host$uri$is_args$args; expires 30d; &#125; location /nginx_status &#123; stub_status on; access_log off; allow 192.168.31.0/24; deny all; &#125; &#125;&#125;","categories":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://hxqxiaoqi.gitee.io/tags/nginx/"}],"keywords":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}]},{"title":"kubeadm部署","slug":"k8s部署","date":"2019-09-17T07:06:00.000Z","updated":"2020-07-24T03:50:28.327Z","comments":true,"path":"2019/09/17/k8s部署/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2019/09/17/k8s部署/","excerpt":"","text":"介绍 Kubernetes是当今最流行的开源容器管理平台，它就是大名鼎鼎的Google Borg的开源版本。Google在2014年推出了Kubernetes，本文发布时最新的版本是1.11。 Kubernetes源于希腊语，意为舵手，K8S是一个简称，因为首尾字母中间正好有8个字母。基于容器技术，Kubernetes可以方便的进行集群应用的部署、扩容、缩容、自愈机制、服务发现、负载均衡、日志、监控等功能，大大减少日常运维的工作量。 Kubernetes所有的操作都可以通过Kubernetes API来进行，通过API来操作Kubernetes中的对象，包括Pod、Service、Volume、Namespace等等。 组件说明API Server：整个集群管理的 API 接口，所有对集群进行的查询和管理都要通过 API 来进行集群内部各个模块之间通信的枢纽，所有模块之前并不会之间互相调用，而是通过和 API Server 打交道来完成自己那部分的工作集群安全控制，API Server 提供的验证和授权保证了整个集群的安全。 Kube Proxy：负责为pod提供代理。它会定期从etcd获取所有的service，并根据service信息创建代理。当某个客户pod要访问其他pod时，访问请求会经过本机proxy做转发。 Scheduler：负责集群的资源调度,跟踪集群中所有Node的资源利用情况,对新创建的pod，采取合适的调度策略，进行均衡的调度到合适的节点上。 etcd：Kubernetes所有的配置数据存储在etcd中；所有组件通过API Server和etcd打交道。 Controller Manager：主要负责集群的故障检测和恢复的自动化，它内部的组件如下:1.endpointController:定期关联service和pod，关联信息由endpoint负责创建和更新。2.ReplicationController:完成pod的复制或移除，以确保ReplicationController定义的复本数量与实际运行pod的数量一致性 CoreDNS：Kubernetes包括用于服务发现的DNS服务器Kube-DNS。 该DNS服务器利用SkyDNS的库来为Kubernetes pod和服务提供DNS请求。在这种灵活的模型中添加对Kubernetes的支持，相当于创建了一个Kubernetes中间件。该中间件使用Kubernetes API来满足针对特定Kubernetes pod或服务的DNS请求。而且由于Kube-DNS作为Kubernetes的另一项服务，kubelet和Kube-DNS之间没有紧密的绑定。您只需要将DNS服务的IP地址和域名传递给kubelet，而Kubernetes并不关心谁在实际处理该IP请求。 pause：我们看下在node节点上都会起很多pause容器，和pod是一一对应的。每个Pod里运行着一个特殊的被称之为Pause的容器，其他容器则为业务容器，这些业务容器共享Pause容器的网络栈和Volume挂载卷，因此他们之间通信和数据交换更为高效，在设计时我们可以充分利用这一特性将一组密切相关的服务进程放入同一个Pod中。同一个Pod里的容器之间仅需通过localhost就能互相通信。 Flannel：通过给每台宿主机分配一个子网的方式为容器提供虚拟网络，它基于Linux TUN/TAP，使用UDP封装IP包来创建overlay网络，并借助etcd维护网络的分配情况。简单说就是给pod分配ip的。 kubelet：每个node上都会启动一个kubelet服务进程，相当于agent进程，该进程用于处理master节点下发到本节点的任务，管理Pod及Pod中的容器，同时Kubelet进程会在API Server上注册节点自身的信息，定期向Master节点汇报节点的资源情况，并通过cAdvise监控容器和节点资源；它负责创建和销毁Pod，通过探针监测Pod的状态，并通过cAdvise监控Pod的状态。 kubeadm：k8s的一键安装工具。 kubectl：通过apiserver组件向整个集群內发送控制命令的管理工具。 service：是pod的路由代理抽象，用于解决pod之间的服务发现问题，即上下游pod之间使用的问题。传统部署方式中，实例所在的主机ip（或者dns名字）一般是不会改变的，但是pod的运行状态可动态变化(比如容器重启、切换机器了、缩容过程中被终止了等)，所以访问端不能以写死IP的方式去访问该pod提供的服务。service的引入旨在保证pod的动态变化对访问端透明，访问端只需要知道service的地址，由service来提供代理。Service分为三类：ClusterIP，NodePort，LoadBalancer。 Pod：Pod是kubernetes集群中的最小单元，可以运行一个或多个容器，Pod对外共享一个ip，通过livenessProbe探针监测容器是否健康，另外一类是readinessProbe探针来判断容器是否启动完成。 Deployment：为Pod和Replica Set提供声明式更新。你只需要在 Deployment 中描述您想要的目标状态是什么，Deployment controller 就会帮您将 Pod 和ReplicaSet 的实际状态改变到您的目标状态。您可以定义一个全新的 kubeadm部署环境准备（所有节点都要操作）实验虚拟机：k8s-master：192.168.40.100k8s-node1：192.168.40.101k8s-node2：192.168.40.102 设置主机名： 123hostnamectl set-hostname k8s-masterhostnamectl set-hostname k8s-node1hostnamectl set-hostname k8s-node2 配置hosts文件解析： 12345cat &gt;&gt; /etc/hosts &lt;&lt; EOF192.168.40.100 k8s-master192.168.40.101 k8s-node1192.168.40.102 k8s-node2EOF 关闭防火墙和selinux： 12systemctl stop firewalld &amp;&amp; systemctl disable firewalldsed -i 's/^SELINUX=enforcing$/SELINUX=disabled/' /etc/selinux/config &amp;&amp; setenforce 0 关闭swap： 12swapoff -a sed -i 's/.*swap.*/#&amp;/' /etc/fstab 设置网桥包经过iptalbes：RHEL / CentOS 7上的一些用户报告了由于iptables被绕过而导致流量路由不正确的问题。 1234567891011# 创建/etc/sysctl.d/k8s.conf文件，添加如下内容cat &lt;&lt;EOF &gt; /etc/sysctl.d/k8s.confvm.swappiness = 0net.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1net.ipv4.ip_forward = 1EOF# 使配置生效modprobe br_netfiltersysctl -p /etc/sysctl.d/k8s.conf kube-proxy开启ipvs的前提条件：由于ipvs已经加入到了内核的主干，所以为kube-proxy开启ipvs的前提需要加载以下的内核模块： 1234567891011121314cat &gt; /etc/sysconfig/modules/ipvs.modules &lt;&lt;EOF#!/bin/bashmodprobe -- ip_vsmodprobe -- ip_vs_rrmodprobe -- ip_vs_wrrmodprobe -- ip_vs_shmodprobe -- nf_conntrack_ipv4EOF# 执行脚本chmod 755 /etc/sysconfig/modules/ipvs.modules &amp;&amp; bash /etc/sysconfig/modules/ipvs.modules &amp;&amp; lsmod | grep -e ip_vs -e nf_conntrack_ipv4# 查看是否已经正确加载所需的内核模块lsmod | grep -e ip_vs -e nf_conntrack_ipv4 安装ipvsadm：接下来还需要确保各个节点上已经安装了ipset软件包，为了便于查看ipvs的代理规则。 1yum -y install ipset ipvsadm 安装Docker： 1234567yum -y install yum-utilsyum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repoyum install -y docker-ce-18.06.1.cesystemctl start docker &amp;&amp; systemctl enable docker 配置kubernetes源： 123456789cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetesbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/enabled=1gpgcheck=1repo_gpgcheck=1gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpgEOF 安装kubeadm、kubelet、kubectl： 12345yum install -y kubelet-1.13.1 yum install -y kubeadm-1.13.1 yum install -y kubectl-1.13.1systemctl enable kubelet &amp;&amp; systemctl start kubelet 设置时间同步配置k8s-master节点： 1234567891011121314151617181920# 安装chrony：yum install -y chrony# 注释默认ntp服务器sed -i 's/^server/#&amp;/' /etc/chrony.conf# 指定上游公共 ntp 服务器，并允许其他节点同步时间cat &gt;&gt; /etc/chrony.conf &lt;&lt; EOFserver 0.asia.pool.ntp.org iburstserver 1.asia.pool.ntp.org iburstserver 2.asia.pool.ntp.org iburstserver 3.asia.pool.ntp.org iburstallow allEOF# 重启chronyd服务并设为开机启动：systemctl enable chronyd &amp;&amp; systemctl restart chronyd# 开启网络时间同步功能timedatectl set-ntp true 配置k8s-node节点： 1234567891011121314# 安装chrony：yum install -y chrony# 注释默认服务器sed -i 's/^server/#&amp;/' /etc/chrony.conf# 指定内网 master节点为上游NTP服务器echo server 192.168.40.100 iburst &gt;&gt; /etc/chrony.conf# 重启服务并设为开机启动：systemctl enable chronyd &amp;&amp; systemctl restart chronyd# 所有节点执行，查看是否同步成功chronyc sources master节点操作初始化k8s-master：初始化过程需要下载镜像，要等待几分钟，注意更改主机IP。注意：如果cpu需要2核，否则会报错。 12345678# 初始化，成功后会生成节点加入集群的命令，保存下来kubeadm init --apiserver-advertise-address=192.168.40.100 --image-repository registry.aliyuncs.com/google_containers --kubernetes-version v1.13.1 --pod-network-cidr=10.244.0.0/16mkdir -p $HOME/.kubecp -i /etc/kubernetes/admin.conf $HOME/.kube/config# 查看集群状态kubectl get cs 下载flannel网络插件：如果网络不好，需要耐心等待flannel进行下载完成 12345678# 安装flannel插件kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml# 查看coredns是否运行kubectl get pod -n kube-system -o wide# 如果节点Ready状态，即表示运行正常kubectl get nodes node操作加入集群1234567# 执行，这是master节点出生成功后生成的kubeadm join 192.168.40.100:6443 --token 0jxnxc.5pn1l3z931kcdqzv --discovery-token-ca-cert-hash sha256:d3de7befd0aa46d999c8f3a4880e45b7f4ab87dafa54c39232078b6cec5b1833#如果执行kubeadm init时没有记录下加入集群的命令，可以通过以下命令重新创建# 查看节点，如果node显示，则成功kubectl get nodes kubectl命令获取节点相应服务的信息 1kubectl get pods 查看集群信息 1kubectl cluster-info 查看各组件信息 1kubectl get cs 查看pods所在的运行节点 1kubectl get pods -o wide 查看pods定义的详细信息 1kubectl get pods -o yaml 查看运行的pod的环境变量 1kubectl exec pod名 env 查看指定pod的日志 1kubectl logs -f pods/heapster-xxxxx 创建资源 1kubectl create -f 文件名.yaml 重建资源 1kubectl replace -f 文件名 [--force] 删除资源 12345kubectl delete -f 文件名kubectl delete pod pod名kubectl delete rc rc名kubectl delete service service名kubectl delete pod --all 查看所有service 1kubectl get services kubernetes-dashboard -n kube-system 查看所有发布 1kubectl get deployment kubernetes-dashboard -n kube-system 查看所有pod 1kubectl get pods --all-namespaces 查看所有pod的IP及节点 12kubectl get pods -o wide --all-namespaces kubectl get pods -n kube-system | grep dashboard 查看指定资源详细描述信息 1kubectl describe svc --namespace=\"kube-system\" 指定类型查看 1kubectl describe pods/kubernetes-dashboard-349859023-g6q8c --namespace=\"kube-system\" 查看pod详细信息 1kubectl describe pod nginx-772ai 动态伸缩 1kubectl scale rc nginx --replicas=5 动态伸缩 1kubectl scale deployment redis-slave --replicas=5 动态伸缩 1kubectl scale --replicas=2 -f redis-slave-deployment.yaml 进入pod容器注：/bin/bash如果不能进入，可以换成sh 1kubectl exec -it redis-master-1033017107-q47hh /bin/bash 增加lable值 [key]=[value] 1kubectl label pod redis-master-1033017107-q47hh role=master 删除lable值 1kubectl label pod redis-master-1033017107-q47hh role- 修改lable值 1kubectl label pod redis-master-1033017107-q47hh role=backend --overwrite 指定pod在哪个节点 1kubectl label nodes node1 zone=north 配置文件滚动升级 1kubectl rolling-update redis-master -f redis-master-controller-v2.yaml 命令升级 1kubectl rolling-update redis-master --image=redis-master:2.0 pod版本回滚 1kubectl rolling-update redis-master --image=redis-master:1.0 --rollback","categories":[{"name":"kubernetes","slug":"kubernetes","permalink":"https://hxqxiaoqi.gitee.io/categories/kubernetes/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://hxqxiaoqi.gitee.io/tags/k8s/"}],"keywords":[{"name":"kubernetes","slug":"kubernetes","permalink":"https://hxqxiaoqi.gitee.io/categories/kubernetes/"}]},{"title":"ansible基本配置","slug":"ansible基本配置","date":"2019-09-09T12:00:00.000Z","updated":"2020-07-24T03:40:48.407Z","comments":true,"path":"2019/09/09/ansible基本配置/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2019/09/09/ansible基本配置/","excerpt":"","text":"介绍官方的title是“Ansible is Simple IT Automation”——简单的自动化IT工具。这个工具的目标有这么几项：让我们自动化部署APP；自动化管理配置项；自动化的持续交付；自动化的（AWS）云服务管理。 所有的这几个目标本质上来说都是在一个台或者几台服务器上，执行一系列的命令而已,批量的在远程服务器上执行命令 。 ansible是一个轻量级的运维自动化配置管理和配置工具，基于Python研发。集合了众多老牌运维工具（puppet、cfengine、chef、func、fabric）的优点，实现了批量系统配置、批量程序部署、批量运行命令等功能 安装1yum -y install ansible 目录说明 ansible.cfg：配置文件 hosts：设置被管理服务器IP roles：ansible-playbook存放位置 ansible.cfg配置文件中配置 12#跳过第一次连接检测询问是否登陆的提示（YES/NO）host_key_checking=False host配置1234567891011#远程主机登陆端口ansible_ssh_port=22#远程主机登陆用户名ansible_ssh_user=root#远程主机登陆用户名的密码ansible_ssh_pass= # sudo密码ansible_sudo_pass 设置主机组使用ansible工具时，指定web组，相当于控制web组下的主机 123[web]192.168.1.101192.168.1.100 设置主机地址段相当于一个IP段或域名段的主机 123[web]192.168.1.[2:100]www.test[a:z].com 指定主机用户、密码、端口使用ansible工具时，自动使用该账户登录操作如果想不使用账号密码操作，需要提前设置 ssh免密设置 12[web]192.168.1.100 ansible_ssh_user=root ansible_ssh_pass=123 ansible_ssh_port=22 设置主机组变量等于所有主机都已经指定用户、密码、端口 123456789[web]192.168.1.100192.168.1.101192.168.1.102[web:vars]ansible_ssh_user=root ansible_ssh_pass=123 ansible_ssh_port=22 主机组继承类似于web、web1是weball的子集，使用weball组，包含web、web1组 12345678[web]192.168.182.101[web1]192.168.182.100[weball:children]web1web 模块1234567命令格式：ansible [主机/主机组] [-m 模块] [-a args]# 列出所有安装模块（q退出）ansible-doc -l # 列出yum模块描述信息和操作动作ansible-doc -s yum command模块这个模块可以直接在远程主机上执行命令，并将结果返回本主机。注意，该命令不支持 | 管道命令 12345# 查询dateansible all -m command -a 'date' # 如果不加-m模块，默认运行command模块ansible all -a 'ls /' cron模块该模块适用于管理cron计划任务的。 minute参数：此参数用于设置计划任务中分钟设定位的值，比如，上述示例1中分钟设定位的值为5，即 minute=5，当不使用此参数时，分钟设定位的值默认为”*”。 hour参数：此参数用于设置计划任务中小时设定位的值，比如，上述示例1中小时设定位的值为1，即 hour=1，当不使用此参数时，小时设定位的值默认为”*”。 day参数：此参数用于设置计划任务中日设定位的值，当不使用此参数时，日设定位的值默认为”*”。 month参数：此参数用于设置计划任务中月设定位的值，当不使用此参数时，月设定位的值默认为”*”。 weekday参数：此参数用于设置计划任务中周几设定位的值，当不使用此参数时，周几设定位的值默认为”*”。 job参数：此参数用于指定计划的任务中需要实际执行的命令或者脚本，比如上例中的 “echo test” 命令。 name参数：此参数用于设置计划任务的名称，计划任务的名称会在注释中显示 state参数：当计划任务有名称时，我们可以根据名称修改或删除对应的任务，当删除计划任务时，需要将 state 的值设置为 absent。 12345#-a：指定添加参数*/1：每分钟执行job：执行内容 ansible all -m cron -a 'minute=\"*/1\" job=\"/usr/bin/echo heihei &gt;&gt; /opt/test.txt\" name=\"test cron\"' # 在all主机上创建计划任务，任务名称为”crontab day test”，任务每3天执行一次，于执行当天的1点1分开始执行，任务内容为输出 test 字符。ansible all -m cron -a \"name='crontab day test' minute=1 hour=1 day=*/3 job='echo test' ##","categories":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}],"tags":[{"name":"ansible","slug":"ansible","permalink":"https://hxqxiaoqi.gitee.io/tags/ansible/"}],"keywords":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}]},{"title":"docker-compose基本用法","slug":"docker-compose基本用法","date":"2019-09-08T13:00:00.000Z","updated":"2020-07-24T03:51:01.721Z","comments":true,"path":"2019/09/08/docker-compose基本用法/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2019/09/08/docker-compose基本用法/","excerpt":"","text":"介绍Compose项目来源于之前的fig项目，使用python语言编写,与docker/swarm配合度很高。 Compose 是 Docker 容器进行编排的工具，定义和运行多容器的应用，可以一条命令启动多个容器，使用Docker Compose不再需要使用shell脚本来启动容器。 Compose 通过一个配置文件来管理多个Docker容器，在配置文件中，所有的容器通过services来定义，然后使用docker-compose脚本来启动，停止和重启应用，和应用中的服务以及所有依赖服务的容器，非常适合组合使用多个容器进行开发的场景。 docker-compose安装1234567curl -L \"https://github.com/docker/compose/releases/download/1.24.1/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-composechmod +x /usr/local/bin/docker-composeln -s /usr/local/bin/docker-compose /usr/bin/docker-composedocker-compose --version mysql模板1234567891011121314151617version: '2'services: mysql: network_mode: \"bridge\" container_name: \"mysql\" environment: MYSQL_ROOT_PASSWORD: \"123123\" MYSQL_USER: 'test' MYSQL_PASS: '123123' image: \"mysql:5.7\" restart: always volumes: - \"./db:/var/lib/mysql\" - \"./conf/my.cnf:/etc/my.cnf\" - \"./init:/docker-entrypoint-initdb.d/\" ports: - \"3306:3306\" 创建db、conf、init三个目录 在conf目录下创建my.cnf配置文件 在init目录下创建init.sql初始化文件 my.cnf实例 12345678[mysqld]user=mysqldefault-storage-engine=INNODBcharacter-set-server=utf8[client]default-character-set=utf8[mysql]default-character-set=utf8 init.sql实例 1234567891011121314use mysql;ALTER USER 'root'@'%' IDENTIFIED WITH mysql_native_password BY '123123';create database test;use test;create table user( id int auto_increment primary key, username varchar(64) unique not null, email varchar(120) unique not null, password_hash varchar(128) not null, avatar varchar(128) not null);insert into user values(1, \"zhangsan\",\"test12345@qq.com\",\"passwd\",\"avaterpath\");insert into user values(2, \"lisi\",\"12345test@qq.com\",\"passwd\",\"avaterpath\"); nginx模板12345678910111213version: '2'services: web: image: nginx ports: - \"8080:80\" container_name: \"web\" networks: - devnetworks: dev: driver: bridge 基本语法imageimage 是指定服务的镜像名称或镜像 ID。如果镜像在本地不存在，Compose 将会尝试拉取这个镜像。 123services: web: image: hello-world build服务除了可以基于指定的镜像，还可以基于一份 Dockerfile，在使用 up 启动之时执行构建任务，这个构建标签就是 build，它可以指定 Dockerfile 所在文件夹的路径。Compose 将会利用它自动构建这个镜像，然后使用这个镜像启动服务容器。 build: /path/to/build/dir也可以是相对路径，只要上下文确定就可以读取到 Dockerfile。 build: ./dir设定上下文根目录，然后以该目录为准指定 Dockerfile。 build: context: ../ dockerfile: path/of/Dockerfile注意 build 都是一个目录，如果你要指定 Dockerfile 文件需要在 build 标签的子级标签中使用 dockerfile 标签指定，如上面的例子。如果你同时指定了 image 和 build 两个标签，那么 Compose 会构建镜像并且把镜像命名为 image 后面的那个名字。 build: ./dirimage: webapp:tag既然可以在 docker-compose.yml 中定义构建任务，那么一定少不了 arg 这个标签，就像 Dockerfile 中的 ARG 指令，它可以在构建过程中指定环境变量，但是在构建成功后取消，在 docker-compose.yml 文件中也支持这样的写法： build: context: . args: buildno: 1 password: secret下面这种写法也是支持的，一般来说下面的写法更适合阅读。 build: context: . args: - buildno=1 - password=secret与 ENV 不同的是，ARG 是允许空值的。例如： args: buildno password这样构建过程可以向它们赋值。 注意：YAML 的布尔值（true, false, yes, no, on, off）必须要使用引号引起来（单引号、双引号均可），否则会当成字符串解析。 command使用 command 可以覆盖容器启动后默认执行的命令。 command: bundle exec thin -p 3000也可以写成类似 Dockerfile 中的格式： command: [bundle, exec, thin, -p, 3000] container_name前面说过 Compose 的容器名称格式是：&lt;项目名称&gt;&lt;服务名称&gt;&lt;序号&gt;虽然可以自定义项目名称、服务名称，但是如果你想完全控制容器的命名，可以使用这个标签指定： container_name: app这样容器的名字就指定为 app 了。 depends_on在使用 Compose 时，最大的好处就是少打启动命令，但是一般项目容器启动的顺序是有要求的，如果直接从上到下启动容器，必然会因为容器依赖问题而启动失败。例如在没启动数据库容器的时候启动了应用容器，这时候应用容器会因为找不到数据库而退出，为了避免这种情况我们需要加入一个标签，就是 depends_on，这个标签解决了容器的依赖、启动先后的问题。例如下面容器会先启动 redis 和 db 两个服务，最后才启动 web 服务： version: ‘2’services: web: build: . depends_on: - db - redis redis: image: redis db: image: postgres注意的是，默认情况下使用 docker-compose up web 这样的方式启动 web 服务时，也会启动 redis 和 db 两个服务，因为在配置文件中定义了依赖关系。 dns和 –dns 参数一样用途，格式如下： dns: 8.8.8.8也可以是一个列表： dns: 8.8.8.8 9.9.9.9此外 dns_search 的配置也类似： dns_search: example.comdns_search: dc1.example.com dc2.example.comtmpfs挂载临时目录到容器内部，与 run 的参数一样效果： tmpfs: /runtmpfs: /run /tmpentrypoint在 Dockerfile 中有一个指令叫做 ENTRYPOINT 指令，用于指定接入点，第四章有对比过与 CMD 的区别。在 docker-compose.yml 中可以定义接入点，覆盖 Dockerfile 中的定义： entrypoint: /code/entrypoint.sh格式和 Docker 类似，不过还可以写成这样： entrypoint: - php - -d - zend_extension=/usr/local/lib/php/extensions/no-debug-non-zts-20100525/xdebug.so - -d - memory_limit=-1 - vendor/bin/phpunit env_file还记得前面提到的 .env 文件吧，这个文件可以设置 Compose 的变量。而在 docker-compose.yml 中可以定义一个专门存放变量的文件。如果通过 docker-compose -f FILE 指定了配置文件，则 env_file 中路径会使用配置文件路径。 如果有变量名称与 environment 指令冲突，则以后者为准。格式如下： env_file: .env或者根据 docker-compose.yml 设置多个： env_file: ./common.env ./apps/web.env /opt/secrets.env注意的是这里所说的环境变量是对宿主机的 Compose 而言的，如果在配置文件中有 build 操作，这些变量并不会进入构建过程中，如果要在构建中使用变量还是首选前面刚讲的 arg 标签。 environment与上面的 env_file 标签完全不同，反而和 arg 有几分类似，这个标签的作用是设置镜像变量，它可以保存变量到镜像里面，也就是说启动的容器也会包含这些变量设置，这是与 arg 最大的不同。一般 arg 标签的变量仅用在构建过程中。而 environment 和 Dockerfile 中的 ENV 指令一样会把变量一直保存在镜像、容器中，类似 docker run -e 的效果。 environment: RACK_ENV: development SHOW: ‘true’ SESSION_SECRET: environment: RACK_ENV=development SHOW=true SESSION_SECRETexpose这个标签与Dockerfile中的EXPOSE指令一样，用于指定暴露的端口，但是只是作为一种参考，实际上docker-compose.yml的端口映射还得ports这样的标签。 expose: “3000” “8000”external_links在使用Docker过程中，我们会有许多单独使用docker run启动的容器，为了使Compose能够连接这些不在docker-compose.yml中定义的容器，我们需要一个特殊的标签，就是external_links，它可以让Compose项目里面的容器连接到那些项目配置外部的容器（前提是外部容器中必须至少有一个容器是连接到与项目内的服务的同一个网络里面）。格式如下： external_links: redis_1 project_db_1:mysql project_db_1:postgresqlextra_hosts添加主机名的标签，就是往/etc/hosts文件中添加一些记录，与Docker client的–add-host类似： extra_hosts: “somehost:162.242.195.82” “otherhost:50.31.209.229”启动之后查看容器内部hosts： 162.242.195.82 somehost50.31.209.229 otherhost labels向容器添加元数据，和Dockerfile的LABEL指令一个意思，格式如下： labels: com.example.description: “Accounting webapp” com.example.department: “Finance” com.example.label-with-empty-value: “”labels: “com.example.description=Accounting webapp” “com.example.department=Finance” “com.example.label-with-empty-value”links还记得上面的depends_on吧，那个标签解决的是启动顺序问题，这个标签解决的是容器连接问题，与Docker client的–link一样效果，会连接到其它服务中的容器。格式如下： links: db db:database redis使用的别名将会自动在服务容器中的/etc/hosts里创建。例如： 172.12.2.186 db172.12.2.186 database172.12.2.187 redis相应的环境变量也将被创建。 logging这个标签用于配置日志服务。格式如下： logging: driver: syslog options: syslog-address: “tcp://192.168.0.42:123”默认的driver是json-file。只有json-file和journald可以通过docker-compose logs显示日志，其他方式有其他日志查看方式，但目前Compose不支持。对于可选值可以使用options指定。有关更多这方面的信息可以阅读官方文档：https://docs.docker.com/engine/admin/logging/overview/ pidpid: “host”将PID模式设置为主机PID模式，跟主机系统共享进程命名空间。容器使用这个标签将能够访问和操纵其他容器和宿主机的名称空间。 ports映射端口的标签。使用HOST:CONTAINER格式或者只是指定容器的端口，宿主机会随机映射端口。 ports: “3000” “8000:8000” “49100:22” “127.0.0.1:8001:8001”注意：当使用HOST:CONTAINER格式来映射端口时，如果你使用的容器端口小于60你可能会得到错误得结果，因为YAML将会解析xx:yy这种数字格式为60进制。所以建议采用字符串格式。 security_opt为每个容器覆盖默认的标签。简单说来就是管理全部服务的标签。比如设置全部服务的user标签值为USER。 security_opt: label:user:USER label:role:ROLEstop_signal设置另一个信号来停止容器。在默认情况下使用的是SIGTERM停止容器。设置另一个信号可以使用stop_signal标签。 stop_signal: SIGUSR1 volumes挂载一个目录或者一个已存在的数据卷容器，可以直接使用 [HOST:CONTAINER] 这样的格式，或者使用 [HOST:CONTAINER:ro] 这样的格式，后者对于容器来说，数据卷是只读的，这样可以有效保护宿主机的文件系统。Compose的数据卷指定路径可以是相对路径，使用 . 或者 .. 来指定相对目录。数据卷的格式可以是下面多种形式： volumes: // 只是指定一个路径，Docker 会自动在创建一个数据卷（这个路径是容器内部的）。 /var/lib/mysql // 使用绝对路径挂载数据卷 /opt/data:/var/lib/mysql // 以 Compose 配置文件为中心的相对路径作为数据卷挂载到容器。 ./cache:/tmp/cache // 使用用户的相对路径（~/ 表示的目录是 /home/&lt;用户目录&gt;/ 或者 /root/）。 ~/configs:/etc/configs/:ro // 已经存在的命名的数据卷。 datavolume:/var/lib/mysql如果你不使用宿主机的路径，你可以指定一个volume_driver。 volume_driver: mydriver volumes_from从其它容器或者服务挂载数据卷，可选的参数是 :ro或者 :rw，前者表示容器只读，后者表示容器对数据卷是可读可写的。默认情况下是可读可写的。 volumes_from: service_name service_name:ro container:container_name container:container_name:rwcap_add, cap_drop添加或删除容器的内核功能。详细信息在前面容器章节有讲解，此处不再赘述。 cap_add: ALL cap_drop: NET_ADMIN SYS_ADMINcgroup_parent指定一个容器的父级cgroup。 cgroup_parent: m-executor-abcd devices设备映射列表。与Docker client的–device参数类似。 devices: “/dev/ttyUSB0:/dev/ttyUSB0”extends这个标签可以扩展另一个服务，扩展内容可以是来自在当前文件，也可以是来自其他文件，相同服务的情况下，后来者会有选择地覆盖原有配置。 extends: file: common.yml service: webapp用户可以在任何地方使用这个标签，只要标签内容包含file和service两个值就可以了。file的值可以是相对或者绝对路径，如果不指定file的值，那么Compose会读取当前YML文件的信息。更多的操作细节在后面的12.3.4小节有介绍。 network_mode网络模式，与Docker client的–net参数类似，只是相对多了一个service:[service name] 的格式。例如： network_mode: “bridge”network_mode: “host”network_mode: “none”network_mode: “service:[service name]”network_mode: “container:[container name/id]”可以指定使用服务或者容器的网络。 networks加入指定网络，格式如下： services: some-service: networks: - some-network - other-network关于这个标签还有一个特别的子标签aliases，这是一个用来设置服务别名的标签，例如： services: some-service: networks: some-network: aliases: - alias1 - alias3 other-network: aliases: - alias2相同的服务可以在不同的网络有不同的别名。 其它还有这些标签：cpu_shares, cpu_quota, cpuset, domainname, hostname, ipc, mac_address, mem_limit, memswap_limit, privileged, read_only, restart, shm_size, stdin_open, tty, user, working_dir上面这些都是一个单值的标签，类似于使用docker run的效果。 cpu_shares: 73cpu_quota: 50000cpuset: 0,1 user: postgresqlworking_dir: /code domainname: foo.comhostname: fooipc: hostmac_address: 02:42:ac:11:65:43 mem_limit: 1000000000memswap_limit: 2000000000privileged: true restart: always read_only: trueshm_size: 64Mstdin_open: truetty: true","categories":[{"name":"kubernetes","slug":"kubernetes","permalink":"https://hxqxiaoqi.gitee.io/categories/kubernetes/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://hxqxiaoqi.gitee.io/tags/docker/"}],"keywords":[{"name":"kubernetes","slug":"kubernetes","permalink":"https://hxqxiaoqi.gitee.io/categories/kubernetes/"}]},{"title":"ELK部署","slug":"Elasticsearch + Logstash + filebeat + redis + Kibana","date":"2019-09-07T13:44:00.000Z","updated":"2020-07-24T04:03:47.859Z","comments":true,"path":"2019/09/07/Elasticsearch + Logstash + filebeat + redis + Kibana/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2019/09/07/Elasticsearch + Logstash + filebeat + redis + Kibana/","excerpt":"","text":"介绍ELK是Elasticsearch + Logstash + Kibana 这种架构的简写。这是一种日志分平台析的架构。从前我们用shell三剑客(grep, sed, awk)来分析日志, 虽然也能对付大多数场景，但当日志量大，分析频繁，并且使用者可能不会shell三剑客的情况下， 配置方便，使用简单，并且分析结果更加直观的工具(平台)就诞生了，它就是ELK。 ELK是开源的，并且社区活跃，用户众多。 架构说明1 Elasticsearch + Logstash + Kibana这是一种最简单的架构。这种架构，通过logstash收集日志，Elasticsearch分析日志，然后在Kibana(web界面)中展示。这种架构虽然是官网介绍里的方式，但是往往在生产中很少使用。 2 Elasticsearch + Logstash + filebeat + Kibana与上一种架构相比，这种架构增加了一个filebeat模块。filebeat是一个轻量的日志收集代理，用来部署在客户端，优势是消耗非常少的资源(较logstash)， 所以生产中，往往会采取这种架构方式，但是这种架构有一个缺点，当logstash出现故障， 会造成日志的丢失。 3 Elasticsearch + Logstash + filebeat + redis(也可以是其他中间件，比如kafka) + Kibana这种架构是上面那个架构的完善版，通过增加中间件，来避免数据的丢失。当Logstash出现故障，日志还是存在中间件中，当Logstash再次启动，则会读取中间件中积压的日志。目前我司使用的就是这种架构，我个人也比较推荐这种方式。 安装步骤安装jdk1.8elasticsearch、logstash服务都需要jdk环境 跳转 jdk安装教程 安装redis跳转 redis安装教程 安装elasticsearch跳转 elasticsearch安装教程 安装kibana1234567891011cd /data# 下载wget https://artifacts.elastic.co/downloads/kibana/kibana-6.6.1-linux-x86_64.tar.gz# 解压tar xf kibana-6.6.1-linux-x86_64.tar.gzcd kibana-6.6.1-linux-x86_64vim config/kibana.yml# 取消以下注释，并修改对应IP 12345678# 服务端口server.port: 5601# 指明服务运行的地址server.host: \"192.168.182.100\"# 指明elasticsearch运行的地址和端口elasticsearch.hosts: [\"http://192.168.182.100:9200\"]# 指明kibana使用的索引，这个是自定义的kibana.index: \".kibana\" 12# 启动，如果elasticsearch有kibana数据，则配置成功/data/kibana-6.6.1-linux-x86_64/bin/kibana 安装filebeat该组件为日志收集服务，安装在需要收集日志的服务器上 123456789# 下载wget https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-6.6.1-linux-x86_64.tar.gz# 解压tar xf filebeat-6.6.1-linux-x86_64.tar.gzcd filebeat-6.6.1-linux-x86_64vim filebeat.yml# 配置以下设置 该配置在input中定义多个日志路径，用于之后的logstash过滤，匹配不同索引 1234567891011121314151617181920filebeat.inputs:- type: log enabled: true paths: - /var/log/*.log fields: log_source: sys- type: log enabled: true paths: - /var/log/httpd/*_log fields: log_source: nginxoutput.redis: hosts: [\"192.168.182.100:6379\"] password: \"\" db: 0 key: \"syslog\" 日志输入：filebeat.inputs: 模块用来指定日志文件的来源type: 指定日志类型，在这里是log， 应该也可以是json。paths指定日志文件路径。fields: 是打标记，主要为了后面日志分析查找的方便，存储的时候也会根据fields分类存储，相同fields的数据存在同一个redis key中 日志输出output.redis：指定输出到redishosts：指定redis主机，可以指定多台。password：redis密码，redis默认没有密码，在这里设为空就行key：指定存入redis中的keydb: 指定存在redis中的db编号(redis默认安装有16个databases，0~15， 默认是存储在db0中的) 12# 启动./filebeat -e -c filebeat.yml 安装logstash1234567# 下载wget https://artifacts.elastic.co/downloads/logstash/logstash-6.6.1.tar.gztar xf logstash-6.6.1.tar.gzcd logstash-6.6.1# 创建配置文件,配置以下设置vim config/syslog.conf 该配置在output中使用fields标签匹配不同索引，从而创建俩个不同的索引给kibana使用 123456789101112131415161718192021222324252627input &#123; redis &#123; host =&gt; \"192.168.182.100\" port =&gt; 6379 data_type =&gt; \"list\" key =&gt; \"syslog\" db =&gt; 0 &#125;&#125;output &#123; if [fields][log_source] == 'sys' &#123; elasticsearch &#123; hosts =&gt; [\"http://192.168.182.100:9200\"] index =&gt; \"syslog-%&#123;+YYYY.MM.dd&#125;\" id =&gt; \"syslog_id\" &#125; &#125; if [fields][log_source] == 'nginx' &#123; elasticsearch &#123; hosts =&gt; [\"http://192.168.182.100:9200\"] index =&gt; \"nginxlog-%&#123;+YYYY.MM.dd&#125;\" id =&gt; \"nginx_id\" &#125; &#125; &#125; 1.key =&gt; “syslog” 对应filebeat.yml配置中，redis设置的key2.if [fields][log_source] == ‘sys’ 对应filebeat.yml配置中，input设置fields标签3.index =&gt; “nginxlog-%{+YYYY.MM.dd}” 创建elasticsearch索引 12# 启动./bin/logstash -f config/syslog.conf 访问kibana，并添加索引访问：IP:5601，没有密码，密码认证需要收费，可以使用nginx代理认证 创建索引： 点击 management 点击 Index Patterns 点击 Create index pattern 在当前配置页中会显示能添加的索引，如果没有显示，请查看logstash和filebeat配置 添加索引：nginxlog-* ， 该索引为elasticsearch中的索引 下一步：选择@timestamp 点击：Create index pattern 创建成功 查看日志 点击：Discover 当前页就是搜索日志页面，有切换索引，添加搜索标签，选择时间范围等功能 kibana汉化Kibana在6.7版本以上，支持了多种语言。并且自带在安装包里，之前版本需要下载中文包安装。 Kibana在6.7版本以下 123456wget https://mirrors.yangxingzhen.com/kibana/Kibana_Hanization.tar.gztar xf Kibana_Hanization.tar.gzcd Kibana_Hanization/old/python main.py /data/kibana-6.6.1-linux-x86_64 Kibana在6.7版本以上 123vim /data/kibana-6.6.1-linux-x86_64/config/kibana.yml# 取消注释i18n.locale: \"zh-CN\"","categories":[{"name":"监控","slug":"监控","permalink":"https://hxqxiaoqi.gitee.io/categories/监控/"}],"tags":[{"name":"elk","slug":"elk","permalink":"https://hxqxiaoqi.gitee.io/tags/elk/"}],"keywords":[{"name":"监控","slug":"监控","permalink":"https://hxqxiaoqi.gitee.io/categories/监控/"}]},{"title":"markdown语法","slug":"markdown语法","date":"2019-09-04T03:00:00.000Z","updated":"2020-07-24T04:08:56.326Z","comments":true,"path":"2019/09/04/markdown语法/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2019/09/04/markdown语法/","excerpt":"","text":"表头 条目一 条目二 项目 项目一 项目二 项目 项目一 项目二 标题123456# 一级标题## 二级标题### 三级标题#### 四级标题##### 五级标题###### 六级标题 强调12345*这里是斜体*_这里是斜体_**这里是加粗**__这里是加粗__ #如何给文字上色 查看颜色代码表 1&lt;font color='98F5FF'&gt;这是颜色内容&lt;/font&gt; 背景框标记段落前加“&gt;”号 这是框 背景高亮段落前加“Tab”号 这是背景高亮插入链接和图片12[点击跳转至百度](http://www.baidu.com)![图片](/images/top.png) 插入表格123表头|条目一|条目二:---:|:---:|:---:项目|项目一|项目二","categories":[{"name":"随笔","slug":"随笔","permalink":"https://hxqxiaoqi.gitee.io/categories/随笔/"}],"tags":[{"name":"markdown","slug":"markdown","permalink":"https://hxqxiaoqi.gitee.io/tags/markdown/"}],"keywords":[{"name":"随笔","slug":"随笔","permalink":"https://hxqxiaoqi.gitee.io/categories/随笔/"}]},{"title":"redis安装","slug":"redis-5.0.2安装","date":"2019-09-04T02:00:00.000Z","updated":"2020-07-24T03:49:02.531Z","comments":true,"path":"2019/09/04/redis-5.0.2安装/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2019/09/04/redis-5.0.2安装/","excerpt":"","text":"介绍REmote DIctionary Server(Redis) 是一个由Salvatore Sanfilippo写的key-value存储系统。 Redis是一个开源的使用ANSI C语言编写、遵守BSD协议、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API。 它通常被称为数据结构服务器，因为值（value）可以是 字符串(String), 哈希(Hash), 列表(list), 集合(sets) 和 有序集合(sorted sets)等类型。 安装步骤 安装环境，下载，解压，编译 修改配置 启动，登录 安装以下为一键安装脚本 12345678910111213141516171819202122232425262728293031323334#!/bin/bash# redis自动安装脚本redis_dir=/usr/localredis_version=redis-stable# 下载wget http://download.redis.io/$redis_version.tar.gzyum -y install gcctar xf $redis_version.tar.gz -C $redis_dircd $redis_dir/$redis_version# 编译make &amp;&amp; make installmkdir $redis_dir/$redis_version/&#123;data,logs&#125;# 导入配置cat &gt; redis.conf &lt;&lt;EOFdaemonize yesprotected-mode noport 6379pidfile \"$redis_dir/$redis_version/logs/redis.pid\"logfile \"$redis_dir/$redis_version/logs/redis.log\"dbfilename \"dump.rdb\"dir \"./data\"save 900 1save 300 10save 60 10000EOF# 启动$redis_dir/$redis_version/src/redis-server $redis_dir/$redis_version/redis.conf 启动，登录12345678910cd /usr/local/redis-stable# 启动./src/redis-server ./redis.conf# 关闭./src/redis-cli -p 6379 shutdown# 登录./src/redis-cli -h 127.0.0.1 -p 6379 自启动脚本将以下文件保存为redis.service，并放在：/usr/lib/systemd/system/每次更改文件必须重启：systemctl daemon-reload 123456789101112[Unit]Description=RedisAfter=network.target[Service]Restart=alwaysRestartSec=1ExecStart=/usr/local/redis-stable/src/redis-server /usr/local/redis-stable/redis.conf --daemonize noExecStop=/usr/local/redis-stable/src/redis-cli -h 127.0.0.1 -p 6379 shutdown[Install]WantedBy=multi-user.target [Unit] 表示这是基础信息Description 是描述After 是在那个服务后面启动，一般是网络服务启动后启动[Service] 表示这里是服务信息Restart=always 定义何种情况 Systemd 会自动重启当前服务，可能的值包括always（总是重启）、on-success、on-failure、on-abnormal、on-abort、on-watchdogRestartSec=1 定义 Systemd 停止当前服务之前等待的秒数ExecStart 是启动服务的命令ExecStop 是停止服务的指令[Install] 表示这是是安装相关信息WantedBy 是以哪种方式启动：multi-user.target表明当系统以多用户方式（默认的运行级别）启动时，这个服务需要被自动运行。 报错123456# 报错WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.# 解决net.core.somaxconn= 1024 #sysctl.confvm.overcommit_memory=1 #sysctl.conf","categories":[{"name":"数据库","slug":"数据库","permalink":"https://hxqxiaoqi.gitee.io/categories/数据库/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://hxqxiaoqi.gitee.io/tags/redis/"}],"keywords":[{"name":"数据库","slug":"数据库","permalink":"https://hxqxiaoqi.gitee.io/categories/数据库/"}]},{"title":"mysql-5.7.24二进制包安装","slug":"mysql-5.7.24二进制包安装","date":"2019-09-03T10:27:43.000Z","updated":"2020-07-24T06:33:56.666Z","comments":true,"path":"2019/09/03/mysql-5.7.24二进制包安装/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2019/09/03/mysql-5.7.24二进制包安装/","excerpt":"","text":"介绍MySQL 是最流行的关系型数据库管理系统，在 WEB 应用方面 MySQL 是最好的 RDBMS(Relational Database Management System：关系数据库管理系统)应用软件之一。 安装下载地址：https://dev.mysql.com/downloads/mysql/ 安装步骤： 下载解压，进入到目录中 创建数据目录，配置目录，日志目录和配置文件，修改配置文件 初始化数据库和启动数据库 配置开机自启动 常见错误 下载解压，改名12345678910wget https://dev.mysql.com/get/Downloads/MySQL-5.7/mysql-5.7.27-el7-x86_64.tartar xf mysql-5.7.24-linux-glibc2.12-x86_64.tar.gz -C /data/cd /datamv mysql-5.7.24-linux-glibc2.12-x86_64/ mysql-5.7.24# data目录：用于存放数据,logs目录：存放日志和PID文件dcd mysql-5.7.24/mkdir data logs 创建需要的目录和文件12vim /etc/my.cnf# 修改 12345678910111213141516171819202122232425# *** DO NOT EDIT THIS FILE. It's a template which will be copied to the# *** default location during install, and will be replaced if you# *** upgrade to a newer version of MySQL.[client]port = 3306default-character-set=utf8[mysqld]# 一般配置选项basedir = /data/mysql-5.7.24datadir = /data/mysql-5.7.24/datalog-error=/data/mysql-5.7.24/logs/error.logport = 3306character-set-server=utf8default_storage_engine = InnoDBbinlog-format=Rowlog-bin=/data/mysql-5.7.24/logs/binlog/binlogserver-id=1slow_query_log=ONslow_query_log_file=/data/mysql-5.7.24/logs/mysql-slow.loglong_query_time=1sql_mode=STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION 授权 12useradd -r -s /sbin/nologin mysqlchown -R mysql:mysql /data/mysql-5.7.24 初始化数据库和启动1234567891011121314cd /data/mysql-5.7.24/bin/#初始化数据库./mysqld --user=mysql --basedir=/data/mysql-5.7.24 --datadir=/data/mysql-5.7.24/data --initialize# 启动脚本cp ../support-files/mysql.server /etc/init.d/mysqldvim /etc/init.d/mysqld# 修改basedir=/data/mysql-5.7.24datadir=/data/mysql-5.7.24/data#启动service mysqld start 配置开机自启动12chkconfig mysqld onchkconfig --list mysqld 设置密码，远程登录1234567891011121314151617#默认密码cat /data/mysql-5.7.24/logs/error.log |grep root@localhost# 登录./mysql -u root -p#密码修改为 aaamysql&gt; set password=password(\"123123\");#设置远程登录权限mysql&gt; grant all privileges on *.* to 'root'@'%' identified by '123123';#刷新登录权限:mysql&gt; flush privileges;#远程登录./mysql -u root -p -P3306 -h192.168.1.23 备份和恢复备份 1234567891011121314151617# 导出数据库中所有表结构；只导出表结构, 不导出表中的数据mysqldump --opt -d 数据库名称 -u用户名 -p密码 &gt; 保存文件路径# 导出数据库中所有表中的数据；只导出表中的数据，不导出表结构mysqldump -t 数据库名称 -u用户名 -p密码 &gt; 保存文件路径# 导出数据库中所有的表结构和数据；导出表结构和数据mysqldump 数据库名称 -u用户名 -p密码 &gt; 保存文件路径# 备份单个库，并压缩mysqldump -uroot -p123123 --database xxl_job | gzip &gt; ./xxl_job.sql.gz# 导出指定表的结构和数据mysqldump -u用户名 -p密码 -B 数据库名称 --table 表名 &gt; 保存文件路径# 导出指定表数据，只导出数据，不导出表结构mysqldump -t 数据库名称 -u用户名 -p密码 --table 表名 &gt; 保存文件路径 恢复 12# 将备份文件导入到数据库mysql -u用户名 -p密码 数据库名称 &lt; 用于恢复数据库的数据文件路径 常见错误安装mysql报错 123456#报错内容bin/mysqld: error while loading shared libraries: libaio.so.1: cannot open shared object file: No such file or directory#由于缺少依赖包，通过yum安装libaio包#安装libaioyum -y install libaio 启动mysql报错 1234567891011121314#启动mysql报错内容line 647: /var/log/mariadb/mariadb.log: No such file or directory2018-04-06T16:59:36.091735Z mysqld_safe error: log-error set to '/var/log/mariadb/mariadb.log', however file don't exists. Create writable for user '2iuser'.bin/mysqld_safe: line 144: /var/log/mariadb/mariadb.log: No such file or directory#当前系统中安装了mariadb，mariadb的配置文件路径/etc/my.cnf，mysql根据配置文件无法找到相关的文件，所以报错。#查找mariadb，删除mariadb。rpm -qa | grep mariadbrpm -e mariadb-libs-5.5.56-2.el7.x86_64#在启动命令中加上--defaults-file参数指定配置文件bin/mysqld_safe \\--defaults-file=/data/mysql/conf/my.cnf \\--user=mysql &amp; 登陆mysql报错 123456789#登陆报错内容Enter password: ERROR 2002 (HY000): Can't connect to local MySQL server through socket '/tmp/mysql.sock' (2)#其中一种解决方法是在命令行里指定sock文件即可登陆，由于本机已安装mysql数据库，sock文件在/tmp/mysql.sock已存在，所以建议这种方式登录，后续再想办法优化。./mysql -u root -p -S /data/mysql/conf/mysql.sock#由于mysql是在路径/tmp/mysql.sock寻找sock文件，我们配置文件里指定的路径是/data/mysql/conf/mysql.sock，所以加上软连接即可。ln -s /data/mysql/conf/mysql.sock /tmp/mysql.sock","categories":[{"name":"数据库","slug":"数据库","permalink":"https://hxqxiaoqi.gitee.io/categories/数据库/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://hxqxiaoqi.gitee.io/tags/mysql/"}],"keywords":[{"name":"数据库","slug":"数据库","permalink":"https://hxqxiaoqi.gitee.io/categories/数据库/"}]},{"title":"zookeeper安装","slug":"zookeeper安装","date":"2019-09-03T06:00:00.000Z","updated":"2020-07-24T04:05:50.554Z","comments":true,"path":"2019/09/03/zookeeper安装/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2019/09/03/zookeeper安装/","excerpt":"","text":"介绍官方文档上这么解释zookeeper，它是一个分布式服务框架，是Apache Hadoop 的一个子项目，它主要是用来解决分布式应用中经常遇到的一些数据管理问题，如：统一命名服务、状态同步服务、集群管理、分布式应用配置项的管理等。 安装步骤 下载，解压 配置文件 配置环境变量 启动 下载，解压1234# 下载wget http://mirror.bit.edu.cn/apache/zookeeper/stable/apache-zookeeper-3.5.5-bin.tar.gztar xf apache-zookeeper-3.5.5-bin.tar.gz -C /usr/local/ 配置文件1234cd /usr/local/apache-zookeeper-3.5.5-bin/conf/# 如果只是运行，配置文件默认即可mv zoo_sample.cfg zoo.cfg 配置环境变量12345678# 配置环境变量，直接使用启动命令echo '# zookeeperexport ZK_HOME=/usr/local/apache-zookeeper-3.5.5-binexport PATH=$ZK_HOME/bin:$PATH' &gt;&gt; /etc/profilesource /etc/profile 启动123zkServer.sh startzkServer.sh stopzkServer.sh status 8080端口占用zookeeper最近的版本中有个内嵌的管理控制台是通过jetty启动，也会占用8080 端口。 123vim /data/zookeeper-3.5.5-bin/conf/zoo.cfg # 添加 admin.serverPort=8888","categories":[{"name":"中间件","slug":"中间件","permalink":"https://hxqxiaoqi.gitee.io/categories/中间件/"}],"tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"https://hxqxiaoqi.gitee.io/tags/zookeeper/"}],"keywords":[{"name":"中间件","slug":"中间件","permalink":"https://hxqxiaoqi.gitee.io/categories/中间件/"}]},{"title":"vsftp搭建","slug":"vsftp搭建","date":"2019-09-01T10:27:43.000Z","updated":"2020-07-24T04:05:39.956Z","comments":true,"path":"2019/09/01/vsftp搭建/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2019/09/01/vsftp搭建/","excerpt":"","text":"服务说明ftp是一种古老的明文传输协议，因为其明文传输的特性，也出现过很多重大的危机，进而逐渐演变为支持加密传输的VSFTP（very security FTP），而CentOS默认自带的FTP就为VSFTP。为了避免干扰，实验前请关闭Selinux和IPtables。 安装前准备：123456789101112#关闭防火墙iptables -Liptables -Fsystemctl stop firewalldsystemctl disable firewalld#永久关闭selinuxvim /etc/selinux/config #修改disable#临时关闭selinuxsetsebool -P ftpd_disable_trans 1 setenforce 0 安装步骤：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162#安装vsftp服务yum -y install vsftpd* pam* db4*#添加虚拟用户，第一行用户，第二行密码，以此类推vim /etc/vsftpd/vsftpd.user #生成虚拟账户数据表db_load -T -t hash -f vsftpd.user vsftpd.db#创建本地用户，并指定家目录useradd -d /var/ftproot -s /sbin/nologin virtual#修改校验文件，用于验证ftp虚拟用户cd /etc/pam.d/cp -a vsftpd vsftpd.pamvim vsftpd.pam添加：auth required pam_userdb.so db=/etc/vsftpd/vsftpdaccount required pam_userdb.so db=/etc/vsftpd/vsftpd#修改配置文件vim /etc/vsftpd/vsftpd.conf 修改与添加： anonymous_enable=NO local_enable=YES write_enable=YES local_umask=022 dirmessage_enable=YES xferlog_enable=YES connect_from_port_20=YES xferlog_std_format=YES listen=NO listen_ipv6=YES pam_service_name=vsftpd.pam userlist_enable=YES tcp_wrappers=YES guest_enable=YES guest_username=virtual user_config_dir=/etc/vsftpd/dir allow_writeable_chroot=YES #新版必须添加否则取消目录w权限#根据配置文件user_config_dir配置，指定虚拟账户配置文件位置，如果没有目录，需要创建mkdir /etc/vsftpd/dircd /etc/vsftpd/dir#创建虚拟用户配置文件,添加单独虚拟用户权限vim aaa #指定虚拟用户家目录 local_root=/share/aaa #允许匿名用户浏览，下载文件,默认没有这一项，只有在虚拟用户的配置文件里才有用 anon_world_readable_only=NO #允许匿名用户上传 anon_upload_enable=YES #允许匿名用户上传/建立目录 anon_mkdir_write_enable=YES #默认没有这一项,允许匿名用户具有建立目录，上传之外的权限，如重命名，删除 anon_other_write_enable=YES#本地创建虚拟用户家目录，并赋予权限mkdir -p /share/aaachown virtual.virtual /share/ -Rchmod 770 /share/ -R 添加虚拟用方法：123456#添加用户vim vsftpd.user #重新校验db_load -T -t hash -f vsftpd.user vsftpd.dbsystemctl restart vsftpd 启动与开机启动12systemctl restart vsftpdsystemctl enable vsftpd","categories":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}],"tags":[{"name":"ftp","slug":"ftp","permalink":"https://hxqxiaoqi.gitee.io/tags/ftp/"}],"keywords":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}]},{"title":"maven-3.6.1安装脚本","slug":"maven-3.6.1安装脚本","date":"2019-09-01T03:00:00.000Z","updated":"2020-07-24T04:08:43.980Z","comments":true,"path":"2019/09/01/maven-3.6.1安装脚本/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2019/09/01/maven-3.6.1安装脚本/","excerpt":"","text":"介绍Maven 翻译为”专家”、”内行”，是 Apache 下的一个纯 Java 开发的开源项目。基于项目对象模型（缩写：POM）概念，Maven利用一个中央信息片断能管理一个项目的构建、报告和文档等步骤。 Maven 是一个项目管理工具，可以对 Java 项目进行构建、依赖管理。 Maven 也可被用于构建和管理各种项目，例如 C#，Ruby，Scala 和其他语言编写的项目。Maven 曾是 Jakarta 项目的子项目，现为由 Apache 软件基金会主持的独立 Apache 项目。 安装脚本事先安装号jdk1.8环境 1234567891011wget http://mirror.bit.edu.cn/apache/maven/maven-3/3.6.1/binaries/apache-maven-3.6.1-bin.tar.gztar xf apache-maven-3.6.1-bin.tar.gz -C /usr/local/#mavenecho \"export MAVEN_HOME=/usr/local/apache-maven-3.6.1export PATH=\\$&#123;PATH&#125;:\\$&#123;MAVEN_HOME&#125;/bin\" &gt;&gt; /etc/profile source /etc/profile 更换仓库镜像站12# 配置文件vim /usr/local/apache-maven-3.6.1/conf/settings.xml 1234567&lt;!-- 阿里云站点 --&gt;&lt;mirror&gt; &lt;id&gt;alimaven&lt;/id&gt; &lt;name&gt;aliyun maven&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;/mirror&gt; java源码编译测试123456789# 下载zk源码git clone https://gitee.com/Outsrkem/zkweb.git# 编译cd zkwebmvn clean package# 安装包位置zkweb/target/zkWeb-v1.2.1.war","categories":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}],"tags":[{"name":"maven","slug":"maven","permalink":"https://hxqxiaoqi.gitee.io/tags/maven/"}],"keywords":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}]},{"title":"solr安装","slug":"solr7.2.1安装","date":"2019-08-11T10:00:00.000Z","updated":"2020-07-24T04:06:10.798Z","comments":true,"path":"2019/08/11/solr7.2.1安装/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2019/08/11/solr7.2.1安装/","excerpt":"","text":"介绍Solr是一个独立的企业级搜索应用服务器，它对外提供类似于Web-service的API接口。用户可以通过http请求，向搜索引擎服务器提交一定格式的XML文件，生成索引；也可以通过Http Get操作提出查找请求，并得到XML格式的返回结果。 Solr是一个高性能，采用Java开发，基于Lucene的全文搜索服务器。同时对其进行了扩展，提供了比Lucene更为丰富的查询语言，同时实现了可配置、可扩展并对查询性能进行了优化，并且提供了一个完善的功能管理界面，是一款非常优秀的全文搜索引擎。 安装步骤Solr的安装必须先 安装JDK，这个的安装这里不再赘述，下面将要介绍的是solr的安装流程。 下载tomcat和solr，并解压 复制solr文件到tomcat 启动并访问solr 创建核心 下载并配置中文分词 下载tomcat和solr，并解压1234567891011# 安装目录cd /data# 下载wget http://mirror.bit.edu.cn/apache/tomcat/tomcat-8/v8.5.45/bin/apache-tomcat-8.5.45.tar.gzwget http://archive.apache.org/dist/lucene/solr/7.1.0/solr-7.1.0.tgztar xf apache-tomcat-8.5.45.tar.gzmv apache-tomcat-8.5.45 tomcat-solrtar xf solr-7.1.0.tgz 复制solr文件到tomcat123456789101112131415161718192021222324cd /datacp -a solr-7.1.0/server/solr-webapp/webapp tomcat-solr/webapps/solrcp -a solr-7.1.0/server/lib/ext/* tomcat-solr/webapps/solr/WEB_INF/libcp -a solr-7.1.0/server/lib/metrics* tomcat-solr/webapps/solr/WEB_INF/libcp -a solr-7.1.0/dist/solr-dataimporthandler* tomcat-solr/webapps/solr/WEB_INF/libcd tomcat-solr/webapps/solr/WEB-INF/mkdir classescd classescp -a solr-7.1.0/server/resources/log4j.properties .cd /datamkdir solrhomecp -a solr-7.1.0/server/solr/* solrhomecp -a solr-7.1.0/dist/ solrhome/cp -a solr-7.1.0/contrib/ solrhome/vim tomcat-solr/webapps/solr/WEB_INF/web.xml # 在web-app节点下添加，然后把security-constraint相关的都注释掉 &lt;env-entry&gt; &lt;env-entry-name&gt;solr/home&lt;/env-entry-name&gt; &lt;env-entry-value&gt;/data/solrhome&lt;/env-entry-value&gt; &lt;env-entry-type&gt;java.lang.String&lt;/env-entry-type&gt; &lt;/env-entry&gt; 启动并访问solr12345# 启动/data/tomcat-solr/bin/startup.sh# 访问Ip:8080/solr/index.html 创建核心1234567891011121314151617181920212223242526cd /data/solrhomemkdir -p testCore/confcd testCore/confcp -a /data/solr-7.1.0/server/solr/configsets/_default/conf/* .vim solrconfig.xml# 添加以下配置，并把原来的&lt;lib dir= 也改为当前路径&lt;lib dir=\"/data/solrhome/contrib/extraction/lib\" regex=\".*\\.jar\" /&gt; &lt;lib dir=\"/data/solrhome/dist/\" regex=\"solr-cell-\\d.*\\.jar\" /&gt; &lt;lib dir=\"/data/solrhome/contrib/clustering/lib/\" regex=\".*\\.jar\" /&gt; &lt;lib dir=\"/data/solrhome/dist/\" regex=\"solr-clustering-\\d.*\\.jar\" /&gt; &lt;lib dir=\"/data/solrhome/contrib/langid/lib/\" regex=\".*\\.jar\" /&gt; &lt;lib dir=\"/data/solrhome/dist/\" regex=\"solr-langid-\\d.*\\.jar\" /&gt; &lt;lib dir=\"/data/solrhome/contrib/velocity/lib\" regex=\".*\\.jar\" /&gt;&lt;lib dir=\"/data/solrhome/dist/\" regex=\"solr-velocity-\\d.*\\.jar\" /&gt;cd /data/solrhome/testCoremkdir datavim core.properties# 写入以下内容name=testCoreconfig=conf/solrconfig.xmlschema=conf/managed-schemadataDir=data 完成以上步骤重启tomcat就可以了 分词器安装1234567891011121314151617181920# github地址https://github.com/magese/ik-analyzer-solr/tree/v7.5.0# 下载wget https://search.maven.org/remotecontent?filepath=com/github/magese/ik-analyzer/7.5.0/ik-analyzer-7.5.0.jarcp -a ik-analyzer-7.5.0.jar tomcat-solr/webapps/solr/WEB-INF/libvim solrhome/testCore/conf/managed-schema# 添加以下配置&lt;fieldType name=\"text_ik\" class=\"solr.TextField\" positionIncrementGap=\"100\"&gt; &lt;analyzer type=\"index\"&gt; &lt;tokenizer class=\"org.wltea.analyzer.lucene.IKTokenizerFactory\" useSmart=\"true\" /&gt; &lt;/analyzer&gt; &lt;analyzer type=\"query\"&gt; &lt;tokenizer class=\"org.wltea.analyzer.lucene.IKTokenizerFactory\" useSmart=\"true\" /&gt; &lt;/analyzer&gt; &lt;/fieldType&gt; &lt;field name=\"text_ik\" type=\"text_ik\" indexed=\"true\" stored=\"true\" multiValued=\"false\" /&gt; 配置完成后，重启tomcat就可以使用分词功能了","categories":[{"name":"中间件","slug":"中间件","permalink":"https://hxqxiaoqi.gitee.io/categories/中间件/"}],"tags":[{"name":"solr","slug":"solr","permalink":"https://hxqxiaoqi.gitee.io/tags/solr/"}],"keywords":[{"name":"中间件","slug":"中间件","permalink":"https://hxqxiaoqi.gitee.io/categories/中间件/"}]},{"title":"elasticsearch安装","slug":"elasticsearch-6.6.1安装","date":"2019-08-08T03:00:00.000Z","updated":"2020-07-24T03:59:35.927Z","comments":true,"path":"2019/08/08/elasticsearch-6.6.1安装/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2019/08/08/elasticsearch-6.6.1安装/","excerpt":"","text":"介绍Elasticsearch 是一个分布式可扩展的实时搜索和分析引擎,一个建立在全文搜索引擎 Apache Lucene(TM) 基础上的搜索引擎.当然 Elasticsearch 并不仅仅是 Lucene 那么简单，它不仅包括了全文搜索功能，还可以进行以下工作: 1.分布式实时文件存储，并将每一个字段都编入索引，使其可以被搜索。2.实时分析的分布式搜索引擎。3.可以扩展到上百台服务器，处理PB级别的结构化或非结构化数据。 安装步骤先安装：jdk1.8 1.下载，解压2.修改linux内核，设置资源参数3.修改配置4.启动elasticsearch、自启动脚本5.安装中文分词 下载，解压123456789101112# 下载wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.6.1.tar.gzcd /datatar xf elasticsearch-6.6.1.tar.gz# 创建用户，需要以普通用户启动useradd elk# 创建目录，用于存放数据和日志cd /data/elasticsearch-6.6.1mkdir data logs 修改linux内核，设置资源参数123456789101112131415# 修改内核参数 cat &gt;&gt; /etc/sysctl.conf &lt;&lt; EOFvm.max_map_count=655360 EOFsysctl -p# 修改服务器资源参数cat &gt;&gt; /etc/security/limits.conf &lt;&lt; EOF * soft nofile 655350 * hard nofile 655350 EOFcat &gt;&gt; /etc/security/limits.d/20-nproc.conf &lt;&lt; EOF elk soft nproc 65536EOF 修改配置1234cd /data/elasticsearch-6.6.1vim config/elasticsearch.yml # 修改，取消以下配置注释 123456#数据目录path.data: /data/elasticsearch-6.6.1/data path.logs: /data/elasticsearch-6.6.1/logs#允许哪个IP访问,0代表所有network.host: 0.0.0.0 http.port: 9200 12# 附权限chown -R elk:elk elasticsearch-6.6.1 启动elasticsearch12345su elkcd /data/elasticsearch-6.6.1# 加-d：后台启动./bin/elasticsearch 启动脚本 12345#!/bin/bashsu - elk&lt;&lt;!/data/elasticsearch-6.6.1/bin/elasticsearch -dexit! root启动命令 12# 内存最好指定为服务器的一半su - elk -l -c \"cd /data/elasticsearch-6.6.1/bin/ &amp;&amp; export JAVA_HOME=/opt/jdk1.8.0_221 &amp;&amp; export ES_JAVA_OPTS='-Xms10g -Xmx10g' &amp;&amp; ./elasticsearch -d\" 安装中文分词1234567891011# 下载wget https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v6.6.1/elasticsearch-analysis-ik-6.6.1.zip# 创建ik目录mkdir /data/elasticsearch-6.6.1/plugins/ikmv elasticsearch-analysis-ik-6.6.1.zip elasticsearch-6.6.1/plugins/ikcd /data/elasticsearch-6.6.1/plugins/ikunzip elasticsearch-analysis-ik-6.6.1.zip docker部署elasticsearch部署 1docker run -d --name elasticsearch -p 9200:9200 -p 9300:9300 -e \"discovery.type=single-node\" elasticsearch:6.4.0 kibana部署 1docker run -p 5601:5601 --name kibana -e \"elasticsearch.hosts=http://localhost:9200\" -d kibana:6.4.0","categories":[{"name":"数据库","slug":"数据库","permalink":"https://hxqxiaoqi.gitee.io/categories/数据库/"}],"tags":[{"name":"es","slug":"es","permalink":"https://hxqxiaoqi.gitee.io/tags/es/"}],"keywords":[{"name":"数据库","slug":"数据库","permalink":"https://hxqxiaoqi.gitee.io/categories/数据库/"}]},{"title":"prometheus+grafana监控部署","slug":"prometheus监控部署","date":"2019-08-04T03:00:00.000Z","updated":"2020-07-24T04:07:07.268Z","comments":true,"path":"2019/08/04/prometheus监控部署/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2019/08/04/prometheus监控部署/","excerpt":"","text":"介绍Prometheus是一个开源监控系统，它前身是SoundCloud的警告工具包。从2012年开始，许多公司和组织开始使用Prometheus。该项目的开发人员和用户社区非常活跃，越来越多的开发人员和用户参与到该项目中。目前它是一个独立的开源项目，且不依赖与任何公司。为了强调这点和明确该项目治理结构，Prometheus在2016年继Kurberntes之后，加入了Cloud Native Computing Foundation。 安装步骤监控机安装：192.168.1.24 安装prometheus，监控服务 安装node-exporter，节点数据收集服务 安装alertmanager，报警服务 安装grafana，图形化展示服务 一、监控机安装prometheus1、安装命令1234567891011121314# 下载wget https://github.com/prometheus/prometheus/releases/download/v2.12.0/prometheus-2.12.0.linux-amd64.tar.gztar xf prometheus-2.12.0.linux-amd64.tar.gzcd prometheus-2.12.0.linux-amd64# 根据下面yml配置文件配置需要信息vim prometheus.yml# 启动nohup ./prometheus --config.file=./prometheus.yml &amp;# 访问prometheushttp://192.168.1.24:9090 2、配置修改：vim prometheus.yml123456789101112131415161718192021global: # 每隔15秒向pushgateway采集一次指标数据 scrape_interval: 15s # 每隔15秒根据所配置的规则集，进行规则计算 evaluation_interval: 15s alerting: alertmanagers: - static_configs: # 设置altermanager的地址，altermanager报警规则服务 - targets: ['192.168.1.24:9093'] # 指定所配置报价模板文件，下面给出模板配置rule_files: - \"rules.yml\"scrape_configs: # 用于获取被控主机数据，可以添加多条 - job_name: '测试-25' static_configs: - targets: ['192.168.1.25:9100'] 3、rules.yml报警模板配置1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556groups:- name: down rules: - alert: \"down报警\" expr: up == 0 for: 1m labels: severity: warning annotations: summary: \"down报警\" description: \"报警时间:\" value: \"已使用：&#123;&#123; $value &#125;&#125;\"- name: memory rules: - alert: \"内存报警\" expr: ((node_memory_MemTotal_bytes -(node_memory_MemFree_bytes+node_memory_Buffers_bytes+node_memory_Cached_bytes) )/node_memory_MemTotal_bytes ) * 100 &gt; 90 for: 1m labels: severity: warning annotations: summary: \"内存报警\" description: \"报警时间:\" value: \"已使用：&#123;&#123; $value &#125;&#125;%\"- name: cpu rules: - alert: \"cpu报警\" expr: 100 - ((avg by (instance,job,env)(irate(node_cpu_seconds_total&#123;mode=\"idle\"&#125;[30s]))) *100) &gt; 90 for: 1m labels: severity: warning annotations: summary: \"cpu报警\" description: \"报警时间:\" value: \"已使用：&#123;&#123; $value &#125;&#125;%\"- name: disk rules: - alert: \"disk报警\" expr: 100 - (node_filesystem_avail_bytes&#123;fstype !~ \"nfs|rpc_pipefs|rootfs|tmpfs\",device!~\"/etc/auto.misc|/dev/mapper/centos-home\",mountpoint !~ \"/boot|/net|/selinux\"&#125; /node_filesystem_size_bytes&#123;fstype !~ \"nfs|rpc_pipefs|rootfs|tmpfs\",device!~\"/etc/auto.misc|/dev/mapper/centos-home\",mountpoint !~ \"/boot|/net|/selinux\"&#125; ) * 100 &gt; 80 for: 1m labels: severity: warning annotations: summary: \"disk报警\" description: \"报警时间:\" value: \"已使用：&#123;&#123; $value &#125;&#125;%\"- name: net rules: - alert: \"net报警\" expr: (irate(node_network_transmit_bytes_total&#123;device!~\"lo\"&#125;[1m]) / 1000) &gt; 80000 for: 1m labels: severity: warning annotations: summary: \"net报警\" description: \"报警时间:\" value: \"已使用：&#123;&#123; $value &#125;&#125;KB\" 二、监控机安装node-exporter1234567891011# 下载wget https://github.com/prometheus/node_exporter/releases/download/v0.18.1/node_exporter-0.18.1.linux-amd64.tar.gztar xf node_exporter-0.18.1.linux-amd64.tar.gzcd node_exporter-0.18.1.linux-amd64# 启动nohup ./node_exporter &amp;# 访问http://192.168.1.24:9100 三、监控机安装alertmanager1、安装命令1234567891011121314# 下载wget https://github.com/prometheus/alertmanager/releases/download/v0.19.0/alertmanager-0.19.0.linux-amd64.tar.gztar xf alertmanager-0.19.0.linux-amd64.tar.gzcd alertmanager-0.19.0.linux-amd64# 修改配置，下面给出配置信息vim alertmanager.yml# 启动nohup ./alertmanager --config.file=./alertmanager.yml &amp;# 访问http://192.168.1.24:9093 2、alertmanager.yml报警规则配置以下是邮箱报警配置： 12345678910111213141516171819202122232425262728293031323334global: #处理超时时间，默认为5min resolve_timeout: 5m # 邮箱smtp服务器代理 smtp_smarthost: 'smtp.163.com:25' # 发送邮箱名称 smtp_from: 'hxqxiaoqi1990@163.com' # 邮箱名称 smtp_auth_username: 'hxqxiaoqi1990@163.com' # 邮箱密码或授权码 smtp_auth_password: 'Hxq7996026' smtp_require_tls: falseroute: # 报警分组依据 group_by: ['alertname'] # 最初即第一次等待多久时间发送一组警报的通知 group_wait: 10s # 在发送新警报前的等待时间 group_interval: 1h # 发送重复警报的周期 对于email配置中，此项不可以设置过低，否则将会由于邮件发送太多频繁，被smtp服务器拒绝 repeat_interval: 1h # 发送警报的接收者的名称，以下receivers name的名称 receiver: 'mail' receivers:- name: 'mail' email_configs: - to: 'hxqxiaoqi1990@163.com'inhibit_rules: - source_match: severity: 'critical' target_match: severity: 'warning' equal: ['alertname', 'dev', 'instance'] 四、监控机安装grafana1、安装命令12345678910wget https://dl.grafana.com/oss/release/grafana-6.3.5.linux-amd64.tar.gz tar xf grafana-6.3.5.linux-amd64.tar.gz cd grafana-6.3.5.linux-amd64# 启动nohup ./alertmanager --config.file=./alertmanager.yml &amp;# 访问http://192.168.1.24:3000 2、添加数据源1.在设置中：Configuration–&gt;Date Sources2.配置prometheus服务信息：http://192.168.1.24:9090 3、添加仪表盘1.在创建中：Create–&gt;Import2.去下载：https://grafana.com/grafana/dashboards 或复制模板ID号3.填写ID号，或上传仪表盘模板","categories":[{"name":"监控","slug":"监控","permalink":"https://hxqxiaoqi.gitee.io/categories/监控/"}],"tags":[{"name":"prometheus","slug":"prometheus","permalink":"https://hxqxiaoqi.gitee.io/tags/prometheus/"}],"keywords":[{"name":"监控","slug":"监控","permalink":"https://hxqxiaoqi.gitee.io/categories/监控/"}]},{"title":"局域网DNS搭建与使用","slug":"局域网DNS搭建与使用","date":"2019-08-01T08:57:55.000Z","updated":"2020-07-24T03:42:16.057Z","comments":true,"path":"2019/08/01/局域网DNS搭建与使用/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2019/08/01/局域网DNS搭建与使用/","excerpt":"","text":"介绍1984年，加州大学伯克利分校的几个学生完成了Unix名称服务的实现，起名叫Berkeley Internet Name Domain（BIND）。目前，它是互联网上使用最为广泛的DNS服务软件 工作原理（1）客户机首先查看查找本地hosts文件，如果有则返回，否则进行下一步（2）客户机查看本地缓存，是否存在本条目的缓存，如果有则直接返回，不再向外发出请求，否则进行下一步，转发。（3）将请求转发本地DNS服务器。（4）查看域名是否本地解析，是则本地解析返回，否则进行下一步。（5）本地DNS服务器首先在缓存中查找，有则返回，无则进行下一步。（6）向全球13个根域服务器发起DNS请求，根域返回org域的地址列表。（7）使用某一个org域的IP地址，发起DNS请求，org域返回kernel域服务器地址列表。（8）使用某一个kernel域IP地址，发起DNS请求，kernel域返回www.kernel.org 主机的IP地址，本地DNS服务收到后，返回给客户机。 注： 递归查询：压力在服务器端 迭代查询：压力在客户端(直接返回结果到客户机) 搭建DNS准备环境： DNS服务器：192.168.40.100 客户机：192.168.40.101 搭建步骤： 安装dns服务bind 修改主配置文件 修改区域配置文件 创建数据配置文件 重启bind服务 修改访问域名的主机dns为DNS服务器ip 测试 安装dns服务binddns服务包名为bind，安装后的服务名为named 1yum -y install bind 修改主配置文件/etc/named.conf：主配置文件用配置于DNS服务器的访问参数 12345678910111213141516vim /etc/named.confoptions &#123; #设置监听的端口和IP listen-on port 53 &#123; 192.168.40.100; &#125;; listen-on-v6 port 53 &#123; ::1; &#125;; directory \"/var/named\"; dump-file \"/var/named/data/cache_dump.db\"; statistics-file \"/var/named/data/named_stats.txt\"; memstatistics-file \"/var/named/data/named_mem_stats.txt\"; recursing-file \"/var/named/data/named.recursing\"; secroots-file \"/var/named/data/named.secroots\"; #允许那些IP访问 allow-query &#123; any; &#125;; 修改区域配置文件/etc/named.rfc1912.zones：区域配置文件用于指定域名名称、配置文件名称 1234567891011vim /etc/named.rfc1912.zones#填写域名zone \"12366xuetang.com\" IN &#123; type master; #填写数据配置文件名 file \"12366xuetang.front\"; allow-update &#123; none; &#125;;&#125;; 创建数据配置文件数据配置文件：根据区域配置文件指定的名称创建，并配置域名解析 1234567891011121314151617181920#到dns数据目录下cd /var/named/#创建数据文件cp -a named.localhost 12366xuetang.front#打开数据配置文件vim 12366xuetang.front#配置举例，域名后面的“.”别忘记$TTL 1D@ IN SOA 12366xuetang.com. rname.invalid. ( 0 ; serial 1D ; refresh 1H ; retry 1W ; expire 3H ) ; minimum NS js.12366xuetang.com.js A 192.168.40.100zj A 192.168.40.101 重启bind服务如果报错：请仔细查看数据配置文件设置 1systemctl restart named 修改访问域名的主机dns为DNS服务器ip注：所有使用域名访问的客户机都需要配置DNS服务器IP 12345678910vim /etc/sysconfig/network-scripts/ifcfg-ens33TYPE=EthernetBOOTPROTO=staticNAME=ens33DEVICE=ens33ONBOOT=yesIPADDR=192.168.40.100NETMASK=255.255.255.0GATEWAY=192.168.40.2DNS1=192.168.40.100 测试123456789101112#安装nslookup工具yum -y install bind-utils#访问域名nslookup zj.12366xuetang.com#显示Address为数据配置文件解析的ip则成功Server: 192.168.40.100Address: 192.168.40.100#53Name: zj.12366xuetang.comAddress: 192.168.40.101","categories":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}],"tags":[{"name":"DNS","slug":"DNS","permalink":"https://hxqxiaoqi.gitee.io/tags/DNS/"}],"keywords":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}]},{"title":"go-fastdfs部署","slug":"go-fastdfs部署","date":"2019-07-31T02:27:43.000Z","updated":"2020-07-24T04:00:35.976Z","comments":true,"path":"2019/07/31/go-fastdfs部署/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2019/07/31/go-fastdfs部署/","excerpt":"","text":"go-fastdfs介绍go-fastdfs是一个基于http协议的分布式文件系统，它基于大道至简的设计理念，一切从简设计，使得它的运维及扩展变得更加简单，它具有高性能、高可靠、无中心、免维护等优点。 下载地址：https://github.com/sjqzhang/go-fastdfs/releases 部署单点部署linux安装，下载已经编译的文件fileserver，执行以下命令： 123#赋予执行权限并运行，会在当前目录生成配置文件chmod +x fileserver./fileserver &amp; 访问：服务器IP:8080下载：上传时会返回文件地址，使用wget或curl即可下载 集群部署注意，go-fastdfs不能在同一台上部署集群以单点部署方式部署其它服务器修改conf/cfg.json，例： 12345678910&#123;\"PeerID\": \"集群内唯一,请使用0-9的单字符，默认自动生成\",\"peer_id\": \"1\",\"本主机地址\": \"本机http地址,默认自动生成(注意端口必须与addr中的端口一致），必段为内网，自动生成不为内网请自行修改，下同\",\"host\": \"http://192.168.40.100:8080\",\"集群\": \"集群列表,注意为了高可用，IP必须不能是同一个,同一不会自动备份，且不能为127.0.0.1,且必须为内网IP，默认自动生成\",\"peers\": [\"http://192.168.40.100:8080\",\"http://192.168.40.101:8080\",\"http://192.168.40.102:8080\"],&#125; 访问任意服务器的go-fastdfs服务，上传文件，其它服务器自动备份 备份数据打包整个目录即可 web后台管理部署下载地址：https://github.com/perfree/go-fastdfs-web/releases1.安装jdk环境2.上传服务器，解压3.启动：./goFastDfsWeb.sh start4.访问：服务器IP:80885.注册用户","categories":[{"name":"中间件","slug":"中间件","permalink":"https://hxqxiaoqi.gitee.io/categories/中间件/"}],"tags":[{"name":"go-fastdfs","slug":"go-fastdfs","permalink":"https://hxqxiaoqi.gitee.io/tags/go-fastdfs/"}],"keywords":[{"name":"中间件","slug":"中间件","permalink":"https://hxqxiaoqi.gitee.io/categories/中间件/"}]},{"title":"jenkins部署与备份","slug":"jenkins部署与备份","date":"2019-07-30T06:27:43.000Z","updated":"2020-07-24T03:43:37.747Z","comments":true,"path":"2019/07/30/jenkins部署与备份/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2019/07/30/jenkins部署与备份/","excerpt":"","text":"jenkins介绍Jenkins只是一个平台，真正运作的都是插件，它是一个自动化部署工具，通过插件完成拉起源代码、编译、发布等功能。 下载地址：http://mirrors.jenkins.io/war-stable/latest/jenkins.war jenkins部署部署jenkins之前需要安装jdk环境，请按照：jdk环境部署 操作安装jdk。 部署方式一1.下载的Jenkins.war包上传到服务器2.服务器上执行以下命令： 12345678#前台运行java -jar jenkins.war#后台运行nohup java -jar jenkins.war &amp;&gt; ./jen.log &amp;#获取Jenkins密码，访问时需要cat /root/.jenkins/secrets/initialAdminPassword 3.访问：localhost:8080，输入密码4.选择默认模式5.设置登录账号密码 部署方式二1.安装tomcat2.下载的Jenkins.war包上传到tomcat目录下的webapps目录下3.运行tomcat4.访问：localhost:8080/jenkins jenkins工作目录说明第一次启动jenkins时，会在用户家目录下自动生成 .jenkins 的隐藏工作目录。 .jenkins：config.xml： jenkins 的核心配置文件jobs： 构建作业的配置细节，及构建产物和数据workspace： jenkins 对当前作业进行构建的地方builds： 包含当前作业的构建历史config.xml： 存放当前作业的所有配置细节nextBuildNumber： 下一次构建的 numberlastStable： 最后一个稳定构建的链接（成功的构建）lastSuccessful： 最近成功的构建链接（没有任何编译错误）plugins： 存放所有已安装的插件，更新 jenkins 不需要重新安装插件users： 当使用 jenkins 本地用户数据库时，用户信息会存放在这个目录下updates： 存放可用的插件更新userContent： 存放用户自己为 jenkins 服务器定制化的一些内容war： 存放扩展的 web 应用程序，当以单机应用程序的形式运，jenkins 时，会把 web 应用程序解压到这个目录。 更改工作目录1234567891011#默认jenkins主目录在/root/.jenkinscp -a /root/.jenkins /home/.jenkins#添加profilevim /etc/profile #jenkins JENKINS_HOME=\"/home/.jenkins\" export JENKINS_HOME #重新加载profilesource /etc/profile jenkins备份与恢复1.登录Jenkins–&gt;选择系统管理–&gt;选择插件管理–&gt;选择可选插件2.搜索ThinBackup插件，安装3.安装成功后，在系统管理中出现ThinBackup选项，点击ThinBackup 设置说明：Backup Now：立即备份，需要设置备份路径，之后在服务器上创建该目录Restore：恢复，按时间选择备份文件Settings：备份设置，设置备份路径，定时备份时间，备份方式等 jenkins配置项目这里以java项目举例说明：配置java项目需要安装插件：Publish Over SSH 、 Maven Release Plug-in和Git 1.登录jenkins，点击新建视图2.输入项目名，选择简单视图，保存3.在该项目下点击新建任务，输入任务名称，选择构建maven项目，选择ok4.选择源码管理的类型，我这边选择git，输入git地址和账号密码5.在Build栏目，添加pom配置路径 1234567例1：pom在当前目录 ./pom.xml clean install package 例2：pom在二级目录 ytb-manager-server/pom.xml clean install -pl ../ytb-manager-server -am 6.在Post Steps点击 Add post-build step，选择send files or execute commands over SSH7.ssh配置举例： 1234567891011121314151617name：选择jar包传输的服务器，需要在系统设置中先添加ssh主机#生成jar包位置Source files：ytb-manager-server/target/*.jar#移除Source files路径Remove prefix：ytb-manager-server/target/#jar上传到服务的目录Remote directory：/home/opt/ytb#服务器执行的脚本Exec command： #!/bin/bash cd /home/opt/ytb/manager-server sh ./stop.sh sh ./start.sh 8.保存配置，之后点击立即构建即可查看是否成功。 遇到的问题安装插件失败因为国内防火墙的问题，有时候无法获取到Jenkins的插件，或下载失败1.更换插件源地址2.https://updates.jenkins.io/update-center.json 更换为 http://mirror.xmission.com/jenkins/updates/update-center.json3.或更换为https://updates.jenkins.io/update-center.json4.点击提交5.点击立即获取","categories":[{"name":"中间件","slug":"中间件","permalink":"https://hxqxiaoqi.gitee.io/categories/中间件/"}],"tags":[{"name":"jenkins","slug":"jenkins","permalink":"https://hxqxiaoqi.gitee.io/tags/jenkins/"}],"keywords":[{"name":"中间件","slug":"中间件","permalink":"https://hxqxiaoqi.gitee.io/categories/中间件/"}]},{"title":"Node.js安装与npm编译前端","slug":"Node.js安装与npm编译前端","date":"2019-07-25T10:27:43.000Z","updated":"2020-07-24T04:07:41.469Z","comments":true,"path":"2019/07/25/Node.js安装与npm编译前端/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2019/07/25/Node.js安装与npm编译前端/","excerpt":"","text":"Node.js 介绍简单的说 Node.js 就是运行在服务端的 JavaScript。Node.js 是一个基于Chrome JavaScript 运行时建立的一个平台。Node.js是一个事件驱动I/O服务端JavaScript环境，基于Google的V8引擎，V8引擎执行Javascript的速度非常快，性能非常好。 NPM 使用介绍NPM是随同NodeJS一起安装的包管理工具，能解决NodeJS代码部署上的很多问题，常见的使用场景有以下几种： 允许用户从NPM服务器下载别人编写的第三方包到本地使用。 允许用户从NPM服务器下载并安装别人编写的命令行程序到本地使用。 允许用户将自己编写的包或命令行程序上传到NPM服务器供别人使用。 linux安装Node.js1234567891011121314151617#下载wget https://npm.taobao.org/mirrors/node/v10.16.0/node-v10.16.0-linux-x64.tar.gz#解压tar xf node-v10.16.0-linux-x64.tar.gzcd node-v10.16.0-linux-x64/bin/#设置软链接，需要绝对路径ln -s /root/node-v10.16.0-linux-x64/bin/node /usr/bin/ln -s /root/node-v10.16.0-linux-x64/bin/npm /usr/bin/#查看版本node -vv10.16.0 npm -v #安装成功6.9.0 NPM安装淘宝镜像大家都知道国内直接使用 npm 的官方镜像是非常慢的，这里推荐使用淘宝 NPM 镜像。 12345678#安装npm install cnpm -g --registry=https://registry.npm.taobao.org#软链接ln -s /root/node-v10.16.0-linux-x64/bin/cnpm /usr/bin/#查看版本cnpm -v NPM全局安装与本地安装npm 的包安装分为本地安装（local）、全局安装（global）两种，从敲的命令行来看，差别只是有没有-g而已。 本地安装： 将安装包放在 ./node_modules 下（运行 npm 命令时所在的目录），如果没有 node_modules 目录，会在当前执行 npm 命令的目录下生成 node_modules 目录。 全局安装： 将安装包放在 /usr/local 下或者你 node 的安装目录。 12npm install express # 本地安装npm install express -g # 全局安装 NPM编译前端源码包以下以web为源码包举例： 12345678#使用本地安装，cd到源码包目录下cd web#安装源码包依赖cnpm install#打包，会在web目录中生成build的包，这个就是可以发布的前端包cnpm run build NPM常用命令安装模块以下都是本地安装，全局安装加参数-gnpm install 查看安装模块信息npm list 卸载模块npm uninstall express 更新模块npm update express 搜索模块npm search express 创建模块生成 package.json 文件npm init 在 npm 资源库中注册用户npm adduser 发布模块npm publish","categories":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}],"tags":[{"name":"node","slug":"node","permalink":"https://hxqxiaoqi.gitee.io/tags/node/"}],"keywords":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}]},{"title":"定时查询elk错误日志并报警","slug":"定时查询elk错误日志并报警","date":"2019-07-09T10:27:43.000Z","updated":"2020-07-24T06:45:02.003Z","comments":true,"path":"2019/07/09/定时查询elk错误日志并报警/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2019/07/09/定时查询elk错误日志并报警/","excerpt":"","text":"1234567891011121314151617181920#!/bin/bash# 安装邮件工具if [ ! -e \"/tmp/sendEmail-v1.56/sendEmail\" ];then cd /tmp &amp;&amp; wget http://caspian.dotconf.net/menu/Software/SendEmail/sendEmail-v1.56.tar.gz &amp;&amp; tar xf sendEmail-v1.56.tar.gz &amp;&amp; chmod +x /tmp/sendEmail-v1.56/sendEmailfi# 获取elasticsearch指定索引，指向条件，指定时间的错误data=`curl -s -H \"Content-Type:application/json\" -XPOST http://172.16.190.240:9200/err-dockerlogs-*/_search -d '&#123;\"query\": &#123;\"bool\": &#123;\"must\": [&#123;\"bool\": &#123;\"should\": [&#123;\"match_phrase\": &#123;\"message\": \"Cause: java.sql.SQLSyntaxErrorException:\"&#125;&#125;,&#123;\"match_phrase\": &#123;\"message\": \"### Error updating database\"&#125;&#125;,&#123;\"match_phrase\": &#123;\"message\": \"### Cause: java.sql\"&#125;&#125;,&#123;\"match_phrase\": &#123;\"message\": \"message:### SQL\"&#125;&#125;,&#123;\"match_phrase\": &#123;\"message\": \"SQLException\"&#125;&#125;]&#125;&#125;,&#123;\"range\": &#123;\"@timestamp\": &#123;\"gte\": \"now-5m/m\",\"lte\": \"now/m\",\"format\": \"epoch_millis\"&#125;&#125;&#125;]&#125;&#125;,\"from\": 0,\"size\": 5&#125;'`# 转为可读json格式jqdata=`echo $data|jq .`# 获取错误总数num=`echo $data|cut -d \":\" -f 10|cut -d \",\" -f 1`# 发送邮件报警if [ \"$num\" -gt \"0\" ];then echo $num /tmp/sendEmail-v1.56/sendEmail -o message-charset=\"utf-8\" -f 111@111.com -t 222@222.com -s smtp.111.com -u \"elk-sql-err\" -xu 111@111.com -xp 1111.1234 -m \"$jqdata\" -o tls=nofi","categories":[{"name":"脚本","slug":"脚本","permalink":"https://hxqxiaoqi.gitee.io/categories/脚本/"}],"tags":[{"name":"shell脚本","slug":"shell脚本","permalink":"https://hxqxiaoqi.gitee.io/tags/shell脚本/"}],"keywords":[{"name":"脚本","slug":"脚本","permalink":"https://hxqxiaoqi.gitee.io/categories/脚本/"}]},{"title":"监控大数据集群并钉钉报警","slug":"监控大数据集群并钉钉报警","date":"2019-07-07T09:27:43.000Z","updated":"2020-07-24T06:53:45.081Z","comments":true,"path":"2019/07/07/监控大数据集群并钉钉报警/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2019/07/07/监控大数据集群并钉钉报警/","excerpt":"","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172#!/bin/bash#个人测试：https://oapi.dingtalk.com/robot/send?access_token=da26636c287511a04ea3e57fdfd860439b2644ae50d0dee18311ab9c1c5a669b#集群监控脚本webhook='https://oapi.dingtalk.com/robot/send?access_token=da26636c287511a04ea3e57fdfd860439b2644ae50d0dee18311ab9c1c5a669b'cluster='hadoop'progressnameold01=\"HMasterResourceManagerKafkaHRegionServerProdServerStartCanalAdminApplicationDataNodeStandaloneSessionClusterEntrypointNameNodeJournalNodeQuorumPeerMainDFSZKFailoverControllerCanalLauncherNodeManager\"progressnameold02=\"CanalLauncherQuorumPeerMainNameNodeNodeManagerJournalNodeDFSZKFailoverControllerHRegionServerStandaloneSessionClusterEntrypointDataNodeHMasterKafka\"progressnameold03=\"QuorumPeerMainHRegionServerKafkaDataNodeCanalLauncherNodeManager\"progressname01=`/opt/jdk1.8.0_221/bin/jps|egrep -v \"(TaskManagerRunner)|(Jps)\"|cut -d \" \" -f2`progressname02=`ssh root@hadoop02 \"/opt/jdk1.8.0_221/bin/jps|egrep -v '(TaskManagerRunner)|(Jps)'|cut -d ' ' -f2\"`progressname03=`ssh root@hadoop03 \"/opt/jdk1.8.0_221/bin/jps|egrep -v '(TaskManagerRunner)|(Jps)'|cut -d ' ' -f2\"`progressNum01=`/opt/jdk1.8.0_221/bin/jps|egrep -v \"(TaskManagerRunner)|(Jps)\"|wc -l`progressNum02=`ssh root@hadoop02 \"/opt/jdk1.8.0_221/bin/jps|egrep -v '(TaskManagerRunner)|(Jps)'|wc -l\"`progressNum03=`ssh root@hadoop03 \"/opt/jdk1.8.0_221/bin/jps|egrep -v '(TaskManagerRunner)|(Jps)'|wc -l\"`function SendMsgToDingding() &#123; curl $webhook -H 'Content-Type: application/json' -d \" &#123; 'msgtype': 'text', 'text': &#123; 'content': '集群名称：$cluster\\n告警信息：$1节点$2进程丢失\\n' &#125;, 'at': &#123; 'isAtAll': true &#125; &#125;\"&#125;progressNum()&#123; if [ \"$3\" -gt \"$2\" ];then echo \"$4\" &gt; /tmp/file1 echo \"$5\" &gt; /tmp/file2 # 比较上面指定的进程，差集 node=`sort -m &lt;(sort /tmp/file1 | uniq) &lt;(sort /tmp/file2 | uniq) &lt;(sort /tmp/file2 | uniq) | uniq -u` SendMsgToDingding $1 $node fi&#125;progressNum hadoop01 $progressNum01 14 \"$progressnameold01\" \"$progressname01\"progressNum hadoop02 $progressNum02 11 \"$progressnameold02\" \"$progressname02\"progressNum hadoop03 $progressNum03 6 \"$progressnameold03\" \"$progressname03\"","categories":[{"name":"脚本","slug":"脚本","permalink":"https://hxqxiaoqi.gitee.io/categories/脚本/"}],"tags":[{"name":"shell脚本","slug":"shell脚本","permalink":"https://hxqxiaoqi.gitee.io/tags/shell脚本/"}],"keywords":[{"name":"脚本","slug":"脚本","permalink":"https://hxqxiaoqi.gitee.io/categories/脚本/"}]},{"title":"dockerfile基本使用","slug":"dockerfile基本使用","date":"2019-06-14T10:27:43.000Z","updated":"2020-07-24T03:51:11.911Z","comments":true,"path":"2019/06/14/dockerfile基本使用/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2019/06/14/dockerfile基本使用/","excerpt":"","text":"dockerfile作用dockerfile 是由一系列命令和参数构成的脚本，这些命令应用于基础镜像并最终创建一个新的镜像。它们简化了从头到尾的流程并极大的简化了部署工作。Dockerfile从FROM命令开始，紧接着跟随者各种方法，命令和参数。其产出为一个新的可以用于创建容器的镜像。 简单来说，dockerfile就是用来快速定制和生成自己的镜像。 dockerfile基本语法FROM指定基础镜像所谓定制镜像，那一定是以一个镜像为基础，在其上进行定制。而 FROM 就是指定基础镜像，因此一个 Dockerfile 中 FROM 是必备的指令，并且必须是第一条指令。 除了选择现有镜像为基础镜像外，Docker 还存在一个特殊的镜像，名为 scratch 。这个镜像是虚拟的概念，并不实际存在，它表示一个空白的镜像。 FROM scratch 如果你以 scratch 为基础镜像的话，意味着你不以任何镜像为基础，接下来所写的指令将作为镜像第一层开始存在。 不以任何系统为基础，直接将可执行文件复制进镜像的做法并不罕见，比如 swarm 、 coreos/etcd 。对于 Linux 下静态编译的程序来说，并不需要有操作系统提供运行时支持，所需的一切库都已经在可执行文件里了，因此直接 FROM scratch 会让镜像体积更加小巧。使用 Go 语言 开发的应用很多会使用这种方式来制作镜像，这也是为什么有人认为 Go是特别适合容器微服务架构的语言的原因之一。 RUNRUN 指令是用来执行命令行命令的。由于命令行的强大能力， RUN 指令在定制镜像时是最常用的指令之一。 在指令格式上，一般推荐使用 exec 格式，这类格式在解析时会被解析为 JSON 数组，因此一定要使用双引号 “ ，而不要使用单引号。 其格式有两种：shell 格式： 1RUN echo '&lt;h1&gt;Hello, Docker!&lt;/h1&gt;' &gt; /usr/share/nginx/html/index.html exec 格式： 1RUN [\"可执行文件\", \"参数1\", \"参数2\"] 注意：Dockerfile 中每一个指令都会建立一层，最大限制为127层，有些类似的指令可以使用&amp;&amp;连接，减少层数。 COPY复制文件 格式： 123COPY &lt;源路径&gt; &lt;目标路径&gt;COPY [\"&lt;源路径1&gt;\",\"&lt;目标路径&gt;\"] 注意： 源路径不能使用绝对路径 复制到容器的文件和状态会被保留 支持通配符 ADD更高级的复制文件 格式与copy一致 如果 &lt;源路径&gt; 为一个 tar 压缩文件的话，压缩格式为 gzip , bzip2 以及 xz 的情况下， ADD 指令将会自动解压缩这个压缩文件到 &lt;目标路径&gt; 去。另外需要注意的是， ADD 指令会令镜像构建缓存失效，从而可能会令镜像构建变得比较缓慢。 CMD容器启动命令 CMD 指令的格式和 RUN 相似。 Docker 不是虚拟机，容器中的应用都应该以前台执行，而不是像虚拟机、物理机里面那样，容器内没有后台服务的概念，所有容器必须有一个前台进程，否则无法启动容器。 ENTRYPOINT入口点 ENTRYPOINT 的格式和 RUN 指令格式一样。 ENTRYPOINT 的目的和 CMD 一样，都是在指定容器启动程序及参数，一个dockerfile中只能有一个ENTRYPOINT 层。 CMD可以指定参数传递到ENTRYPOINT，例： 1234FROM alpine:3.4 ... RUN addgroup -S redis &amp;&amp; adduser -S -G redis redis ... ENTRYPOINT [\"docker-entrypoint.sh\"] EXPOSE 6379 CMD [ \"redis-server\" ] 1234567#!/bin/sh ... #allow the container to be started with `--user` if [ \"$1\" = 'redis-server' -a \"$(id -u)\" = '0' ]; then chown -R redis . exec su-exec redis \"$0\" \"$@\" fi exec \"$@\" 该脚本的内容就是根据 CMD 的内容来判断，如果是 redis-server的话，则切换到 redis 用户身份启动服务器，否则依旧使用 root 身份执行。 ENV设置环境变量 格式有两种： 12ENV &lt;key&gt; &lt;value&gt;ENV &lt;key1&gt;=&lt;value1&gt; &lt;key2&gt;=&lt;value2&gt;... 下列指令可以支持环境变量：ADD 、 COPY 、 ENV 、 EXPOSE 、 LABEL 、 USER 、 WORKDIR 、 VOLUME 、 STOPSIGNAL 、 ONBUILD 。 ARG构建参数 1ARG &lt;参数名&gt;[=&lt;默认值&gt;] Dockerfile 中的 ARG 指令是定义参数名称，以及定义其默认值。该默认值可以在构建命令 docker build 中用 –build-arg &lt;参数名&gt;=&lt;值&gt; 来覆盖。 在 1.13 之前的版本，要求 –build-arg 中的参数名，必须在 Dockerfile 中用 ARG 定义过了，换句话说，就是 –build-arg 指定的参数，必须在 Dockerfile 中使用了。如果对应参数没有被使用，则会报错退出构建。从 1.13 开始，这种严格的限制被放开，不再报错退出，而是显示警告信息，并继续构建。这对于使用 CI 系统，用同样的构建流程构建不同的 Dockerfile 的时候比较有帮助，避免构建命令必须根据每个 Dockerfile 的内容修改。 VOLUME定义匿名卷 12VOLUME [\"&lt;路径1&gt;\", \"&lt;路径2&gt;\"...]VOLUME &lt;路径&gt; 容器运行时应该尽量保持容器存储层不发生写操作，对于数据库类需要保存动态数据的应用，其数据库文件应该保存于卷(volume)中。为了防止运行时用户忘记将动态文件所保存目录挂载为卷，在 Dockerfile 中，我们可以事先指定某些目录挂载为匿名卷，这样在运行时如果用户不指定挂载，其应用也可以正常运行，不会向容器存储层写入大量数据。 1VOLUME /data 这里的 /data 目录就会在运行时自动挂载为匿名卷，任何向 /data 中写入的信息都不会记录进容器存储层，从而保证了容器存储层的无状态化。当然，运行时可以覆盖这个挂载设置。比如： 1docker run -d -v mydata:/data xxxx 在这行命令中，就使用了 mydata 这个命名卷挂载到了 /data 这个位置，替代了 Dockerfile 中定义的匿名卷的挂载配置。 EXPOSE声明端口 1EXPOSE &lt;端口1&gt; &lt;端口2&gt; EXPOSE 指令是声明运行时容器提供服务端口，这只是一个声明，在运行时并不会因为这个声明应用就会开启这个端口的服务。在 Dockerfile 中写入这样的声明有两个好处，一个是帮助镜像使用者理解这个镜像服务的守护端口，以方便配置映射；另一个用处则是在运行时使用随机端口映射时，也就是 docker run -P 时，会自动随机映射 EXPOSE 的端口。 要将 EXPOSE 和在运行时使用 -p &lt;宿主端口&gt;:&lt;容器端口&gt; 区分开来。 -p ，是映射宿主端口和容器端口，换句话说，就是将容器的对应端口服务公开给外界访问，而 EXPOSE 仅仅是声明容器打算使用什么端口而已，并不会自动在宿主进行端口映射。 WORKDIR指定工作目录 1WORKDIR &lt;工作目录路径&gt; 使用 WORKDIR 指令可以来指定工作目录（或者称为当前目录），以后各层的当前目录就被改为指定的目录，如该目录不存在， WORKDIR 会帮你建立目录。 USER指定当前用户 1USER &lt;用户名&gt; USER 指令和 WORKDIR 相似，都是改变环境状态并影响以后的层。 WORKDIR 是改变工作目录， USER 则是改变之后层的执行 RUN , CMD 以及 ENTRYPOINT 这类命令的身份。当然，和 WORKDIR 一样， USER 只是帮助你切换到指定用户而已，这个用户必须是事先建立好的，否则无法切换。 HEALTHCHECK健康检查 1HEALTHCHECK [选项] CMD &lt;命令&gt; ：设置检查容器健康状况的命令 当在一个镜像指定了 HEALTHCHECK 指令后，用其启动容器，初始状态会为 starting ，在 HEALTHCHECK 指令检查成功后变为 healthy ，如果连续一定次数失败，则会变为 unhealthy 。 HEALTHCHECK 支持下列选项： interval=&lt;间隔&gt; ：两次健康检查的间隔，默认为 30 秒； timeout=&lt;时长&gt; ：健康检查命令运行超时时间，如果超过这个时间，本次健康检查就被视为失败，默认 30 秒； retries=&lt;次数&gt; ：当连续失败指定次数后，则将容器状态视为 unhealthy ，默认 3 次。 和 CMD , ENTRYPOINT 一样， HEALTHCHECK 只可以出现一次，如果写了多个，只有最后一个生效。 例： 1234FROM nginxRUN apt-get update &amp;&amp; apt-get install -y curl &amp;&amp; rm -rf /var/lib/apt/lists/*HEALTHCHECK --interval=5s --timeout=3s \\ CMD curl -fs http://localhost/ || exit 1 使用 curl -fs http://localhost/ || exit 1作为健康检查命令。当运行该镜像后，可以通过 docker container ls HEALTHCHECK有三种状态： starting：当运行该镜像后的最初状态 healthy：容器运行稳定后的健康状态 unhealthy：健康检查连续失败超过了重试次数 为了帮助排障，健康检查命令的输出（包括 stdout 以及 stderr ）都会被存储于健康状态里，可以用 docker inspect 来查看。","categories":[{"name":"kubernetes","slug":"kubernetes","permalink":"https://hxqxiaoqi.gitee.io/categories/kubernetes/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://hxqxiaoqi.gitee.io/tags/docker/"}],"keywords":[{"name":"kubernetes","slug":"kubernetes","permalink":"https://hxqxiaoqi.gitee.io/categories/kubernetes/"}]},{"title":"docker基本使用","slug":"docker基本使用","date":"2019-06-12T07:27:43.000Z","updated":"2020-07-24T03:51:15.341Z","comments":true,"path":"2019/06/12/docker基本使用/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2019/06/12/docker基本使用/","excerpt":"","text":"docker是什么docker是一个开源的应用容器引擎，开发者可以打包自己的应用到容器里面，然后迁移到其他机器的docker应用中，可以实现快速部署。如果出现的故障，可以通过镜像，快速恢复服务。 docker是利用Linux内核虚拟机化技术（LXC），提供轻量级的虚拟化，以便隔离进程和资源。LXC不是硬件的虚拟化，而是Linux内核的级别的虚拟机化，相对于传统的虚拟机，节省了很多硬件资源。 NameSpace LXC是利用内核namespace技术，进行进程隔离。其中pid, net, ipc, mnt, uts 等namespace将container的进程, 网络, 消息, 文件系统和hostname 隔离开。 Control Group LXC利用的宿主机共享的资源，虽然用namespace进行隔离，但是资源使用没有收到限制，这里就需要用到Control Group技术，对资源使用进行限制，设定优先级，资源控制等。 docker安装安装软件源：阿里云镜像 1234yum install -y yum-utils device-mapper-persistent-data lvm2yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repoyum makecache fastyum -y install docker-ce 镜像加速1234567mkdir -p /etc/dockertee /etc/docker/daemon.json &lt;&lt;-'EOF'&#123; \"registry-mirrors\": [\"https://pthx0mbz.mirror.aliyuncs.com\"]&#125;EOF 启动12systemctl start dockersystemctl enable docker 删除12yum remove docker-cerm -rf /var/lib/docker docker常用命令12345678910111213141516171819202122232425262728293031323334353637383940414243444546docker info#显示守护进程的系统资源docker search imageID#Docker仓库的查询,用户名/镜像名:版本，最好选官方的docker pull imageID#Docker仓库的下载docker images#Docker镜像的查询docker rmi imageID/镜像名:版本#Docker 镜像的删除，-f强制删除docker ps -a#正在运行容器的查询，-a查询所有容器docker run --restart always -v /data/:/var/log/ -v /etc/localtime:/etc/localtime -v /etc/timezone:/etc/timezone -p 服务器端口:容器端口 --name 定义容器名 -d 指定images:tag#--restart always在容器自启动#-v /data/:/var/log/是持久化目录#-v /etc/localtime:/etc/localtime -v /etc/timezone:/etc/timezone 持久化容器时间，如果没有timezone文件，执行echo 'Asia/Shanghai' &gt;/etc/timezone#更新启动命令，在容器创建时没使用的参数docker update --restart=always xxxdocker exec -it 容器名 bash#进入容器中docker start/stop 容器别名/ID#容器启动停止docker rm -f 容器名#强制删除容器docker rm -f `docker ps -a -q`#删除所有容器docker rmi -f#强制删除镜像docker save -o rocketmq.tar rocketmq #-o：指定保存的镜像的名字；rocketmq.tar：保存到本地的镜像名称；rocketmq：镜像名字docker load --input rocketmq.tar#导入镜像 docker网络模式docker network ls #查看当前可用的网络类型–net=网络类型 #创建容器时指定 –net=bridge 这个是默认值，连接到默认的网桥，容器IP自动生成，相互可以访问，共用一个docker0网桥。 –net=host 告诉 Docker 不要将容器网络放到隔离的名字空间中，即不要容器化容器内的网络。此时容器使用本地主机的网络，它拥有完全的本地主机接口访问权限。容器进程可以跟主机其 它 root 进程一样可以打开低范围的端口，可以访问本地网络服务比如 D-bus，还可以让容器做一些影响整个主机系统的事情，比如重启主机。因此使用这个选项的时候要非常小心。如果进一步的使用 –privileged=true，容器会被允许直接配置主机的网络堆栈。 –net=container:NAME_or_ID 让 Docker 将新建容器的进程放到一个已存在容器的网络栈中，新容器进程有自己的文件系统、进程列表和资源限制，但会和已存在的容器共享 IP 地址和端口等网络资源，两者进程可以直接通过 lo 环回接口通信。 –net=none 让 Docker 将新容器放到隔离的网络栈中，但是不进行网络配置。之后，用户可以自己进行配置。","categories":[{"name":"kubernetes","slug":"kubernetes","permalink":"https://hxqxiaoqi.gitee.io/categories/kubernetes/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://hxqxiaoqi.gitee.io/tags/docker/"}],"keywords":[{"name":"kubernetes","slug":"kubernetes","permalink":"https://hxqxiaoqi.gitee.io/categories/kubernetes/"}]},{"title":"linux常用命令","slug":"常用命令","date":"2019-06-09T10:27:43.000Z","updated":"2020-07-24T03:38:27.829Z","comments":true,"path":"2019/06/09/常用命令/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2019/06/09/常用命令/","excerpt":"","text":"命令大全 ls 显示目录文件 选项： -d 显示当前目录 -i 显示inode号 -h 常见单位显示 -a 显示所有文件包括隐藏文件 cd 切换目录（shell内置命令）cd - 进入上一次目录 cd ~ 进入家目录 cd .. 进入上级目录 pwd 显示当前路径 mkdir 建立目录例：mkdir -p /huang/xiao/qi 递归建立 rm 删除文件 选项：-r递归，删除目录 -f强制 例：rm -rf 文件和目录 tree 显示目录下所有目录树（要安装的命令） touch 创建新文件或修改文件时间 cat 查看文件内容 选项：-n显示行号 例：cat -n 文件名 more 分页显示文件内容空格键：下翻 n键：上翻 q键：退出 less 分行显示文件内容空格键或pgdn：下翻 pgup键：上翻 q键：退出 head 显示文件头，默认10行选项：-n 指定显示文件头几行 tail 显示文件后几行，默认10行选项：-n 指定显示文件头几行 -f 监听文件尾部 cp 复制文件（如果复制链接文件，则复制原文件）选项：-r 复制目录（包括目录内文件数据） -p 连带文件属性复制 -d 若源文件是链接文件，则复制链接属性 -a 相当于-rpd 例：cp -pdr 源文件位置 目的位置 mv 剪切或改名例：mv 源文件 目的文件位置 type 区分命令类型例：type 命令 ln 生成链接文件（硬链接）选项：-s 生成软链接 例：ln -s 源文件 目的文件 chmod 修改权限例：chmod 775 文件或目录 选项：-R 递归设置，将设置到该目录上的权限递归设置到该目录下的所有子文件上 chown 修改所有者例：chown 用户:用户组 文件或目录名 （同时修改所有者和所属组） 选项：-R 递归设置，将设置到该目录上的所有者递归设置到该目录下的所有子文件上 chgrp 修改所属组例：chgrp 所属组 文件名或目录 umask 查看文件和目录默认权限 man 查看命令帮助例： man -f 命令 选项：-f 查看命令等级0-9 命令等级 help 查看内部命令帮助例：help 内部命令 –help 查看常用命令选项帮助例：命令 --help 命令 --version 查看命令作者 info查看帮助页例：info 命令 选项：n进入下一小节 p进入上一小节 q退出 enter确认 which查找存储命令路径与alias别名例：which 命令 whereis查找存储命令路径与man帮助存储位置例：whereis 命令 whatis 查询命令帮助等级例：whereis 命令 locate按文件名查找系统中的文件（包含匹配，在系统数据库中查找）例：locate 文件名 配置文件：/etc/updatedb.conf 配合命令：updatedb强制更新数据库/var/lib/mlocate/mlocatedb位置 find 查询符合条件的文件名（完全匹配，可用通配符）例：find 查找位置 选项 文件名 选项：-name 按文件名查找 -iname 不区分大小写 -size 按文件大小查找 -type 按文件类型查找（f：文件d：目录l：链接） -ctime 按权限修改时间查找，如+4，-4，4天 -mtime按数据修改时间查找 -atime 按访问时间查找 -nouser按没有属主的文件查找 -user 按用户名查找 -group 按用户组查找 -uid 按用户ID查找 -gid 按属组组ID查找 -inum 按i节点查找 -perm 按权限查找，如775 -exec {} \\；管道符作用 grep 查找符合条件的字符串，文件中查找数据，包含匹配例：grep “字符串” 文件名 选项：-i 不区分大小写 -v 反向 -c 统计符合条件的行数 -A 数字 #列出符合条件的行，并连续列出后面n行 -B 数字 #列出符合条件的行，并连续列出前面n行 --colour=auto 查找字符显示红色 “|” 管道符，命令1的结果作为命令2的条件例：ls -l | grep “^-” netstat 查看系统网络状态例：netstat -tuln 选项：-t 显示tcp -u 显示udp -l 监听 -n 显示IP和端口 tar 打包压缩命令例：tar -zcvf 压缩文件名 源文件 选项：-z：gz格式 -j：bz2格式 -c：解压 -x：压缩 -t：显示压缩文件不解压 -C：解压到指定位置 tar -zxvf 123.tar.gz 123/aaa -C /root/ 解压其中一个文件 w 查看当前在线用户（显示用户登入时间，在线持续时间，1,5,15分钟前的cpu负载，来源IP） who查看当前在线用户（在线持续时间，来源IP） last 列出登入相关信息（显示用户开始登入时间，退出登入时间，在线时间，系统重启时间）文件位置：/var/run/wtmp lastlog显示账户最后一次登入时间文件位置：/var/run/utmp write 给在线用户写信息 wall对所有在线用户说话 mail邮件命令例：mail 用户名 （写信ctrl+d:保存退出） 选项：1 2 查看对于邮件 h列出邮件标题 q退出 邮件保存位置：/var/spool/mail/root ping网络探测选项：-c 指定次数 -s 指定数据包大小 ifconfig查看网卡配置例：ifconfig etho0 配置临时生效网卡 netstat查看网络状态例：netstat -tuln 选项：-t tcp -u udp -l listen -n 显示IP和端口 配置文件：/etc/services telnet 测试端口连通性例：telnet IP 端口 sync数据同步，强制把内存数据保存到硬盘 shutdown关机重启命令例：shutdown -r now重启（可以指定时间，建议使用） shutdown -h now关机 mount挂载命令（直接执行可以查看已经挂载的挂载点）例：mount [-t iso9660] /dev/sr0 挂载点 选项：-t 文件系统 光盘iso9660 U盘fat:16或vfat：32 -L 卷标名 挂载指定卷标的分区 -o 特殊选项 可以指定挂载的额外选项 常用挂载 挂载光盘 例：mount 【-t iso9660】 /dev/sr0 /mnt/cdrom 卸载挂载 例：umount /mnt/cdrom 指定字符编码挂载 例：mount -o iocharset=utf8 /dev/sr0 /mnt/cdrom/ 挂载特殊指定项 mount -o remount,exec 挂载点（remount针对已挂载） 挂载本地镜像 mount -o loop 镜像文件 挂载点 查看分硬盘区 例：fdisk -l 显示当前系统字符编码 例：echo $LANG 修改字符编码 例： $LANG=zh_CN.UTF-8 $LANG=en_US.UTF-8 强制把内存数据保存到硬盘中（建议重启前使用） 例：sync 重启命令（建议使用） 例：shutdown -r now 或指定时间 05:30 umount 卸载挂载点例：umount 挂载点或设备文件名 rpm二进制包安装命令例：rpm -ivh 包全名 选项：-i：安装 -v：显示更详细信息 -h：显示安装进度 -q：查询包是否安装 -a：查询所有安装包 -qi：查询安装包的信息 -qip：查询未安装包的信息 -ql：查询包中，文件的安装位置 -qf：查询系统文件属于哪个安装包 -qR：查询软件包所依赖的软件包 -qRp：查询没有安装的软件包的依赖包 -e：卸载 -V：检验安装包有没有修改过 -U：升级安装包，如果没有安装，就安装 -F：升级安装包，如果没有安装，就不安装 --force：强制安装，用于文件丢失 --import：用于导入数字证书，安装包在 date修改时间命令例：date -s 20180613或15:12:11 选项：-s：指定时间 lrzsz安装包，用于xshell上传或下载文件的例：先安装lrzsz安装包， 选项：rz：下载 sz：上传 dos2unix和Unix2dos安装包，需要安装，用于Windows和Linux系统之间的文件转换例：dos2unix 文件名 或 unix2dos 文件名 yum在线安装例：yum -y install 包名 选项：install安装 remove卸载 update升级（如果不指定包名，就全部软件升级，小心使用） list查看yum源所有可以安装的rpm包，可以指定包名 search查看yum源中所有与关键字相关的包 info查看包的信息 grouplist查看所有软件组 groupinstall安装指定组包 groupinfo查看组包中的软件 groupremove卸载组包 LANG查看系统当前语言例：LANG=zh_CN.UTF-8 选项：echo $LANG 查看当前使用语言 uname -r 查看系统内核版本 du 统计目录大小（统计文件大小是准确的）例：du -sh 目录 选项：-h 人性化显示 -s 和 -a 显示每个子文件磁盘占用量 df 查看分区大小（查看硬盘剩余空间是准确的）例：df -h 选项：-h 人性化显示 -a 显示所有文件系统 -T 显示挂着的文件系统类型 diff 生成补丁例：diff -Naur 旧文件 新文件 &gt; 补丁文件 patch导入补丁命令例：patch -pn &lt; 补丁名 （-n：数字 -p：取消路径等级） 防火墙关闭例：iptables -F （临时生效，清空防火墙配置） service iptables stop（永久生效，停止防火墙服务） chkconfig iptables off（永久生效，防火墙服务开机不启动） useradd添加用户例：useradd 选项 参数 用户名 选项： -u：UID -g：指定初始组 -d：指定家目录，目录不需要事先创建 -s：指定登录shell -G：指定附加组 -r：创建系统用户，默认密码失效，没有家目录，与-s一起使用，指定shell为/sbin/nologin passwd修改密码例：passwd 选项 用户 选项： -l：锁定用户密码 -u：解锁用户密码 -U：查看密码状态 usermod用户信息修改例：usermod 选项 用户名 usermod -m -d /home/已更改名 用户名 选项： -u：修改UID -g：修改初始组 -d：修改家目录与-m一起使用 -L：锁定密码 -U：解锁密码 -G：修改附加组 -l 新用户名 旧用户名 修改用户名 -s：修改登录的shell userdel删除用户例：userdel 选项 用户名 选项：-r：连家目录一起删除 groupadd增加组例：groupadd 组名 groupdel删除组例：groupdel 组名（尽量空组） gpasswd向组内添加成员例：gpasswd 选项 用户名 组名 选项：-a：指定一个用户添加到组 -d：删除组内成员 -M：批量添加组成员 echo $?（上次命令是否执行成功，0表示成功，非0表示错误） id显示用户的UID，初始组，附加组例：id 用户名 su切换用户例：su 用户名 例：su - 用户名 连带环境变量一起切换 newgrp切换有效组例：newgrp 组 dumpe2fs查看ACL权限例：dumpe2fs 分区 | grep acl setfacl设置ACL权限例：setfacl -m u:用户名:权限 文件名（添加ACL权限rwx） setfacl -x u:用户 文件名（删除ACL权限） setfacl -b 文件名（清空ACL权限，包括mask） setfacl -m u:权限（设置mask权限） setfacl -R -m u:用户名:权限 文件名（递归设置） setfacl -d -m u:用户名:权限 文件名（默认权限设置） getfacl查看文件权限例：getfacl 文件名或目录 chattr 文件属性设置例：chattr +i 文件或目录 选项：i：对文件，不允许任何操作修改 对目录，那么只能修改目录下文件的数据 a：对文件，那么只能在文件中增加数据 对目录，那么只允许在目录中建立和修改文件 e：表示该文件是使用ext文件系统进行存储的，而且不能使用“chattr -e”命令取消e属性 lsattr 查看文件属性例：lsattr -a 文件名 选项：-a 显示所有 -d 如果目标是目录，仅显示目录本身77．fsck文件系统修复命令例：fsck -y 分区名 dumpe2fs 显示磁盘状态例：dumpe2fs -h 分区名 #卷标，挂载点，UUID，挂载参数，文件系统状态，inode总量/空闲，block总量/空闲，单个block大小 stat显示文件详细信息例：stat 文件名 #文件名，文件大小，占用的block的大小，所在设备编号，硬链接数，属组，属主，权限，访问时间，数据修改时间，状态时间 file判断文件类型例：file 文件名 type判断命令是否是内部或外部命令例：tpye 命令 fdisk分区命令MBR例：fdisk -l 查看磁盘分区 选项：fdisk 进入分区交互模式 -m 操作菜单 -n 新建分区 -p 查看分区 -d 删除分区 -q 退出不保存 -w 退出保持 -t 修改分区属性（可以更改swap分区用） -L 查看分区属性 partprobe强制读取所有分区例：若分区报错，可使用此命令，若没安装，parted-2*安装包 mkfs格式化分区例：mkfs -t ext4 分区名 mkfs -t ext4 -b4096 -i4096 分区 mkfs.ext4 分区 parted分区命令GPT例：parted 分区 #进入交互模式 选项：p 打印分区表 mklabel 更改分区表类型gpt/msdos mkpart 创建分区 rm 删除分区 q 退出（修改实时生效） swap分区命令例：1.fdisk分区 更改分区属性为swap 3.mkswap 格式化分区 4.swapon 开启swap分区 free查看swap分区状态 quota磁盘配额相关命令选项：quotacheck -avgu 生产磁盘配额文件 -a #扫描所有磁盘 -v #显示扫描过程 -c #清楚原有文件重新生成行动文件 -g #生成组文件 -u #生成用户文件 edquota -u 用户名 #指定用户限制设置 -g 组名 #指定组限制设置 -t #用户宽限天数设置 -T #组宽限天数设置 -p #复制设置 quota -uvs #查看此用户在所有磁盘的配额 quota -hvs #查看此组在所有磁盘的配额 repquota -ugvs 分区 #查看该分区的所有配额设置 quotaon -guav 分区 #开启指定分区磁盘配额设置 quotaoff -guav 分区 #关闭指定分区磁盘配额设置 dd用指定大小的块拷贝一个文件if=指定源文件 of=指定目的文件 bs=bytes：同时设置读入/输出的块大小为bytes个字节 count=blocks：仅拷贝blocks个块，块大小等于ibs指定的字节 dd应用实例 将本地的/dev/hdb整盘备份到/dev/hdddd if=/dev/hdb of=/dev/hdd 将/dev/hdb全盘数据备份到指定路径的image文件dd if=/dev/hdb of=/root/image 将备份文件恢复到指定盘dd if=/root/image of=/dev/hdb 备份/dev/hdb全盘数据，并利用gzip工具进行压缩，保存到指定路径dd if=/dev/hdb | gzip &gt; /root/image.gz 将压缩的备份文件恢复到指定盘gzip -dc /root/image.gz | dd of=/dev/hdb 备份与恢复MBRa.备份磁盘开始的512个字节大小的MBR信息到指定文件： dd if=/dev/hda of=/root/image count=1 bs=512 count=1指仅拷贝一个块；bs=512指块大小为512个字节。 b.恢复： dd if=/root/image of=/dev/had 将备份的MBR信息写到磁盘开始部分 拷贝内存内容到硬盘dd if=/dev/mem of=/root/mem.bin bs=1024 (指定块大小为1k) 拷贝光盘内容到指定文件夹，并保存为cd.iso文件dd if=/dev/cdrom(sr0) of=/root/cd.iso 增加swap分区文件大小第一步：创建一个大小为256M的文件： dd if=/dev/zero of=/swapfile bs=1024 count=262144 第二步：把这个文件变成swap文件： mkswap /swapfile 第三步：启用这个swap文件： swapon /swapfile 第四步：编辑/etc/fstab文件，使在每次开机时自动加载swap文件： /swapfile swap swap default 0 0 销毁磁盘数据dd if=/dev/urandom of=/dev/hda1 注意：利用随机的数据填充硬盘，在某些必要的场合可以用来销毁数据。 测试硬盘的读写速度dd if=/dev/zero bs=1024 count=1000000 of=/root/1Gb.file dd if=/root/1Gb.file bs=64k | dd of=/dev/null 确定硬盘的最佳块大小：dd if=/dev/zero bs=1024 count=1000000 of=/root/1Gb.file dd if=/dev/zero bs=2048 count=500000 of=/root/1Gb.file dd if=/dev/zero bs=4096 count=250000 of=/root/1Gb.file dd if=/dev/zero bs=8192 count=125000 of=/root/1Gb.file LVM逻辑卷管理命令选项： pvcreate 磁盘设备名 #创建物理卷 pvscan或pvdisplay #查看物理卷 pvremove #删除物理卷 vgcreate -s PE大小 卷组名 物理卷名 #创建卷组 vgscan或vgdisplay #查看卷组 vgremove 卷组名 #删除卷组 vgextend 卷组名 物理卷名 #增加物理卷 vgreduce 卷组名 物理卷名 #删除物理卷 lvcreate -L 大小 -n lv名 卷组名 #创逻辑卷 lvscan或lvdisplay #查看逻辑卷 lvremove 逻辑卷名 #删除逻辑卷 lvextend -L +大小 分区名 #增加逻辑卷容量，只修改MBR表 resize -f 分区名 分区实际大小 #修改superblock大小 e2fsck -f 分区名 #检查文件系统 resize -f 分区名 减少到大小 #与增加大小反着来 lvreduce -L 实际大小 分区名 RAID设置命令例：mdadm -Cv md* -l10 -n4 磁盘 -x2 热备 #创建RAID10 mdadm -D 查看RAID10状态 mdadm -f cip #指定磁盘损坏 mdadm 设备名md* --remove 磁盘 #移除磁盘 mdadm 设备名md* --add 磁盘 #添加磁盘 mdadm -S 设备名md* #停止RAID mdadm --zero-superblock 设备名md* #删除RAID set查询当前所有生效的变量例：set -u #设置后，被调用的无效变量报错 set -x #设置后，每次执行命令，打印一次命令 unset 变量名 #取消变量 env只查询环境变量 echo 输出到屏幕例：echo -e “字符或格式” 选项：-e 支持反斜线控制的字符转换 -n 取消输出后行尾的换行符 history历史命令例：history -c #清空历史命令 -w #把缓存的历史命令保存到配置文件中 dd命令详解作用 dd：用指定大小的块拷贝一个文件 格式 dd if=/dev/zero of=/指定目录 bs=1M count=1000 if=文件名：输入文件名，缺省为标准输入。即指定源文件。&lt; if=input file &gt; of=文件名：输出文件名，缺省为标准输出。即指定目的文件。&lt; of=output file &gt; bs=bytes：同时设置读入/输出的块大小为bytes个字节。 count=blocks：仅拷贝blocks个块，块大小等于ibs指定的字节数。 dd应用实例 将本地的/dev/hdb整盘备份到/dev/hdddd if=/dev/hdb of=/dev/hdd 将/dev/hdb全盘数据备份到指定路径的image文件dd if=/dev/hdb of=/root/image 将备份文件恢复到指定盘dd if=/root/image of=/dev/hdb 备份/dev/hdb全盘数据，并利用gzip工具进行压缩，保存到指定路径dd if=/dev/hdb | gzip &gt; /root/image.gz 将压缩的备份文件恢复到指定盘gzip -dc /root/image.gz | dd of=/dev/hdb 备份与恢复MBRa.备份磁盘开始的512个字节大小的MBR信息到指定文件： dd if=/dev/hda of=/root/image count=1 bs=512 count=1指仅拷贝一个块；bs=512指块大小为512个字节。 b.恢复： dd if=/root/image of=/dev/had 将备份的MBR信息写到磁盘开始部分 拷贝内存内容到硬盘dd if=/dev/mem of=/root/mem.bin bs=1024 (指定块大小为1k) 拷贝光盘内容到指定文件夹，并保存为cd.iso文件dd if=/dev/cdrom(sr0) of=/root/cd.iso 增加swap分区文件大小第一步：创建一个大小为256M的文件： dd if=/dev/zero of=/swapfile bs=1024 count=262144 第二步：把这个文件变成swap文件： mkswap /swapfile 第三步：启用这个swap文件： swapon /swapfile 第四步：编辑/etc/fstab文件，使在每次开机时自动加载swap文件： /swapfile swap swap default 0 0 销毁磁盘数据dd if=/dev/urandom of=/dev/hda1 注意：利用随机的数据填充硬盘，在某些必要的场合可以用来销毁数据。 测试硬盘的读写速度dd if=/dev/zero bs=1024 count=1000000 of=/root/1Gb.file dd if=/root/1Gb.file bs=64k | dd of=/dev/null 通过以上两个命令输出的命令执行时间，可以计算出硬盘的读、写速度。 /dev/zero，是一个输入设备，你可你用它来初始化文件。该设备无穷尽地提供0，可以使用任何你需要的数目——设备提供的要多的多。他可以用于向设备或文件写入字符串0。 /dev/null——它是空设备，也称为位桶（bit bucket）。任何写入它的输出都会被抛弃。如果不想让消息以标准输出显示或写入文件，那么可以将消息重定向到位桶。外号叫无底洞，你可以向它输出任何数据，它通吃，并且不会撑着！ 确定硬盘的最佳块大小：dd if=/dev/zero bs=1024 count=1000000 of=/root/1Gb.file dd if=/dev/zero bs=2048 count=500000 of=/root/1Gb.file dd if=/dev/zero bs=4096 count=250000 of=/root/1Gb.file dd if=/dev/zero bs=8192 count=125000 of=/root/1Gb.file 通过比较以上命令输出中所显示的命令执行时间，即可确定系统最佳的块大小。常用查看命令 uname -a 查看内核/操作系统/CPU信息的linux系统信息命令 cat /etc/redhat-release 查看系统版本 cat /proc/cpuinfo| grep “processor”| wc -l 查看逻辑CPU个数 systemctl list-unit-files 查看服务启动项 cat /proc/sys/fs/file-max 系统最大打开文件描述符数 cat/proc/sys/fs/nr_open 单个进程可分配最大文件数 cat /proc/sys/fs/file-nr 查看当前系统使用的打开文件描述符数 sed -i ‘/^SELINUX/s/enforcing/disabled/g’ /etc/selinux/config 关闭selinux localectl set-locale LANG=zh_CN.UTF-8 更改为中文字符集 localectl status 查看系统字符集 echo ‘export TMOUT=300’ &gt;&gt;/etc/profile 设置闲置超时时间为300s echo ‘export HISTFILESIZE=100’ &gt;&gt;/etc/profile 设置闲置超时时间为300s echo ‘export HISTTIMEFORMAT=”%Y-%m-%d %H:%M:%S”‘ &gt;&gt;/etc/profile 格式化输出历史记录(以年月日分时秒的格式输出) #查看 CPU 物理个数grep ‘physical id’ /proc/cpuinfo | sort -u | wc -l #查看 CPU 核心数量grep ‘core id’ /proc/cpuinfo | sort -u | wc -l #查看 CPU 线程数grep ‘processor’ /proc/cpuinfo | sort -u | wc -l #查看 CPU 型号dmidecode -s processor-version #查看 CPU 的详细信息：cat /proc/cpuinfo","categories":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}],"tags":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/tags/linux基础/"}],"keywords":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}]},{"title":"网络顶级域名查看表","slug":"网络顶级域名查看表","date":"2019-06-09T07:27:43.000Z","updated":"2020-07-24T03:42:31.646Z","comments":true,"path":"2019/06/09/网络顶级域名查看表/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2019/06/09/网络顶级域名查看表/","excerpt":"","text":"国际域名 .com：商业机构，任何人都可以注册; .edu：教育机构; .gov：政府部门; .int：国际组织; .mil：美国军事部门; .net：网络组织，例如因特网服务商和维修商，现在任何人都可以注册; .org：非盈利组织，任何人都可以注册; .biz：商业; .info：网络信息服务组织; .pro：用于会计、律师和医生。; .name：用于个人; .museum：用于博物馆; .coop：用于商业合作团体; .aero：用于航空工业; .xxx：用于成人、色情网站; .idv：用于个人 国家域名 (按国家地区名称汉语拼音排列) A - B - C - D - E - F - G - H - I - J - K - L - M - N - O - P - Q - R - S - T - U - V - W - X - Y - Z A 阿尔巴尼亚 .al 阿尔及利亚 .dz 阿富汗 .af 阿根廷 .ar 阿拉伯联合酋长国 .ae 阿鲁巴 .aw 阿曼 .om 阿塞拜疆 .az 埃及 .eg 埃塞俄比亚 .et 爱尔兰 .ie 爱沙尼亚 .ee 安道尔 .ad 安哥拉 .ao 安圭拉 .ai 安提瓜和巴布达 .ag 奥地利 .at 澳大利亚 .au 澳门地区 .mo B 巴巴多斯 .bb 巴布亚新几内亚 .pg 巴哈马 .bs 巴基斯坦 .pk 巴拉圭 .py 巴勒斯坦 .ps 巴林 .bh 巴拿马 .pa 巴西 .br 白俄罗斯 .by 百慕大 .bm 保加利亚 .bg 北马里亚纳群岛 .mp 贝宁 .bj 比利时 .be 冰岛 .is 波多黎各 .pr 波斯尼亚和黑塞哥维那 .ba 波兰 .pl 玻利维亚 .bo 伯利兹 .bz 博茨瓦纳 .bw 不丹 .bt 布基纳法索 .bf 布隆迪 .bi 布维岛 .bv C 朝鲜 .kp 赤道几内亚 .gq D 丹麦 .dk 德国 .de 东帝汶 .tl (新域名); .tp (旧域名，尚未停用) 多哥 .tg 多米尼克 .dm 多米尼加共和国 .do E 俄罗斯 .ru 厄瓜多尔 .ec 厄立特里亚 .er F 法国 .fr 法罗群岛 .fo 法属波利尼西亚 .pf 法属圭亚那 .gf 法属南部领土 .tf 梵蒂冈 .va 菲律宾 .ph 斐济 .fj 芬兰 .fi 佛得角 .cv 福克兰群岛 .fk G 冈比亚 .gm 刚果 .cg 刚果民主共和国 .cd 哥伦比亚 .co 哥斯达黎加 .cr 格恩西岛 .gg 格林纳达 .gd 格陵兰 .gl 格鲁吉亚 .ge 古巴 .cu 瓜德罗普 .gp 关岛 .gu 圭亚那 .gy H 哈萨克斯坦 .kz 海地 .ht 韩国 .kr 荷兰 .nl 荷属安地列斯群岛 .an 赫德和麦克唐纳群岛 .hm 洪都拉斯 .hn J 基里巴斯 .ki 吉布提 .dj 吉尔吉斯斯坦 .kg 几内亚 .gn 几内亚比绍 .gw 加拿大 .ca 加纳 .gh 加蓬 .ga 柬埔寨 .kh 捷克共和国 .cz 津巴布韦 .zw K 喀麦隆 .cm 卡塔尔 .qa 开曼群岛 .ky 科摩罗 .km 科特迪瓦 .ci 科威特 .kw 可可群岛 .cc 克罗地亚 .hr 肯尼亚 .ke 库克群岛 .ck L 拉脱维亚 .lv 莱索托 .ls 老挝 .la 黎巴嫩 .lb 立陶宛 .lt 利比里亚 .lr 利比亚 .ly 列支敦士登 .li 留尼汪 .re 卢森堡 .lu 卢旺达 .rw 罗马尼亚 .ro M 马达加斯加 .mg 马恩岛 .im 马尔代夫 .mv 马耳他 .mt 马拉维 .mw 马来西亚 .my 马里 .ml 马其顿 .mk 马绍尔群岛 .mh 马提尼克岛 .mq 马约特岛 .yt 毛里求斯 .mu 毛里塔尼亚 .mr 美国 .us 美国本土外小岛屿 .um 美属萨摩亚 .as 美属维尔京群岛 .vi 蒙古 .mn 蒙特塞拉特岛 .ms 孟加拉国 .bd 秘鲁 .pe 密克罗尼西亚联邦 .fm 缅甸 .mm 摩尔多瓦 .md 摩洛哥 .ma 摩纳哥 .mc 莫桑比克 .mz 墨西哥 .mx N 瑙鲁 .nr 尼泊尔 .np 尼加拉瓜 .ni 尼日尔 .ne 尼日利亚 .ng 纽埃岛 .nu 挪威 .no 诺福克岛 .nf 纳米比亚 .na 南非 .za 南极洲 .aq 南乔治亚岛和南桑德韦奇岛 .gs O 欧洲联盟 .eu P 帕劳 .pw 皮特凯恩群岛 .pn 葡萄牙 .pt R 日本 .jp 瑞典 .se 瑞士 .ch S 萨尔瓦多 .sv 萨摩亚 .ws 塞尔维亚和黑山 .yu 塞拉利昂 .sl 塞内加尔 .sn 塞浦路斯 .cy 塞舌尔 .sc 沙特阿拉伯 .sa 圣诞岛 .cx 圣多美和普林西比 .st 圣赫勒拿岛 .sh 圣基茨和尼维斯 .kn 圣卢西亚 .lc 圣马力诺 .sm 圣皮埃尔岛及密客隆岛 .pm 圣文森特和格林纳丁斯 .vc 斯里兰卡 .lk 斯洛伐克 .sk 斯洛文尼亚 .si 斯瓦尔巴岛和扬马延岛 .sj 斯威士兰 .sz 苏丹 .sd 苏里南 .sr 所罗门群岛 .sb 索马里 .so T 塔吉克斯坦 .tj 台湾 .tw 泰国 .th 坦桑尼亚 .tz 汤加 .to 特克斯和凯科斯群岛 .tc 特立尼达和多巴哥 .tt 突尼斯 .tn 图瓦卢 .tv 土耳其 .tr 土库曼斯坦 .tm 托克劳 .tk W 瓦利斯和富图纳群岛 .wf 瓦努阿图 .vu 危地马拉 .gt 委内瑞拉 .ve 文莱 .bn 乌干达 .ug 乌克兰 .ua 乌拉圭 .uy 乌兹别克斯坦 .uz X 西班牙 .es 西撒哈拉 .eh 希腊 .gr 香港地区 .hk 新加坡 .sg 新喀里多尼亚 .nc 新西兰 .nz 匈牙利 .hu 叙利亚 .sy Y 牙买加 .jm 亚美尼亚 .am 亚森松岛 .ac 也门 .ye 伊拉克 .iq 伊朗 .ir 以色列 .il 意大利 .it 印度 .in 印度尼西亚 .id 英国 .uk 英属维尔京群岛 .vg 英属印度洋地区 .io 约旦 .jo 越南 .vn Z 赞比亚 .zm 泽西岛 .je 乍得 .td 直布罗陀 .gi 智利 .cl 中非共和国 .cf 中国 .cn 国家域名 (按国家、地区的域名顺序排列) A - B - C - D - E - F - G - H - I - J - K - L - M - N - O - P - Q - R - S - T - U - V - W - X - Y - Z A .ac 亚森松岛 .ad 安道尔 .ae 阿拉伯联合酋长国 .af 阿富汗 .ag 安提瓜和巴布达 .ai 安圭拉 .al 阿尔巴尼亚 .am 亚美尼亚 .an 荷属安地列斯群岛 .ao 安哥拉 .aq 南极洲 .ar 阿根廷 .as 美属萨摩亚 .at 奥地利 .au 澳大利亚 .aw 阿鲁巴 .az 阿塞拜疆 B .ba 波斯尼亚和黑塞哥维那 .bb 巴巴多斯 .bd 孟加拉国 .be 比利时 .bf 布基纳法索 .bg 保加利亚 .bh 巴林 .bi 布隆迪 .bj 贝宁 .bm 百慕大 .bn 文莱 .bo 玻利维亚 .br 巴西 .bs 巴哈马 .bt 不丹 .bv 布维岛 .bw 博茨瓦纳 .by 白俄罗斯 .bz 伯利兹 C .ca 加拿大 .cc 可可群岛 .cd 刚果民主共和国 .cf 中非共和国 .cg 刚果 .ch 瑞士 .ci 科特迪瓦 .ck 库克群岛 .cl 智利 .cm 喀麦隆 .cn 中国大陆 .co 哥伦比亚 .cr 哥斯达黎加 .cu 古巴 .cv 佛得角 .cx 圣诞岛 .cy 塞浦路斯 .cz 捷克共和国 D .de 德国 .dj 吉布提 .dk 丹麦 .dm 多米尼克 .do 多米尼加共和国 .dz 阿尔及利亚 E .ec 厄瓜多尔 .ee 爱沙尼亚 .eg 埃及 .eh 西撒哈拉 .er 厄立特里亚 .es 西班牙 .et 埃塞俄比亚 .eu 欧洲联盟 F .fi 芬兰 .fj 斐济 .fk 福克兰群岛 .fm 密克罗尼西亚联邦 .fo 法罗群岛 .fr 法国 G .ga 加蓬 .gd 格林纳达 .ge 格鲁吉亚 .gf 法属圭亚那 .gg 格恩西岛 .gh 加纳 .gi 直布罗陀 .gl 格陵兰 .gm 冈比亚 .gn 几内亚 .gp 瓜德罗普 .gq 赤道几内亚 .gr 希腊 .gs 南乔治亚岛和南桑德韦奇岛 .gt 危地马拉 .gu 关岛 .gw 几内亚比绍 .gy 圭亚那 H .hk 香港 .hm 赫德和麦克唐纳群岛 .hn 洪都拉斯 .hr 克罗地亚 .ht 海地 .hu 匈牙利 I .id 印度尼西亚 .ie 爱尔兰 .il 以色列 .im 马恩岛 .in 印度 .io 英属印度洋地区 .iq 伊拉克 .ir 伊朗 .is 冰岛 .it 意大利 J .je 泽西岛 .jm 牙买加 .jo 约旦 .jp 日本 K .ke 肯尼亚 .kg 吉尔吉斯斯坦 .kh 柬埔寨 .ki 基里巴斯 .km 科摩罗 .kn 圣基茨和尼维斯 .kp 朝鲜 .kr 韩国 .kw 科威特 .ky 开曼群岛 .kz 哈萨克斯坦 L .la 老挝 .lb 黎巴嫩 .lc 圣卢西亚 .li 列支敦士登 .lk 斯里兰卡 .lr 利比里亚 .ls 莱索托 .lt 立陶宛 .lu 卢森堡 .lv 拉脱维亚 .ly 利比亚 M .ma 摩洛哥 .mc 摩纳哥 .md 摩尔多瓦 .mg 马达加斯加 .mh 马绍尔群岛 .mk 马其顿 .ml 马里 .mm 缅甸 .mn 蒙古 .mo 中国澳门 .mp 北马里亚纳群岛 .mq 马提尼克岛 .mr 毛里塔尼亚 .ms 蒙特塞拉特岛 .mt 马耳他 .mu 毛里求斯 .mv 马尔代夫 .mw 马拉维 .mx 墨西哥 .my 马来西亚 .mz 莫桑比克 N .na 纳米比亚 .nc 新喀里多尼亚 .ne 尼日尔 .nf 诺福克岛 .ng 尼日利亚 .ni 尼加拉瓜 .nl 荷兰 .no 挪威 .np 尼泊尔 .nr 瑙鲁 .nu 纽埃岛 .nz 新西兰 O .om 阿曼 P .pa 巴拿马 .pe 秘鲁 .pf 法属波利尼西亚 .pg 巴布亚新几内亚 .ph 菲律宾 .pk 巴基斯坦 .pl 波兰 .pm 圣皮埃尔岛及密客隆岛 .pn 皮特凯恩群岛 .pr 波多黎各 .ps 巴勒斯坦 .pt 葡萄牙 .pw 帕劳 .py 巴拉圭 Q .qa 卡塔尔 R .re 留尼汪 .ro 罗马尼亚 .ru 俄罗斯 .rw 卢旺达 S .sa 沙特阿拉伯 .sb 所罗门群岛 .sc 塞舌尔 .sd 苏丹 .se 瑞典 .sg 新加坡 .sh 圣赫勒拿岛 .si 斯洛文尼亚 .sj 斯瓦尔巴岛和扬马延岛 .sk 斯洛伐克 .sl 塞拉利昂 .sm 圣马力诺 .sn 塞内加尔 .so 索马里 .sr 苏里南 .st 圣多美和普林西比 .sv 萨尔瓦多 .sy 叙利亚 .sz 斯威士兰 T .tc 特克斯和凯科斯群岛 .td 乍得 .tf 法属南部领土 .tg 多哥 .th 泰国 .tj 塔吉克斯坦 .tk 托克劳 .tl 东帝汶(新域名) .tm 土库曼斯坦 .tn 突尼斯 .to 汤加 .tp 东帝汶(旧域名，尚未停用) .tr 土耳其 .tt 特立尼达和多巴哥 .tv 图瓦卢 .tw 台湾 .tz 坦桑尼亚 U .ua 乌克兰 .ug 乌干达 .uk 英国 .um 美国本土外小岛屿 .us 美国 .uy 乌拉圭 .uz 乌兹别克斯坦 V .va 梵蒂冈 .vc 圣文森特和格林纳丁斯 .ve 委内瑞拉 .vg 英属维尔京群岛 .vi 美属维尔京群岛 .vn 越南 .vu 瓦努阿图 W .wf 瓦利斯和富图纳群岛 .ws 萨摩亚 Y .ye 也门 .yt 马约特岛 .yu 塞尔维亚和黑山 .yr 耶纽 Z .za 南非 .zm 赞比亚 .zw 津巴布韦","categories":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}],"tags":[{"name":"DNS","slug":"DNS","permalink":"https://hxqxiaoqi.gitee.io/tags/DNS/"}],"keywords":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}]},{"title":"记一次nginx超时连接错误","slug":"记一次nginx超时连接错误","date":"2019-06-07T09:27:43.000Z","updated":"2020-07-24T03:39:20.687Z","comments":true,"path":"2019/06/07/记一次nginx超时连接错误/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2019/06/07/记一次nginx超时连接错误/","excerpt":"","text":"连接错误代码1232019/06/05 17:15:05 [error] 10560#0: *7830037 connect() failed (110: Connection timed out) while connecting to upstream, client: 192.168.1.100, server: 123.abc.com, request: \"OPTIONS //tax/school/login/resetToken/101 HTTP/1.1\",upstream: \"http://192.168.1.20//aaa/bbb/login/resetToken/101\", host: \"123.abc.com\", referrer: \"http://abc.qwe.com/\" 分析网络上有很多的解决方法，但实际上都是根据自身遇到的问题而找到对应的服务解决，都没有讲为什么这个报错，报错的原因，其实仔细分析nginx报错的代码，也能很好的了解到你的问题所在。分析报错的代码： Connection timed out：按字面上的意思就可以知道，这是连接超时，也就是连接服务时，没有在规定时间内取得回应，才会报错。 connecting to upstream：如果了解nginx负载均衡，那你应该知道upstream是nginx负载均衡的设置，也就是问题出在负载均衡的连接上。 client: 192.168.1.100, server: 123.abc.com：客户端 192.168.1.100 请求服务端 123.abc.com 地址，返回错误。 upstream: “http://192.168.1.20//aaa/bbb/login/resetToken/101&quot; ： 这句话比较重要，负载到http://192.168.1.20//aaa/bbb/login/resetToken/101 这个地址是连接出问题。 解决思路 显然，上面的报错代码可以看出，问题是出在负载均衡地址的http://192.168.1.20//aaa/bbb/login/resetToken/101 上，定位问题后，接下去就比较好解决了。nginx负载无法访问到192.168.1.20服务器上的服务： 服务挂了，可以登陆服务器上查看 服务运行错误，可以查看服务的日志 防火墙问题，查看对应的Ip和端口是否开放 网络传输问题，tcpdump抓取数据查看是否有传输数据","categories":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://hxqxiaoqi.gitee.io/tags/nginx/"}],"keywords":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}]},{"title":"nfs 目录共享","slug":"nfs 目录共享","date":"2019-06-05T09:40:43.000Z","updated":"2020-07-24T04:00:03.357Z","comments":true,"path":"2019/06/05/nfs 目录共享/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2019/06/05/nfs 目录共享/","excerpt":"","text":"介绍NFS 是Network File System的缩写，即网络文件系统。一种使用于分散式文件系统的协定，由Sun公司开发，于1984年向外公布。功能是通过网络让不同的机器、不同的操作系统能够彼此分享个别的数据，让应用程序在客户端通过网络访问位于服务器磁盘中的数据，是在类Unix系统间实现磁盘文件共享的一种方法。 安装实验环境 服务器IP 安装服务 192.168.40.100 nfs-utils 192.168.40.101 nfs-utils nfs 服务端安装 在192.168.40.100 操作 12345678# 安装nfs（实际上需要安装两个包nfs-utils和rpcbind, 不过当使用yum安装nfs-utils时会把rpcbind一起安装上）yum -y install nfs-utils# 创建共享目录mkdir /data# 创建文件用户，uid为1000useradd huang 12# 修改nfs配置文件vim /etc/exports 1/data 192.168.40.101(rw,all_squash,anonuid=1000,anongid=1000) /data：为共享目录 192.168.40.101：为允许的客户端ip，可以是IP段（192.168.40.0/24），也可以是单个IP，或域名 sync ：同步模式，内存中数据时时写入磁盘；async ：不同步，把内存中数据定期写入磁盘中 no_root_squash ：加上这个选项后，root用户就会对共享的目录拥有至高的权限控制，就像是对本机的目录操作一样。不安全，不建议使用；root_squash：和上面的选项对应，root用户对共享目录的权限不高，只有普通用户的权限，即限制了root；all_squash：不管使用NFS的用户是谁，他的身份都会被限定成为一个指定的普通用户身份 anonuid/anongid ：要和root_squash 以及all_squash一同使用，用于指定使用NFS的用户限定后的uid和gid，前提是本机的/etc/passwd中存在这个uid和gid fsid=0：表示将/opt/nfs整个目录包装成根目录 如果需要共享多目录，可以在另取一行按以上格式填写 启动 12systemctl start rpcbind.servicesystemctl start nfs.service 查看是否启动 12# 通过查看service列中是否有nfs服务来确认NFS是否启动。rpcinfo -p 查看可挂载目录及可连接的IP 1showmount -e 192.168.40.100 重新加载exports配置 1exportfs -arv nfs客户端 在192.168.40.101 操作 1234567891011# 创建挂在目录mkdir -p /data/test# 查看nfs服务端可用共享目录showmount -e 192.168.40.100# 挂载目录mount -t nfs 192.168.40.100:/data /data/test# 查看是否挂在df -h 开机启动挂载 1vim /etc/fstab 1192.168.40.100:/opt/nfs /data/test nfs nolock 0 0","categories":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}],"tags":[{"name":"nfs","slug":"nfs","permalink":"https://hxqxiaoqi.gitee.io/tags/nfs/"}],"keywords":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}]},{"title":"nginx日志备份脚本","slug":"nginx日志备份脚本","date":"2019-06-04T11:40:43.000Z","updated":"2020-07-24T04:08:14.134Z","comments":true,"path":"2019/06/04/nginx日志备份脚本/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2019/06/04/nginx日志备份脚本/","excerpt":"","text":"定时任务配置12#定时任务#30 0 * * * /usr/bin/bash /usr/local/nginx/logs/nginx-log.sh &amp;&gt; /dev/null 备份脚本配置123456789101112131415161718192021222324252627#!/bin/bash#此脚本用于自动分割Nginx的日志，包括access.log和error.log#将前一天的access.log重命名为access-xxxx-xx-xx.log格式，并重新打开日志文件#Nginx日志文件所在目录LOG_PATH=/usr/local/nginx/logs/#获取昨天的日期YESTERDAY=$(date -d \"yesterday\" +%Y-%m-%d)WEEK=$(date -d -7day +%Y-%m-%d)#获取pid文件路径PID=/usr/local/nginx/logs/nginx.pid#创建备份目录mkdir -p /usr/local/nginx/logs/bak#分割日志mv $&#123;LOG_PATH&#125;access.log $&#123;LOG_PATH&#125;bak/access-$&#123;YESTERDAY&#125;.logmv $&#123;LOG_PATH&#125;error.log $&#123;LOG_PATH&#125;bak/error-$&#123;YESTERDAY&#125;.log#删除一周前日志rm -rf $&#123;LOG_PATH&#125;bak/access-$&#123;WEEK&#125;.logrm -rf $&#123;LOG_PATH&#125;bak/error-$&#123;WEEK&#125;.log#向Nginx主进程发送USR1信号，重新打开日志文件kill -USR1 `cat $&#123;PID&#125;`","categories":[{"name":"脚本","slug":"脚本","permalink":"https://hxqxiaoqi.gitee.io/categories/脚本/"}],"tags":[{"name":"shell脚本","slug":"shell脚本","permalink":"https://hxqxiaoqi.gitee.io/tags/shell脚本/"}],"keywords":[{"name":"脚本","slug":"脚本","permalink":"https://hxqxiaoqi.gitee.io/categories/脚本/"}]},{"title":"linux ssh免密登录设置","slug":"linux ssh免密登录设置","date":"2019-06-04T10:40:43.000Z","updated":"2020-07-24T04:09:12.418Z","comments":true,"path":"2019/06/04/linux ssh免密登录设置/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2019/06/04/linux ssh免密登录设置/","excerpt":"","text":"什么是sshSSH是一种网络协议，用于计算机之间的加密登录。相比传统的账户密码登录，SSH提供了一种更便捷安全的登录方式。 设置思路本博客中一律以：A电脑为登录机，IP为192.168.1.101，B电脑为被登录机，IP为192.168.1.100，也就是A登录到B是免密的。 在A电脑生成免密的公钥和私钥 把A电脑的公钥传到B电脑上 验证 总结 1. 生成免密的公钥和私钥在A电脑上执行以下命令： 1ssh-keygen -t rsa 一路回车就行查看家目录下，会生成一个.ssh的隐藏目录： 12[root@localhost ~]# ls -a ~/. .. anaconda-ks.cfg .bash_history .bash_logout .bash_profile .bashrc .cshrc .ssh .tcshrc .viminfo 在.ssh目录下三个文件： id_rsa : 生成的私钥文件 id_rsa.pub ： 生成的公钥文件 know_hosts : 已知的主机公钥清单 2. 把A电脑的公钥传到B电脑上在A电脑上执行命令： 1ssh-copy-id root@192.168.1.100 在跳出的输入框中输入yes之后需要输入B电脑的登录密码，回车完成该命令是把本机的公钥直接传到B电脑上的.ssh目录下，自动生成authorized_keys文件，这个文件是用来存放远程免密登录的公钥,主要通过这个文件记录多台机器的公钥 3. 验证现在在A电脑上直接连接B电脑，验证是否需要密码 1ssh root@192.168.1.100 4. 总结 实现远程免密登录不需要去被登录机上操作，只需要有其登录密码就行。 免密的原理：在被登录机上有本机生成的公钥，在本机用私钥去连接远程机，公钥是锁，私钥是钥匙。 如果有错误，可以把.ssh目录删除在重复以上操作。","categories":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}],"tags":[{"name":"ssh","slug":"ssh","permalink":"https://hxqxiaoqi.gitee.io/tags/ssh/"}],"keywords":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}]},{"title":"JDK1.8环境安装-linux","slug":"JDK1.8环境安装-linux","date":"2019-06-04T09:40:43.000Z","updated":"2020-07-24T04:10:47.680Z","comments":true,"path":"2019/06/04/JDK1.8环境安装-linux/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2019/06/04/JDK1.8环境安装-linux/","excerpt":"","text":"什么是JDKJDK (Java Development Kit) 是 Java 语言的软件开发工具包(SDK)。在JDK的安装目录下有一个jre目录，里面有两个文件夹bin和lib，在这里可以认为bin里的就是jvm，lib中则是jvm工作所需要的类库，而jvm和 lib合起来就称为jre。JRE（Java Runtime Environment，Java运行环境），包含JVM标准实现及Java核心类库。JRE是Java运行环境，并不是一个开发环境，所以没有包含任何开发工具（如编译器和调试器）JVM 是Java Virtual Machine（Java虚拟机）的缩写，JVM是一种用于计算设备的规范，它是一个虚构出来的计算机，是通过在实际的计算机上仿真模拟各种计算机功能来实现的。 JDK安装思路 下载JDK 上传linux服务器，解压 设置环境变量 查看版本 1. 下载JDKJDK官网下载地址：https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html请根据自己服务器情况下载对应版本，linux是下载tar.gz结尾的包 2. 上传linux服务器把JDK包上传服务器有多种方法，我是用Xshell自带的ftp功能上传服务器，比较简单，这边不多讲。上传完成后 3. 设置环境变量粘贴命令直接执行 123456789101112tar xf jdk-8u221-linux-x64.tar.gz -C /optcat &gt;&gt; /etc/profile &lt;&lt; 'EOF'#jdk8export JAVA_HOME=/opt/jdk1.8.0_221export JRE_HOME=$JAVA_HOME/jreexport PATH=$PATH:$JAVA_HOME/binexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jarEOFsource /etc/profilejava -version","categories":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}],"tags":[{"name":"jdk","slug":"jdk","permalink":"https://hxqxiaoqi.gitee.io/tags/jdk/"}],"keywords":[{"name":"linux基础","slug":"linux基础","permalink":"https://hxqxiaoqi.gitee.io/categories/linux基础/"}]},{"title":"nginx-1.14.2自动安装脚本","slug":"nginx-1.14.2自动安装脚本","date":"2019-06-04T09:40:43.000Z","updated":"2020-07-24T04:08:33.252Z","comments":true,"path":"2019/06/04/nginx-1.14.2自动安装脚本/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2019/06/04/nginx-1.14.2自动安装脚本/","excerpt":"","text":"安装方法前提服务器需要联网 在服务器上新建文件：nginx.sh 把代码复制到文件中 赋予执行权限：chmod 755 nginx.sh 执行脚本：./nginx.sh 脚本代码12345678910111213141516#!/bin/bash# 安装目录dir=/usr/local#安装依赖yum -y install gcc gcc-c++ pcre pcre-devel zlib zlib-devel openssl openssl-devel wget#下载nginxwget http://nginx.org/download/nginx-1.14.2.tar.gz#解压并安装useradd -r -s /sbin/nologin nginxtar xf ./nginx-1.14.2.tar.gzcd nginx-1.14.2/./configure --prefix=$dir/nginx --user=nginx --group=nginx --with-http_ssl_module --with-http_stub_status_module --with-http_gzip_static_module --with-http_realip_modulemake &amp;&amp; make install nginx基本命令启动： 1/usr/local/nginx/sbin/nginx 热重启： 1/usr/local/nginx/sbin/nginx -s reload 停止： 1/usr/local/nginx/sbin/nginx -s stop","categories":[{"name":"脚本","slug":"脚本","permalink":"https://hxqxiaoqi.gitee.io/categories/脚本/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://hxqxiaoqi.gitee.io/tags/nginx/"},{"name":"shell脚本","slug":"shell脚本","permalink":"https://hxqxiaoqi.gitee.io/tags/shell脚本/"}],"keywords":[{"name":"脚本","slug":"脚本","permalink":"https://hxqxiaoqi.gitee.io/categories/脚本/"}]},{"title":"无公网IP，实现云上服务器只允许公司访问","slug":"无公网IP，实现云上服务器只允许公司访问","date":"2019-06-04T08:40:43.000Z","updated":"2020-07-24T03:40:34.177Z","comments":true,"path":"2019/06/04/无公网IP，实现云上服务器只允许公司访问/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2019/06/04/无公网IP，实现云上服务器只允许公司访问/","excerpt":"","text":"实验效果随着云服务的普及，现在小公司大都没有购买公网IP，这对于运维人员来说，无法限制ssh远程登录的IP是一个很不爽的事，这篇博客就是为了实现公司无公网IP，也可现在ssh连接IP方法。 实验思路 注册动态域名 把动态域名绑定到公司路由器的DDNS服务上 在服务器上，使用shell脚本定时解析动态域名，获取公司IP，并与服务器白名单匹配 配置定时任务 1. 注册动态域名登录花生壳官网：https://b.oray.com/ 注册账号，申请动态域名（例：2awfes953.51mypc.cn）这里就不作详细解释。 2. 域名绑定路由器 登录公司主路由器 选择：虚拟服务–DDNS服务 开启DDNS，选择服务商oray.com，输入花生壳注册的用户名和密码，确认。 3. shell脚本配置1234567891011121314#!/bin/bash#定时获取公网IP脚本#如果没有nslookup命令，请安装：yum -y install bind-utils#获取公司公网IPip1=`nslookup 2awfes953.51mypc.cn|grep Address|awk -F \":\" 'NR==2&#123;print $2&#125;'|cut -d \" \" -f2`#获取白名单下的ssh允许的IP，如果原先没有，请先设置公司当前公网IPip2=`grep sshd /etc/hosts.allow|awk -F \":\" 'NR==1&#123;print $2&#125;'`#匹配获取的IP与白名单的IP是否一致，不一致就修改白名单IP为当前获取的公司IPif [ $ip1 != $ip2 ]:then sed -i \"s/sshd:$ip2:allow/sshd:$ip1:allow/g\" /etc/hosts.allowfi 4. 定时任务设置12#一小时匹配一次0 */1 * * * /bin/bash /data/ssh-rule.sh &amp;&gt; /dev/null","categories":[{"name":"脚本","slug":"脚本","permalink":"https://hxqxiaoqi.gitee.io/categories/脚本/"}],"tags":[{"name":"shell脚本","slug":"shell脚本","permalink":"https://hxqxiaoqi.gitee.io/tags/shell脚本/"}],"keywords":[{"name":"脚本","slug":"脚本","permalink":"https://hxqxiaoqi.gitee.io/categories/脚本/"}]},{"title":"一个简单的linux跳板机脚本","slug":"一个简单的linux跳板机脚本","date":"2019-06-03T09:27:43.000Z","updated":"2020-07-24T03:40:39.607Z","comments":true,"path":"2019/06/03/一个简单的linux跳板机脚本/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2019/06/03/一个简单的linux跳板机脚本/","excerpt":"","text":"实现效果前提需要设置ssh免密登录，这个跳板机脚本可以快速的切换登录服务器，通过脚本登录服务器之后，退出服务器，依然会返回跳板机菜单，因为只是个简单的脚本没有安全防护，推荐内网使用，或在跳板机脚本的服务器上设置安全策略。 服务器设置 上传脚本到服务器/home/test/ 修改/etc/profile.d/jump.sh，这个文件是连接服务器时执行的脚本，匹配你要登录的用户UID12#!/bin/bash[ $UID -eq 1000 ] &amp;&amp; /bin/bash /home/test/tbj.sh tbj.sh脚本配置12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091#!/bin/bash#kill信号，屏蔽的是HUP INT QUIT TSTP几个信号,用于防止退出操作function traper()&#123; trap '' INT QUIT TSTP TERM HUP&#125;#主菜单函数function menu()&#123; echo \"================Host List============== 1)项目1 2)项目2 3)有跳板机脚本服务器 q)退出================Host End===============\"&#125;#项目1,二级目录函数function Project1()&#123; echo \"================Host List============== 1)服务1 2)服务2 q)返回上一级================Host End===============\"&#125;#项目2,二级目录函数function Project2()&#123; echo \"================Host List============== 1)服务1 2)服务2 q)返回上一级================Host End===============\"&#125;#登录服务器连接函数，需要设置ssh免密登录function host()&#123;USER=\"test\"port=22 case \"$1\" in 1) Project1 read -p 'Pls input your choice:' num1 if [ $num1 == \"1\" ];then ssh $USER@172.16.136.2 -p $port elif [ $num1 == \"2\" ];then ssh $USER@172.16.136.3 -p $port else echo \"input number\" fi ;; 2) Project2 read -p 'Pls input your choice:' num2 if [ $num2 == \"1\" ];then ssh $USER@172.16.136.4 -p $port elif [ $num2 == \"2\" ];then ssh $USER@172.16.136.5 -p $port else echo \"input number\" fi ;; 3) exit ;; q) export $PPID kill -9 $PPID exit esac&#125;#主函数function main()&#123; while true do traper clear menu read -p 'Pls input your choice:' num host $num done&#125;#程序主入口main","categories":[{"name":"脚本","slug":"脚本","permalink":"https://hxqxiaoqi.gitee.io/categories/脚本/"}],"tags":[{"name":"shell脚本","slug":"shell脚本","permalink":"https://hxqxiaoqi.gitee.io/tags/shell脚本/"}],"keywords":[{"name":"脚本","slug":"脚本","permalink":"https://hxqxiaoqi.gitee.io/categories/脚本/"}]},{"title":"git基础使用","slug":"git基础使用","date":"2019-06-03T07:27:43.000Z","updated":"2020-07-24T04:04:14.528Z","comments":true,"path":"2019/06/03/git基础使用/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2019/06/03/git基础使用/","excerpt":"","text":"git是什么Git 是一个开源的分布式版本控制系统，用于敏捷高效地处理任何或小或大的项目。Git 是 Linus Torvalds 为了帮助管理 Linux 内核开发而开发的一个开放源码的版本控制软件。Git 与常用的版本控制工具 CVS, Subversion 等不同，它采用了分布式版本库的方式，不必服务器端软件支持。 git安装linux安装 123$ yum install curl-devel expat-devel gettext-devel openssl-devel zlib-devel$ yum -y install git-core$ git --version windows安装 官网下载:https://gitforwindows.org/ 下载后直接安装 git基本概念我们先来理解下Git 工作区、暂存区和版本库概念: 工作区：就是你在电脑里能看到的目录。暂存区：英文叫stage, 或index。一般存放在 “.git目录下” 下的index文件（.git/index）中，所以我们把暂存区有时也叫作索引（index）。版本库：工作区有一个隐藏目录.git，这个不算工作区，而是Git的版本库。 当对工作区修改（或新增）的文件执行 “git add” 命令时，暂存区的目录树被更新，同时工作区修改（或新增）的文件内容被写入到对象库中的一个新的对象中，而该对象的ID被记录在暂存区的文件索引中。 当执行提交操作（git commit）时，暂存区的目录树写到版本库（对象库）中，master 分支会做相应的更新。即 master 指向的目录树就是提交时暂存区的目录树。 当执行 “git reset HEAD” 命令时，暂存区的目录树会被重写，被 master 分支指向的目录树所替换，但是工作区不受影响。 当执行 “git rm –cached file” 命令时，会直接从暂存区删除文件，工作区则不做出改变。 当执行 “git checkout .” 或者 “git checkout – file” 命令时，会用暂存区全部或指定的文件替换工作区的文件。这个操作很危险，会清除工作区中未添加到暂存区的改动。 当执行 “git checkout HEAD .” 或者 “git checkout HEAD file” 命令时，会用 HEAD 指向的 master 分支中的全部或者部分文件替换暂存区和以及工作区中的文件。这个命令也是极具危险性的，因为不但会清除工作区中未提交的改动，也会清除暂存区中未提交的改动。 git 基本命令git config配置个人的用户名称和电子邮件地址,新的设定保存在当前项目的 .git/config 文件里。 12$ git config --global user.name \"runoob\"$ git config --global user.email test@runoob.com 要检查已有的配置信息，可以使用 git config –list 命令,这些配置我们也可以在 ~/.gitconfig 或 /etc/gitconfig 看到 1234$ git config --listhttp.postbuffer=2Muser.name=runoobuser.email=test@runoob.com git init该命令执行完后会在当前目录生成一个 .git 目录,该目录包含了资源的所有元数据，其他的项目目录保持不变（不像 SVN 会在每个子目录生成 .svn 目录，Git 只在仓库的根目录生成 .git 目录）。 12$ git init$ git init \"指定目录\" git clone我们使用 git clone 从现有 Git 仓库中拷贝项目参数说明：repo:Git 仓库。directory:本地目录。 1$ git clone &lt;repo&gt; 如果我们需要克隆到指定的目录，可以使用以下命令格式： 1$ git clone &lt;repo&gt; &lt;directory&gt; 如果要指定分支，使用选项-b： 1$ git clone -b master &lt;repo&gt; &lt;directory&gt; git add可将该文件添加到缓存 12$ git add \"指定文件或目录\"$ git add . git statusgit status 以查看在你上次提交之后是否有修改。 1$ git status git diff执行 git diff 来查看执行 git status 的结果的详细信息。git diff 命令显示已写入缓存与已修改但尚未写入缓存的改动的区别。git diff 有两个主要的应用场景。尚未缓存的改动：git diff查看已缓存的改动： git diff –cached查看已缓存的与未缓存的所有改动：git diff HEAD显示摘要而非整个 diff：git diff –stat git commit 使用 git add 命令将想要快照的内容写入缓存区， 而执行 git commit 将缓存区内容添加到仓库中。 m: 提交更新说明 a: add的使用 1$ git commit -am git reset HEAD用于取消已缓存的内容。 1$ git reset HEAD hello.php git rm 从工作目录中手工删除文件 1git rm &lt;file&gt; 如果删除之前修改过并且已经放到暂存区域的话，则必须要用强制删除选项 -f 1git rm -f &lt;file&gt; 如果把文件从暂存区域移除，但仍然希望保留在当前工作目录中，换句话说，仅是从跟踪清单中删除，使用 –cached 选项即可 1git rm --cached &lt;file&gt; git mvgit mv 命令用于移动或重命名一个文件、目录、软连接。 git branch (branchname) 创建分支 git checkout (branchname)切换分支命令 git merge (branchname)合并分支命令 git branch列出分支基本命令 git branch -d删除分支命令 git log列出历史提交记录 git log –oneline 历史记录的简洁的版本 git tag 查看所有标签 git tag -a v1.0 -m “标签说明”给最新一次提交打上（HEAD）”v1.0”的标签 git tag -a v1.0 “commit名”之前忘记,后面添加标签 git push origin v1.5默认上传不上传标签,需要指定 git remote add [shortname] [url]添加远程库 git remote rm [别名]删除远程仓库 git remotegit remote -v查看当前配置有哪些远程仓库 git fetch从远程仓库下载新分支与数据该命令执行完后需要执行git merge 远程分支到你所在的分支。 git push [alias] [branch]以上命令将你的 [branch] 分支推送成为 [alias] 远程仓库上的 [branch] 分支","categories":[{"name":"中间件","slug":"中间件","permalink":"https://hxqxiaoqi.gitee.io/categories/中间件/"}],"tags":[{"name":"git","slug":"git","permalink":"https://hxqxiaoqi.gitee.io/tags/git/"}],"keywords":[{"name":"中间件","slug":"中间件","permalink":"https://hxqxiaoqi.gitee.io/categories/中间件/"}]},{"title":"hexo主题多终端管理","slug":"hexo主题多终端管理","date":"2019-06-02T13:29:43.000Z","updated":"2020-07-24T04:04:46.761Z","comments":true,"path":"2019/06/02/hexo主题多终端管理/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2019/06/02/hexo主题多终端管理/","excerpt":"","text":"搭建目的很多人可能家里一台笔记本，公司一个台式机，想两个同时管理博客，同时达到备份的博客主题、文章、配置的目的。下面就介绍一下用gitee来备份博客并同步博客。 搭建步骤以下步骤统一用A和B电脑举例，A电脑为已经部署hexo客户端，B为另一台没有任何部署的电脑，如果之前都没部署过，请客之前教程heox主题搭建和hexo主题部署到gitee教程两个教程 新建一个gitee分支hexo，用于上传A电脑的hexo代码 A电脑上传hexo代码到gitee上 B电脑安装好环境，克隆gitee分支代码 常用命令 1. 新建一个gitee分支hexo登陆gitee，新建一个分支hexo，用于上传A电脑的hexo代码，master为存放hexo发布的代码，新建hexo分支为hexo客户端代码，我们就是下客户端代码到本机，之后写文章或样式发布到master。 2. A电脑上传hexo代码到gitee上进入博客根目录文件夹下，找到.gitignore文件，在最后增加两行内容/.deploy_git和/public然后运行git bash here，初始化仓库，执行： 1git init 如果提示已经有初始化，需要删除目录下所有.git文件，再执行初始化 添加远程仓库，origin为本地远程仓库名，后面是gitee仓库地址： 1git remote add origin https://gitee.com/xxx/xxx.git 如果远程仓库已存在文件，需要执行下面命令： 12# 把远程仓库和本地同步，消除差异git pull origin master --allow-unrelated-histories 添加目录下所有文件到暂存区，执行： 1git add . 提交并添加更新说明到版本库，执行： 1git commit -m \"更新说明\" 推送更新到远程仓库hexo分支，执行： 1git push -u origin hexo 如果仓库已经有代码会报错： 12345678xu:QProj xiaokai$ git push origin masterTo https://gitee.com/XXXXX.git ! [rejected] master -&gt; master (non-fast-forward)error: failed to push some refs to 'https://gitee.com/XXXXX.git'hint: Updates were rejected because the tip of your current branch is behindhint: its remote counterpart. Integrate the remote changes (e.g.hint: 'git pull ...') before pushing again.hint: See the 'Note about fast-forwards' in 'git push --help' for details. 执行以下命令： 12git fetch #从仓库更新代码到本地暂存区git merge origin/hexo #暂存区更新代码合并 执行git merge又报错： 12git mergefatal: refusing to merge unrelated histories 接着执行： 1git pull origin hexo --allow-unrelated-histories 然后继续git merge,依然有问题： 12fatal: You have not concluded your merge (MERGE_HEAD exists).Please, commit your changes before you merge. 这个就好处理了，是我们没有提交当前的变化， git add .,git commit -am “提交信息” 然后输入git pull,显示如下: 1Already up-to-date. 最后就可以执行: 1git push origin hexo 有时还会报错，执行以下命令上传代码： 1git push origin HEAD:hexo 现在可以去gitee上查看hexo分支，已经有hexo客户端代码 3. B电脑安装好环境，克隆gitee分支代码在B电脑上同样先安装好node、git、ssh、hexo，安装好插件，新建目录，进入git bash here，执行以下命令克隆代码，会在当前目生成仓库同名目录，可以在这个目录下更新文章，发布博客到gitee。 1git clone -b hexo https://gitee.com/xxx/xxx.git 4. 常用命令12345678git pull #同步更新hexo new post \"新建文章\" #简写形式 hexo n \"新建文章\"hexo clean #清除旧的public文件夹hexo g #生成静态文件 简写形式 hexo ghexo d #发布到github上 简写形式 hexo dgit add . #添加更改文件到缓存区git commit -m \"更新说明\" #提交到本地仓库git push -u origin HEAD:hexo #推送到远程仓库进行备份","categories":[{"name":"随笔","slug":"随笔","permalink":"https://hxqxiaoqi.gitee.io/categories/随笔/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://hxqxiaoqi.gitee.io/tags/hexo/"}],"keywords":[{"name":"随笔","slug":"随笔","permalink":"https://hxqxiaoqi.gitee.io/categories/随笔/"}]},{"title":"hexo主题部署到gitee教程","slug":"hexo主题部署到gitee教程","date":"2019-06-01T10:11:43.000Z","updated":"2020-07-24T04:04:41.801Z","comments":true,"path":"2019/06/01/hexo主题部署到gitee教程/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2019/06/01/hexo主题部署到gitee教程/","excerpt":"","text":"使用gitee原因目前国内访问GitHub速度慢，还可能被墙，所以Gitee来构建个人博客。Gitee类似国内版的GitHub，访问速度有保证。 安装前提 已经安装本地hexo主题，如果还未安装，请查看 hexo搭建教程 已经注册gitee账号 安装步骤 创建gitee仓库，获取仓库地址 启用gitee Pages服务，获取url 地址 修改hexo根目录config.xml配置 发布到gitee上 更新gitee Pages服务 1. 创建gitee仓库，获取仓库地址 登陆gitee，点击创建仓库 仓库名称最好取跟个性地址一致的名称，后期完成部署就生成的url可以不需要指定二级目录，博客样式也不会出错 选择公开 其他默认，点击创建 在克隆/下载的标签上可以看到你的仓库地址（例：https://gitee.com/xxx/xxx.git ） 2. 启用gitee Pages服务，获取url 地址 点击-服务，选择gitee Pages 勾选-强制使用https 点击-启动 等一会儿就会生成你的url，也就是完成部署后的博客访问地址，（例：https://xxx.gitee.io ），如果之前仓库名称没有与自己的个性地址一致，生成的地址应该是（https://xxx.gitee.io/xxx ） 3. 修改hexo根目录config.xml配置url地址，也就是域名地址，如果url是（ https://xxx.gitee.io/xxx ）这种格式，root设置二级目录名称修改： 12url: https://xxx.gitee.ioroot: / 仓库地址，用于上传hexo主题的地址，分支选择，如果没有修改，默认是master添加： 1234deploy: type: git repository: https://gitee.com/xxx/xxx.git branch: master 注意：冒号后面需要空格 4. 发布到gitee上安装自动部署发布工具 1npm install hexo-deployer-git --save 清除本地hexo缓存 1hexo clean 编译 1hexo g 码云认证12git config --global user.name \"用户名\"git config --global user.email \"邮箱\" 12# 第一次需要再输入码云账户和密码hexo d 5. 更新gitee Pages服务 点击服务，选择gittee Pages，点击更新 访问：https://xxx.gitee.io 每次hexo发布，都需要更新gittee Pages服务。 至此，博客发布成功","categories":[{"name":"随笔","slug":"随笔","permalink":"https://hxqxiaoqi.gitee.io/categories/随笔/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://hxqxiaoqi.gitee.io/tags/hexo/"}],"keywords":[{"name":"随笔","slug":"随笔","permalink":"https://hxqxiaoqi.gitee.io/categories/随笔/"}]},{"title":"heox主题搭建","slug":"heox主题搭建","date":"2019-05-31T12:27:43.000Z","updated":"2020-07-24T04:04:34.535Z","comments":true,"path":"2019/05/31/heox主题搭建/","link":"","permalink":"https://hxqxiaoqi.gitee.io/2019/05/31/heox主题搭建/","excerpt":"","text":"hexo简介Hexo是一款基于Node.js的静态博客框架，依赖少易于安装使用，可以方便的生成静态网页托管在GitHub和Coding上，是搭建博客的首选框架。大家可以进入hexo官网进行详细查看，因为Hexo的创建者是台湾人，对中文的支持很友好，可以选择中文进行查看。 Hexo搭建步骤 安装Git 安装Node.js 安装Hexo 更换博客主题 1. 安装gitGit是目前世界上最先进的分布式版本控制系统，可以有效、高速的处理从很小到非常大的项目版本管理。也就是用来管理你的hexo博客文章，上传到GitHub的工具。到git官网上下载,https://gitforwindows.org 直接双击安装即可。 2. 安装Node.jsHexo是基于nodeJS编写的，所以需要安装一下nodeJs和里面的npm工具。官网下载：https://nodejs.org/en/download/ 直接安装。 3. 安装Hexo前面git和nodejs安装好后，就可以安装hexo了。 创建一个自定义文件夹blog，右击该文件夹选择git bash here，会跳出git命令框。安装命令： 12345npm install -g hexo-cli #安装hexohexo -v #查看版本hexo init #初始化目录（会在目录下生成安装文件） 初始化后，blog文件夹目录下有： node_modules: 依赖包 public：存放生成的页面 scaffolds：生成文章的一些模板 source：用来存放你的文章 themes：主题目录（默认已经有一个主题landscape） _config.yml: 博客的配置文件 启动主题 12hexo g #编译hexo s #启动主题 访问localhost:4000即可看到博客内容至此hexo搭建完成 4. 更换博客主题主题官网：https://hexo.io/themes/ 这里有200多个主题可以选。点击主题名（以BlueLake）会链接到github上，下载zip包，然后放到themes文件夹下解压为BlueLake。 接下来打开blog目录下的_config.yml配置文件，修改： 1theme: BlueLake #名字为解压的主题名 运行命令： 12hexo g #编译hexo s #启动主题 访问localhost:4000，主题已更换 注：有些主题还需要安装其它样式模块，可以在主题目录下查看README.md文件，是否需要安装模块。","categories":[{"name":"随笔","slug":"随笔","permalink":"https://hxqxiaoqi.gitee.io/categories/随笔/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://hxqxiaoqi.gitee.io/tags/hexo/"}],"keywords":[{"name":"随笔","slug":"随笔","permalink":"https://hxqxiaoqi.gitee.io/categories/随笔/"}]}]}